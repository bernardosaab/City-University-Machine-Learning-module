<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,IE=9,chrome=1"><meta name="generator" content="MATLAB 2020b"><title>3. Dataset split</title><style type="text/css">.rtcContent { padding: 30px; } .CodeBlock { background-color: #F7F7F7; margin: 10px 0 10px 0;}
.S0 { border-left: 0.994318px solid rgb(233, 233, 233); border-right: 0.994318px solid rgb(233, 233, 233); border-top: 0.994318px solid rgb(233, 233, 233); border-bottom: 0.994318px solid rgb(233, 233, 233); border-radius: 4px; padding: 6px 45px 4px 13px; line-height: 17.234px; min-height: 18px; white-space: nowrap; color: rgb(0, 0, 0); font-family: Menlo, Monaco, Consolas, "Courier New", monospace; font-size: 14px;  }
.S1 { margin-bottom: 20px; padding-bottom: 4px;  }
.S2 { margin: 0px; padding: 10px 0px 10px 5px; line-height: 21px; min-height: 0px; white-space: pre-wrap; color: rgb(0, 0, 0); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 14px; font-weight: 700; text-align: start;  }
.S3 { margin: -1px 0px 0px; padding: 10px 0px 10px 7px; line-height: 21px; min-height: 0px; white-space: pre-wrap; color: rgb(0, 0, 0); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 14px; font-weight: 400; text-align: start;  }
.S4 { margin: 20px 10px 5px 4px; padding: 0px; line-height: 20px; min-height: 0px; white-space: pre-wrap; color: rgb(60, 60, 60); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 20px; font-weight: 700; text-align: left;  }
.S5 { margin: 2px 10px 9px 4px; padding: 0px; line-height: 21px; min-height: 0px; white-space: pre-wrap; color: rgb(0, 0, 0); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 14px; font-weight: 400; text-align: left;  }
.S6 { margin: 15px 10px 5px 4px; padding: 0px; line-height: 18px; min-height: 0px; white-space: pre-wrap; color: rgb(60, 60, 60); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 17px; font-weight: 700; text-align: left;  }
.S7 { border-left: 0.994318px solid rgb(233, 233, 233); border-right: 0.994318px solid rgb(233, 233, 233); border-top: 0.994318px solid rgb(233, 233, 233); border-bottom: 0px none rgb(0, 0, 0); border-radius: 4px 4px 0px 0px; padding: 6px 45px 0px 13px; line-height: 17.234px; min-height: 18px; white-space: nowrap; color: rgb(0, 0, 0); font-family: Menlo, Monaco, Consolas, "Courier New", monospace; font-size: 14px;  }
.S8 { border-left: 0.994318px solid rgb(233, 233, 233); border-right: 0.994318px solid rgb(233, 233, 233); border-top: 0px none rgb(0, 0, 0); border-bottom: 0px none rgb(0, 0, 0); border-radius: 0px; padding: 0px 45px 0px 13px; line-height: 17.234px; min-height: 18px; white-space: nowrap; color: rgb(0, 0, 0); font-family: Menlo, Monaco, Consolas, "Courier New", monospace; font-size: 14px;  }
.S9 { border-left: 0.994318px solid rgb(233, 233, 233); border-right: 0.994318px solid rgb(233, 233, 233); border-top: 0px none rgb(0, 0, 0); border-bottom: 0.994318px solid rgb(233, 233, 233); border-radius: 0px 0px 4px 4px; padding: 0px 45px 4px 13px; line-height: 17.234px; min-height: 18px; white-space: nowrap; color: rgb(0, 0, 0); font-family: Menlo, Monaco, Consolas, "Courier New", monospace; font-size: 14px;  }
.S10 { margin: 10px 10px 9px 4px; padding: 0px; line-height: 21px; min-height: 0px; white-space: pre-wrap; color: rgb(0, 0, 0); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 14px; font-weight: 400; text-align: left;  }
.S11 { margin: 10px 0px 20px; padding-left: 0px; font-family: Helvetica, Arial, sans-serif; font-size: 14px;  }
.S12 { margin-left: 56px; line-height: 21px; min-height: 0px; text-align: left; white-space: pre-wrap;  }
.S13 { margin: 10px 10px 5px 4px; padding: 0px; line-height: 18px; min-height: 0px; white-space: pre-wrap; color: rgb(60, 60, 60); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 15px; font-weight: 700; text-align: left;  }
.S14 { margin: 3px 10px 5px 4px; padding: 0px; line-height: 18px; min-height: 0px; white-space: pre-wrap; color: rgb(60, 60, 60); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 17px; font-weight: 700; text-align: left;  }
.S15 { margin: 3px 10px 5px 4px; padding: 0px; line-height: 20px; min-height: 0px; white-space: pre-wrap; color: rgb(60, 60, 60); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 20px; font-weight: 700; text-align: left;  }
.S16 { margin: 3px 10px 5px 4px; padding: 0px; line-height: 28.8px; min-height: 0px; white-space: pre-wrap; color: rgb(213, 80, 0); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 24px; font-weight: 400; text-align: left;  }
.S17 { margin: 15px 10px 5px 4px; padding: 0px; line-height: 28.8px; min-height: 0px; white-space: pre-wrap; color: rgb(213, 80, 0); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 24px; font-weight: 400; text-align: left;  }
.S18 { margin: 2px 10px 9px 4px; padding: 0px; line-height: 21px; min-height: 0px; white-space: pre-wrap; color: rgb(0, 0, 0); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 14px; font-weight: 400; text-align: center;  }
.S19 { margin: 3px 10px 5px 4px; padding: 0px; line-height: 18px; min-height: 0px; white-space: pre-wrap; color: rgb(60, 60, 60); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 15px; font-weight: 700; text-align: left;  }
.S20 { border-left: 0.994318px solid rgb(233, 233, 233); border-right: 0.994318px solid rgb(233, 233, 233); border-top: 0px none rgb(0, 0, 0); border-bottom: 0.994318px solid rgb(233, 233, 233); border-radius: 0px; padding: 0px 45px 4px 13px; line-height: 17.234px; min-height: 18px; white-space: nowrap; color: rgb(0, 0, 0); font-family: Menlo, Monaco, Consolas, "Courier New", monospace; font-size: 14px;  }
.S21 { color: rgb(64, 64, 64); padding: 10px 0px 6px 17px; background: rgb(255, 255, 255) none repeat scroll 0% 0% / auto padding-box border-box; font-family: Menlo, Monaco, Consolas, "Courier New", monospace; font-size: 14px; overflow-x: hidden; line-height: 17.234px;  }
.embeddedOutputsErrorElement {min-height: 18px; max-height: 250px; overflow: auto;}
.embeddedOutputsErrorElement.inlineElement {}
.embeddedOutputsErrorElement.rightPaneElement {}
.embeddedOutputsWarningElement{min-height: 18px; max-height: 250px; overflow: auto;}
.embeddedOutputsWarningElement.inlineElement {}
.embeddedOutputsWarningElement.rightPaneElement {}
.diagnosticMessage-wrapper {font-family: Menlo, Monaco, Consolas, "Courier New", monospace; font-size: 12px;}
.diagnosticMessage-wrapper.diagnosticMessage-warningType {color: rgb(255,100,0);}
.diagnosticMessage-wrapper.diagnosticMessage-warningType a {color: rgb(255,100,0); text-decoration: underline;}
.diagnosticMessage-wrapper.diagnosticMessage-errorType {color: rgb(230,0,0);}
.diagnosticMessage-wrapper.diagnosticMessage-errorType a {color: rgb(230,0,0); text-decoration: underline;}
.diagnosticMessage-wrapper .diagnosticMessage-messagePart,.diagnosticMessage-wrapper .diagnosticMessage-causePart {white-space: pre-wrap;}
.diagnosticMessage-wrapper .diagnosticMessage-stackPart {white-space: pre;}
.embeddedOutputsTextElement,.embeddedOutputsVariableStringElement {white-space: pre; word-wrap: initial; min-height: 18px; max-height: 250px; overflow: auto;}
.textElement,.rtcDataTipElement .textElement {padding-top: 3px;}
.embeddedOutputsTextElement.inlineElement,.embeddedOutputsVariableStringElement.inlineElement {}
.inlineElement .textElement {}
.embeddedOutputsTextElement.rightPaneElement,.embeddedOutputsVariableStringElement.rightPaneElement {min-height: 16px;}
.rightPaneElement .textElement {padding-top: 2px; padding-left: 9px;}
.variableValue { width: 100% !important; }
.embeddedOutputsMatrixElement,.eoOutputWrapper .matrixElement {min-height: 18px; box-sizing: border-box;}
.embeddedOutputsMatrixElement .matrixElement,.eoOutputWrapper .matrixElement,.rtcDataTipElement .matrixElement {position: relative;}
.matrixElement .variableValue,.rtcDataTipElement .matrixElement .variableValue {white-space: pre; display: inline-block; vertical-align: top; overflow: hidden;}
.embeddedOutputsMatrixElement.inlineElement {}
.embeddedOutputsMatrixElement.inlineElement .topHeaderWrapper {display: none;}
.embeddedOutputsMatrixElement.inlineElement .veTable .body {padding-top: 0 !important; max-height: 100px;}
.inlineElement .matrixElement {max-height: 300px;}
.embeddedOutputsMatrixElement.rightPaneElement {}
.rightPaneElement .matrixElement,.rtcDataTipElement .matrixElement {overflow: hidden; padding-left: 9px;}
.rightPaneElement .matrixElement {margin-bottom: -1px;}
.embeddedOutputsMatrixElement .matrixElement .valueContainer,.eoOutputWrapper .matrixElement .valueContainer,.rtcDataTipElement .matrixElement .valueContainer {white-space: nowrap; margin-bottom: 3px;}
.embeddedOutputsMatrixElement .matrixElement .valueContainer .horizontalEllipsis.hide,.embeddedOutputsMatrixElement .matrixElement .verticalEllipsis.hide,.eoOutputWrapper .matrixElement .valueContainer .horizontalEllipsis.hide,.eoOutputWrapper .matrixElement .verticalEllipsis.hide,.rtcDataTipElement .matrixElement .valueContainer .horizontalEllipsis.hide,.rtcDataTipElement .matrixElement .verticalEllipsis.hide {display: none;}
.embeddedOutputsVariableMatrixElement .matrixElement .valueContainer.hideEllipses .verticalEllipsis, .embeddedOutputsVariableMatrixElement .matrixElement .valueContainer.hideEllipses .horizontalEllipsis {display:none;}
.embeddedOutputsMatrixElement .matrixElement .valueContainer .horizontalEllipsis,.eoOutputWrapper .matrixElement .valueContainer .horizontalEllipsis {margin-bottom: -3px;}
.eoOutputWrapper .embeddedOutputsVariableMatrixElement .matrixElement .valueContainer {cursor: default !important;}
.embeddedOutputsVariableElement {white-space: pre-wrap; word-wrap: break-word; min-height: 18px; max-height: 250px; overflow: auto;}
.variableElement {}
.embeddedOutputsVariableElement.inlineElement {}
.inlineElement .variableElement {}
.embeddedOutputsVariableElement.rightPaneElement {min-height: 16px;}
.rightPaneElement .variableElement {padding-top: 2px; padding-left: 9px;}
.variableNameElement {margin-bottom: 3px; display: inline-block;}
.matrixElement .horizontalEllipsis,.rtcDataTipElement .matrixElement .horizontalEllipsis {display: inline-block; margin-top: 3px; width: 30px; height: 12px; background-repeat: no-repeat; background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB0AAAAJCAYAAADO1CeCAAAAJUlEQVR42mP4//8/A70xw0i29BUDFPxnAEtTW37wWDqakIa4pQDvOOG89lHX2gAAAABJRU5ErkJggg==");}
.matrixElement .verticalEllipsis,.textElement .verticalEllipsis,.rtcDataTipElement .matrixElement .verticalEllipsis,.rtcDataTipElement .textElement .verticalEllipsis {margin-left: 35px; width: 12px; height: 30px; background-repeat: no-repeat; background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAZCAYAAAAIcL+IAAAALklEQVR42mP4//8/AzGYgWyFMECMwv8QddRS+P//KyimlmcGUOFoOI6GI/UVAgDnd8Dd4+NCwgAAAABJRU5ErkJggg==");}</style></head><body><div class = rtcContent><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'></div></div></div><div  class = 'S1'><div  class = 'S2'><span style=' font-weight: bold;'>Table of Contents</span></div><div  class = 'S3'><span>    </span><a href = "#H_C0E408AA"><span>0. Problem statement
</span></a><span>    </span><a href = "#H_A6343FB4"><span>1. Data loading and preprocessing
</span></a><span>        </span><a href = "#H_13B9D098"><span>1.1 Data Load
</span></a><span>        </span><a href = "#H_89BEBEC9"><span>1.2 Data understanding and scope definition
</span></a><span>            </span><a href = "#H_4BAC38B8"><span>1.2.3 Remove 'vrl', 'phg' and 'plm' classes
</span></a><span>        </span><a href = "#H_FB1EF708"><span>1.3 Missing values analysis
</span></a><span>        </span><a href = "#H_6EC625C6"><span>1.4 Basic statistics 
</span></a><span>        </span><a href = "#H_FDC45C73"><span>1.4 Outliers
</span></a><span>    </span><a href = "#H_D284FB03"><span>2. Descriptive statistics
</span></a><span>    </span><a href = "#H_113375E9"><span>2.4 Correlation plot
</span></a><span>    </span><a href = "#H_416E3464"><span>2.5 Group statistics
</span></a><span>    </span><a href = "#H_57061E7D"><span>2.6 Convert categorical variables to numerical
</span></a><span>        </span><a href = "#H_5BA508C7"><span>2.6 Collinearity diagnostic
</span></a><a href = "#T_568AE8D7"><span>3. Dataset split
</span></a><a href = "#T_C5D08332"><span>4. Feature Selection
</span></a><span>    </span><a href = "#H_4D1B6D0A"><span>4.1 Classification ensemble of decision trees
</span></a><span>    </span><a href = "#H_50B14154"><span>4.2 Sequential Feature selection (sequentialfs)
</span></a><span>    </span><a href = "#H_E0E87931"><span>4.3 MSMR
</span></a><span>    </span><a href = "#H_6B6EC885"><span>4.4 NCA
</span></a><a href = "#T_457F559B"><span>5. Building, optimising and testing two models: Logistic Regression and Random Forest
</span></a><span>    </span><a href = "#H_1EEBF230"><span>5.1 Metrics of performance
</span></a><span>    </span><a href = "#H_1BA3E410"><span>4.2 Dataset split (training / testing)
</span></a><span>        </span><a href = "#H_169AE65B"><span>5.3 Multinomial Logistic regression
</span></a><span>    </span><a href = "#H_28117777"><span>5.3 Using SMOTE for minority class and undersampling of majority class
</span></a><span>        </span><a href = "#H_D1D04370"><span>5.3.1 Validation of class proportions
</span></a><span>        </span><a href = "#H_ED2B39E9"><span>5.3.2 Applying SafeLevelSMOTE to class 1 (arc)
</span></a><span>            </span><a href = "#H_8A53F44B"><span>Applying SafeLevelSMOTE
</span></a><span>        </span><a href = "#H_6B75D645"><span>5.3.3 Random undersampling of majority class (Class 3 (euk))
</span></a><span>        </span><a href = "#H_9D93B27D"><span>5.3.4 Validate new dataset
</span></a><span>            </span><a href = "#H_45DA9F37"><span>3
</span></a><span>    </span><a href = "#H_E451C2B5"><span>5.4 Regularization and best model selection
</span></a><span>    </span><a href = "#H_102C5F97"><span>5.2.9 Generating SMOTE dataset for training with entire set
</span></a><span>    </span><a href = "#H_AE5E8193"><span>5.3 Random Forest
</span></a><span>        </span><a href = "#H_583EBF9B"><span>5.3.1 Using Bayesian Optimisation
</span></a><span>    </span><a href = "#H_5D0A9B6D"><span>5.3.2 Performing training using best hyperparameters choice
</span></a><span>    </span><a href = "#H_ECD804FF"><span>5.5.4 with oversampling
</span></a><span>    </span><a href = "#H_FB024E77"><span>5.5.4 with oversampling
</span></a><span>    </span><a href = "#H_D8CE37C4"><span>Using cross-validation to improve performance of Bayesian Optimisation function
</span></a><span>    </span><a href = "#H_80A954B4"><span>5.9 Generate best model from the training set (using all data)
</span></a><span>    </span><a href = "#H_535B9C39"><span>5.10 Validating the optimised RF model on the test set</span></a></div></div><h2  class = 'S4' id = 'H_C0E408AA' ><span>0. Problem statement</span></h2><div  class = 'S5'><span></span></div><div  class = 'S5'><span>RNA is the code that creates proteins inside organisms.</span></div><div  class = 'S5'><span>RNA is organised into groups of 3 and each group is a triple nitrogenous base.</span></div><div  class = 'S5'><span>Codon is a triple nitrogenous base sequence present on mRNA (RNA messenger).</span></div><div  class = 'S5'><span>A codon is a sequence of three DNA or RNA nucleotides that corresponds with a specific amino acid or stop signal during protein synthesis. DNA and RNA molecules are written in a language of four nucleotides; meanwhile, the language of proteins includes 20 amino acids. Codons provide the key that allows these two languages to be translated into each other. Each codon corresponds to a single amino acid (or stop signal), and the full set of codons is called the genetic code. The genetic code includes 64 possible permutations, or combinations, of three-letter nucleotide sequences that can be made from the four nucleotides. Of the 64 codons, 61 represent amino acids, and three are stop signals mark the end of a protein.</span></div><div  class = 'S5'><span>The mRNA sequence is thus used as a template to assemble—in order—the chain of amino acids that form a protein. </span></div><div  class = 'S5'><span>The frequency of codon use in each organism can be determined and was originally developed by Professor Toshimichi Ikemura at</span><span> </span><a href = "http://spinner.lab.nig.ac.jp/lab_evol/home-e.html"><span>Laboratory of Evolutionary Genetics,</span></a><span> </span><a href = "http://www.nig.ac.jp/"><span>National Institute of Genetics.</span></a></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span>The dataset is made of 64 features</span></div><h2  class = 'S4' id = 'H_A6343FB4' ><span>1. Data loading and preprocessing</span></h2><div  class = 'S5'><span>Our dataset is availabe to download in </span><a href = "https://archive.ics.uci.edu/ml/datasets/Codon+usage"><span>https://archive.ics.uci.edu/ml/datasets/Codon+usage</span></a><span> in CSV file format and can be publicly accessed. </span></div><div  class = 'S5'><span>We are assuming the dataset is located in the folder below considering the script is located in the root folder:</span></div><div  class = 'S5'><span>root\Dataset\CodonUsageDataset</span></div><h3  class = 'S6' id = 'H_13B9D098' ><span>1.1 Data Load</span></h3><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Clear variables and close any open document</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>clear, close </span><span style="color: rgb(170, 4, 249);">all</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Add path to reproduce the code in another environment</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>addpath(</span><span style="color: rgb(170, 4, 249);">'.\Dataset\CodonUsageDataset'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Placeholder text to treat as an empty value, </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% specified as the comma-separated pair consisting of 'TreatAsMissing' and a character vector, % cell array of character vectors, string, or string array. Table elements corresponding to these characters are set to NaN.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% 'TreatAsEmpty' only applies to numeric columns in the file and cannot handle numeric values specified as text, such as '-99'.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>codon = readtable(</span><span style="color: rgb(170, 4, 249);">'codon_usage.csv'</span><span>,</span><span style="color: rgb(170, 4, 249);">"TreatAsEmpty"</span><span>,{</span><span style="color: rgb(170, 4, 249);">'.'</span><span>,</span><span style="color: rgb(170, 4, 249);">'NA'</span><span>});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>head(codon)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><h3  class = 'S6' id = 'H_89BEBEC9' ><span>1.2 Data understanding and scope definition</span></h3><div  class = 'S5'><span>let's take a copy of the raw file if we need to pre process again</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'><span style="white-space: pre;"><span>codonOriginal = codon;</span></span></div></div></div><div  class = 'S10'><span>We use the method </span><span style=' font-weight: bold;'>head</span><span> to plot and investigate a few samples of the dataset and understand the relation between the dependent variable and independent variables.</span></div><div  class = 'S5'><span></span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'><span style="white-space: pre;"><span>head(codon,10)</span></span></div></div></div><div  class = 'S10'><span>Now a few properties of the dataset</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>codon.Properties.VariableNames'</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div  class = 'S10'><span>The variable names are already self explanatory therefore we don't need to rename them can categorise them accordingly.</span></div><div  class = 'S5'><span>Column 1: Kingdom</span></div><ul  class = 'S11'><li  class = 'S12'><span>The 'Kingdom' is a 3-letter code corresponding to `xxx' in the CUTG database name: 'arc'(archaea), 'bct'(bacteria), 'phg'(bacteriophage), 'plm' (plasmid), 'pln' (plant), 'inv' (invertebrate), 'vrt' (vertebrate), 'mam' (mammal), 'rod' (rodent), 'pri' (primate), and 'vrl'(virus) sequence entries. Note that the CUTG database does not contain 'arc' and 'plm' (these have been manually curated ourselves).</span></li></ul><div  class = 'S5'><span>Column 2: DNAtype</span></div><ul  class = 'S11'><li  class = 'S12'><span>The 'DNAtype' is denoted as an integer for the genomic composition in the species: 0-genomic, 1-mitochondrial, 2-chloroplast, 3-cyanelle, 4-plastid, 5-nucleomorph, 6-secondary_endosymbiont, 7-chromoplast, 8-leucoplast, 9-NA, 10-proplastid, 11-apicoplast, and 12-kinetoplast.</span></li></ul><div  class = 'S5'><span>Column 3: SpeciesID</span></div><div  class = 'S5'><span>Column 4: Ncodons</span></div><div  class = 'S5'><span>Column 5: SpeciesName</span></div><div  class = 'S5'><span>Columns 6-69: codon (header: nucleotide bases; entries: frequency of usage (5 digit floating point number))</span></div><div  class = 'S5'><span>Codon frequencies </span></div><div  class = 'S5'><span>Replacing "Kingdom" column (dependent variable) values to adapt to the problem classification.</span></div><div  class = 'S5'><span>The values will be remapped to correspond to the 3 classes of Kingdoms of life:</span></div><div  class = 'S5'><img class = "imageNode" src = "data:image/png;base64,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" width = "440" height = "239" alt = "" style = "vertical-align: baseline"></img></div><div  class = 'S5'><span>Due to a controversial debate amongst viruses as to whether</span><span> they can be included in the tree of life then we will discard 'vrl' from the classification problem.</span></div><div  class = 'S5'><span>Another question posed by the biologists are related to phg classification in which group they should be classified. Given that we will also discard 'phg' from the problem.</span></div><div  class = 'S5'><span>For historical reasons, bacteriophage is widely used to refer to viruses of bacteria (and sometimes even archaea). The problem with such nomenclature is that it artificially divides the virosphere into two camps, with viruses of bacteria and archaea on one hand and viruses of eukaryotes on the other. </span></div><div  class = 'S5'><span>The term plasmid was first introduced by the American molecular biologist Joshua Lederberg in 1952. Plasmids are considered replicons. They can be found in all three major domains: </span><span style=' font-weight: bold;'>Archaea, Bacteria, and Eukarya</span><span>. Similar to viruses, plasmids are not considered by some to be a form of life. Therefore 'plm' will not be included as well.</span></div><div  class = 'S5'><span>From the original 11 classes of kingdoms we have 8 left in which 6 of them (plant, invertebrate, vertebrate, mammal, rodent, primate) we decided to classify as Eukaryotas and rename the values as 'euk' in order to reduce the complexity and still maintain a fairly robust classification problem. Other than that, there are another 2 groups ('arc' and 'bct' which are correspondent to the domains of Bacteria and Archaea).</span></div><div  class = 'S5'><span>'arc'(archaea), 'bct'(bacteria), 'phg'(bacteriophage), </span></div><div  class = 'S5'><span>'plm' (plasmid)</span></div><div  class = 'S5'><span> 'vrl'(virus)</span></div><div  class = 'S5'><span>Eukaryotas ('euk')</span></div><div  class = 'S5'><span>'pln' (plant), 'inv' (invertebrate), 'vrt' (vertebrate), 'mam' (mammal), 'rod' (rodent), 'pri' (primate), and</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%codon.Kingdom(strcmpi(codon.Kingdom,'pln')) = {0};</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>codon.Kingdom = regexprep(codon.Kingdom, {</span><span style="color: rgb(170, 4, 249);">'pln' 'inv' 'vrt' 'mam' 'rod' 'pri'</span><span>}, </span><span style="color: rgb(170, 4, 249);">'euk'</span><span>)</span></span></div></div></div><h4  class = 'S13' id = 'H_4BAC38B8' ><span>1.2.3 </span><span style=' font-weight: bold;'>Remove 'vrl', 'phg' and 'plm' classes</span></h4><div  class = 'S5'><span>Now we remove the Kingdom values (classes) which are not in the scope of the model.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Specify values</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>kingdom_out_scope = [</span><span style="color: rgb(170, 4, 249);">'vrl'</span><span>;</span><span style="color: rgb(170, 4, 249);">'phg'</span><span>;</span><span style="color: rgb(170, 4, 249);">'plm'</span><span>];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Specify conditions</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>is_out_scope = ismember(codon.Kingdom,kingdom_out_scope) ~= 0;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% remove</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>codon(is_out_scope,:) = []</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%new_table = my_Table(~(my_Table.data7 &gt; 1000 | my_Table.data7 &lt; 100),:); % filter and remove</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%cleanedData_2.Pregnancy(isnan(cleanedData_2.Pregnancy))</span></span></div></div></div><div  class = 'S10'><span>a</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>disp((codon.Properties.VariableNames)')</span></span></div></div></div><h3  class = 'S14' id = 'H_FB1EF708' ><span>1.3 Missing values analysis</span></h3><div  class = 'S5' id = 'H_4E186060' ><span>Let's investigate to verify if missing values are found</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Find rows with missing values that have at least one missing value '' '.' 'NA' NaN -99</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>TF = ismissing(codon,{</span><span style="color: rgb(170, 4, 249);">'' '.' 'NA' </span><span>NaN -99});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>rowsWithMissing = codon(any(TF,2),:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>disp(rowsWithMissing)</span></span></div></div></div><div  class = 'S10'><span>Given that there is only one row with missing values</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'><span style="white-space: pre;"><span>codon(any(TF,2),:) = []</span></span></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>variables_codon = codonOriginal.Properties.VariableNames;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>f=figure;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>f.Position = [100 100 1000 400];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>imagesc(ismissing(codonOriginal))</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>ax = gca;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>ax.XTick = 1:69;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>ax.XTickLabel = variables_codon;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>ax.XTickLabelRotation = 90;</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>title(</span><span style="color: rgb(170, 4, 249);">'Missing values in the Codon dataset'</span><span>)</span></span></div></div></div><div  class = 'S10'><span></span></div><div  class = 'S5' id = 'H_9AB61659' ><span></span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0' id = 'H_137EEF3C' ><span style="white-space: pre;"><span>summary(codon)</span></span></div></div></div><h3  class = 'S6' id = 'H_6EC625C6' ><span>1.4 Basic statistics </span></h3><div  class = 'S5'><span>Let's calculate the number of samples per class and basic statistics about the dependent variables.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7' id = 'H_1C7319C8' ></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Unique values and count for dependent variable</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>ckingdom = codon.Kingdom;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>[C,</span><span class="warning_squiggle_rte457626237 warningHighlight457626237">ia</span><span>,ic] = unique(codon.Kingdom);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>a_counts = accumarray(ic,1); </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>a_proportion = accumarray(ic,1) / size(codon,1); </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>value_counts = [string(C), a_counts, a_proportion]</span></span></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'><span style="white-space: pre;"><span>tabulate(ckingdom)</span></span></div></div></div><div  class = 'S5'><span>The proportion of each class in the dataset respects the following relationship:</span></div><div  class = 'S5'><span>Eukaryota: 69.4%</span></div><div  class = 'S5'><span>Bacteria: 29.3%</span></div><div  class = 'S5'><span>Archaea: 1.3%</span></div><div  class = 'S5'><span>We observe a high imbalance in one of the classes (Archaea). Therefore we </span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Now we should split the dataset between categorical and numerical data as</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% we will investigate basec statistics which are appropriate to numerical</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% data (e.g. min, max, mean) but not to categorical data.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>var_names = codon.Properties.VariableNames;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>i = </span><span class="warning_squiggle_rte457626237">[</span><span>1:width(codon)]</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span class="warning_squiggle_rte457626237">v_is_cell</span><span>(i) = iscell(codon.(var_names{i}));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">if </span><span>var_names{i}==</span><span style="color: rgb(170, 4, 249);">"Kingdom"</span><span>; then </span><span style="color: rgb(170, 4, 249);">iscell(codon.(var_names{2}))</span><span>; </span><span style="color: rgb(14, 0, 255);">end</span><span class="warning_squiggle_rte457626237 warningHighlight457626237">;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%use logical indexing to split between numerical and categorical columns</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>codon_numerical = codon(:,~v_is_cell);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%col_dependant_var = iscell(codon(:,find(string(codon.Properties.VariableNames) == "Kingdom"));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>codon_categorical = codon(:,v_is_cell);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>codon_categorical(:,codon_categorical.Properties.VariableNames==</span><span style="color: rgb(170, 4, 249);">"Kingdom"</span><span>) = [];</span></span></div></div></div><div  class = 'S10' id = 'H_1FC3799D' ><span></span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>statsTable = varfun(@(x) [mean(x);std(x);kurtosis(x);skewness(x);min(x);max(x)],codon_numerical);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>statsTable.Properties.RowNames = {</span><span style="color: rgb(170, 4, 249);">'mean' 'std' 'kurtosis' 'skewness' 'min' 'max'</span><span>};</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>statsTable.Properties.VariableNames = extractAfter(statsTable.Properties.VariableNames,</span><span style="color: rgb(170, 4, 249);">'Fun_'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>disp(statsTable);</span></span></div></div></div><div  class = 'S5'><span style=' font-family: monospace;'></span></div><div  class = 'S5'><span></span></div><h3  class = 'S6' id = 'H_FDC45C73' ><span>1.4 Outliers</span></h3><div  class = 'S5'><span></span></div><div  class = 'S5'><span style=' font-weight: bold;'>Detect Outliers using Mean</span></div><div  class = 'S5'><span>We can use isoutlier function to investigate the proportion of outliers. However, we should be careful with outliers removal considering Random Forest and Logistic Regression can be affected by outliers but depending on how they are implemented it is possible to impart robustness to outliers.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>outl = isoutlier(codon_numerical,</span><span style="color: rgb(170, 4, 249);">'mean'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span class="warning_squiggle_rte457626237">f</span><span> = figure;</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>bar(round(100 * sum(outl) / size(codon_numerical,1),2))</span></span></div></div></div><div  class = 'S10'><span>We observe the proportion of outliers is small considering each of the 67 columns</span></div><div  class = 'S5'><span></span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div  class = 'S10'><span style=' font-weight: bold;'>Detect Outliers for each codon using threshold </span><span>(Compute thresholds with outliers)</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>f = figure;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>f.Position = [10 10 2200 1600]; </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>out_rows = width(codon_numerical) - 4;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>p = zeros(out_rows ,2);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>i = </span><span class="warning_squiggle_rte457626237">[</span><span>4:width(codon_numerical)]</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    prc = prctile(codon_numerical{:,i},[5 95]);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    p(i,1) = prc(1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    p(i,2) = prc(2);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    t = 1:numel(codon_numerical{:,1});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Logical Index Of Values Outside The Respective Percentiles</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    TF = (codon_numerical{:,i}&lt;=p(i,1)) | (codon_numerical{:,i}&gt;=p(i,2));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    subplot(11,6,i-3)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    plot(t, codon_numerical{:,i})</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    hold </span><span style="color: rgb(170, 4, 249);">on</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    plot(t(TF), codon_numerical{:,i}(TF),</span><span style="color: rgb(170, 4, 249);">'x'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    yline(0.05)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    yline(0.95)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    hold </span><span style="color: rgb(170, 4, 249);">off</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    grid</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'></div></div></div><h2  class = 'S15' id = 'H_D284FB03' ><span>2. Descriptive statistics</span></h2><div  class = 'S5'><span></span></div><div  class = 'S5'><span>First let's analyse the dependent variables distributions individually  </span></div><div  class = 'S5'><span>Categorical variables</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%for k = 1:size(codon_numerical,2)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%    var_numerical_names{k} = codon_numerical.Properties.VariableNames;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%var_numerical_names = codon_numerical.Properties.VariableNames;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%var_numerical_names = cell2table(var_numerical_names);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>var_numerical_names = string(codon_numerical.Properties.VariableNames);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%setappdata(gcf, 'SubplotDefaultAxesLocation', [0, 0, 1, 1]);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% subplot dimension</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>n1 = 3; </span><span style="color: rgb(2, 128, 9);">% number of rows</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>n2 = 7; </span><span style="color: rgb(2, 128, 9);">% number of columns</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% These values would define the space between the graphs</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% if equal to 1 there will be no space between graphs</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>nw = 0.9; </span><span style="color: rgb(2, 128, 9);">% normalized width</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>nh = 0.9; </span><span style="color: rgb(2, 128, 9);">% normalized height</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span class="warning_squiggle_rte457626237">f1</span><span>=figure;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%size(codon_numerical,2) </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>k = 0;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>k1 = 1:n1</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">for </span><span>k2 = 1:n2 </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        k = k + 1;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(2, 128, 9);">%Ax = subplot(3,7,k);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        subplot(n1,n2,(k1-1)*n2 + k2,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                </span><span style="color: rgb(170, 4, 249);">'position'</span><span>, [(1-nw)/n2/2 + (k2-1)/n2, (1-nh)/n1/2 + 1-k1/n1,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                nw/n2 nh/n1]);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        hc1 = histogram(codon_numerical.(k));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        xlabel(var_numerical_names(k))</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        ylabel(</span><span style="color: rgb(170, 4, 249);">'Freq.'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        title({</span><span style="color: rgb(170, 4, 249);">''</span><span>;</span><span style="color: rgb(170, 4, 249);">'Histogram'</span><span>})</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(2, 128, 9);">%PosVec = Ax.Position;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(2, 128, 9);">%Ax.Position = PosVec+[0.005 0.035 0 0.005];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%f1.Position = f1.Position+[0 0 500 500];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>var_numerical_names = string(codon_numerical.Properties.VariableNames);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>fig = figure(); </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>fig.Position = [0 0 1880 1400];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>n = 67;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>tlo = tiledlayout(fig, </span><span style="color: rgb(170, 4, 249);">'flow'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%arrayfun(@(col)histogram(nexttile(tlo),table2array(codon_numerical(:,col))),1:n); % *see below</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>i = 1:n</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    ax = nexttile(tlo);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    h=histogram(ax, table2array(codon_numerical(:,i))); </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    xlabel(var_numerical_names(i));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>tlo.TileSpacing = </span><span style="color: rgb(170, 4, 249);">'compact'</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>tlo.Padding = </span><span style="color: rgb(170, 4, 249);">'compact'</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>title(tlo,</span><span style="color: rgb(170, 4, 249);">'Global title'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>ylabel(tlo, </span><span style="color: rgb(170, 4, 249);">'Frequency'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>xlabel(tlo, </span><span style="color: rgb(170, 4, 249);">'Histogram of Dependent Variables'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span style=' font-weight: bold;'>Exploratory Plots</span></div><div  class = 'S5'><span>We will generate boxplots to explore the relationships between</span><span> the independent variable </span><span>and the other dependent variables.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% subplot dimension</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>n1 = 8; </span><span style="color: rgb(2, 128, 9);">% number of rows</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>n2 = 7; </span><span style="color: rgb(2, 128, 9);">% number of columns</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% These values would define the space between the graphs</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% if equal to 1 there will be no space between graphs</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>nw = 0.9; </span><span style="color: rgb(2, 128, 9);">% normalized width</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>nh = 0.9; </span><span style="color: rgb(2, 128, 9);">% normalized height</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>f1=figure();</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>f1.Position = [0 0 2100 2400];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%size(codon_numerical,2) </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>k = 0;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>j=0;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>k1 = 1:n1</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">for </span><span>k2 = 1:n2 </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(2, 128, 9);">%hc1 = histogram(codon_numerical.(k));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        k = k + 1;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">if </span><span>any(ismember(var_numerical_names, codon.Properties.VariableNames{k})) </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            j = j + 1;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            subplot(n1,n2,j); </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span><span style="color: rgb(2, 128, 9);">%(k1-1)*n2 + k2</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            vs = violinplot(codon.(k), codon.Kingdom);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            xlabel(codon.Properties.VariableNames{k})</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            ylabel(</span><span style="color: rgb(170, 4, 249);">'Freq.'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span><span style="color: rgb(2, 128, 9);">%title({'';'Histogram'})</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span><span style="color: rgb(2, 128, 9);">%PosVec = Ax.Position;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(2, 128, 9);">%Ax.Position = PosVec+[0.005 0.035 0 0.005];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span> </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span> </span></span></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span></span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'><span style="white-space: pre;"><span>stats3 = groupsummary(codon,</span><span style="color: rgb(170, 4, 249);">"Kingdom"</span><span>,</span><span style="color: rgb(170, 4, 249);">"sum"</span><span>)</span></span></div></div></div><h2  class = 'S4' id = 'H_113375E9' ><span>2.4 Correlation plot</span></h2><div  class = 'S5'><span>n this step correlation between variables is explored and visualised using a heatmap</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%codon_cleaned = removevars(cleanedData_2,["ICU","Intubation"]);</span></span></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>fcorr = figure();</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>fcorr.Position = [0 0 2400 2800];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>codon_covmat = table2array(codon_numerical);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>covmat = corrcoef(codon_covmat);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>imagesc(covmat)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>ax = gca;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>colormap(jet);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>colorbar;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>xlabel(</span><span style="color: rgb(170, 4, 249);">'Codon Usage parameters'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>ylabel(</span><span style="color: rgb(170, 4, 249);">'Codon Usage parameters'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>title(</span><span style="color: rgb(170, 4, 249);">'Covariance of Codon Usage parameters'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>N=67;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>labelNames = var_numerical_names;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>set(gca,</span><span style="color: rgb(170, 4, 249);">'XTick'</span><span>,1:N);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>set(gca,</span><span style="color: rgb(170, 4, 249);">'YTick'</span><span>,1:N);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>set(gca,</span><span style="color: rgb(170, 4, 249);">'XTickLabel'</span><span>,labelNames);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>set(gca,</span><span style="color: rgb(170, 4, 249);">'YTickLabel'</span><span>,labelNames);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>set(gca,</span><span style="color: rgb(170, 4, 249);">'XTickLabelRotation'</span><span>,90)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%set(gca,'YTickLabel',labelNames);</span></span></div></div></div><h2  class = 'S15' id = 'H_416E3464' ><span>2.5 Group statistics</span></h2><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%statarray = grpstats(codon,["Deceased"], "mean","DataVars",["Age"]) % Calculating group statistics by outcome variable (Deceased).</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Let's draw a probabilistic plot</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%probplot('normal',dataF.Age)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%calculating basic statistics according to a grouping variable using groupsummary function</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%stats3 = groupsummary(dataF,"Deceased","sum")</span></span></div></div></div><h2  class = 'S15' id = 'H_57061E7D' ><span style=' font-weight: bold;'>2.6 Convert categorical variables to numerical</span></h2><div  class = 'S5'><span>One hot encoding is the most widespread approach, and it works very well unless your categorical variable takes on a large number of values (i.e. you generally won't it for variables taking more than 15 different values. It'd be a poor choice in some cases with fewer values, though that varies.)</span></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span>First we will investigate how many values are in the SpeciesName column which is the only categorical variable.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>[C,ia,ic] = unique(codon_categorical);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>size(C,1)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Now we can calculate the proportion of unique values compared to the</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% cardinality of the dataset</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>size(C,1)/size(codon_categorical,1)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div  class = 'S10'><span>Since the only column left is SpeciesName with 9952 distinct values and 99.95% of cardinality then we understand that this would not be a useful variable to include as it has surprisingly high cardinality and it could be similar to a unique identifier rather than a generalisable feature. Therefore, we will not convert the SpeciesName column to numerical and we consider codon_numerical as our cleaned dataset for the next steps of the process.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'></div></div></div><div  class = 'S5'><span style=' font-weight: bold;'></span></div><div  class = 'S5'><span style=' font-weight: bold;'></span></div><div  class = 'S5'><span style=' font-weight: bold;'></span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'></div></div></div><h3  class = 'S14' id = 'H_5BA508C7' ><span>2.6 Collinearity diagnostic</span></h3><div  class = 'S5'><span></span></div><div  class = 'S5'><span>The collinearity diagnostics</span><span> </span><span style=' font-weight: bold;'>confirm that there are serious problems with multicollinearity</span><span>. Several eigenvalues are close to 0, indicating that the predictors are highly intercorrelated and that small changes in the data values may lead to large changes in the estimates of the coefficients.</span></div><div  class = 'S5'><span>To assess collinearity, the software computes </span><a href = "https://in.mathworks.com/help/econ/collintest.html#btcd2tb"><span>singular values</span></a><span> </span><span>of the scaled variable matrix,</span><span> </span><span style=' font-style: italic;'>X</span><span>, and then converts them to</span><span> </span><a href = "https://in.mathworks.com/help/econ/collintest.html#btcdtr4"><span>condition indices</span></a><span>. The conditional indices identify the number and strength of any near dependencies between variables in the variable matrix. The software decomposes the variance of the ordinary least squares (OLS) estimates of the regression coefficients in terms of the singular values to identify variables involved in each near dependency, and the extent to which the dependencies degrade the regression.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Display the Belsley collinearity diagnostics, using all default options.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>coll = collintest(codon_numerical)</span></span></div></div></div><div  class = 'S10'><span>Considering the method has a default tolerance of 30 we conclude there are 11 rows with a condition index larger than the tolerance.</span></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span>Now we should also investigate if any of the variables has </span></div><div  class = 'S5'><span>And several </span></div><div  class = 'S5'><span> last row in the display has a condition index larger than the default tolerance, 30. In this row, the last three variables (in the last three columns) have variance-decomposition proportions exceeding the default tolerance, 0.5. This suggests that the variables </span><span style=' font-family: monospace;'>INT_S</span><span>, </span><span style=' font-family: monospace;'>INT_M</span><span>, and </span><span style=' font-family: monospace;'>INT_L</span><span> exhibit multicollinearity.</span></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span></span></div><h1  class = 'S16' id = 'T_568AE8D7' ><span style=' font-weight: bold;'>3. Dataset split</span></h1><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%% Define a random seed for reproducibility purpose</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% This is to prevent differences that can result in a new set of random numbers after</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% executing again random functions.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>rng(1,</span><span style="color: rgb(170, 4, 249);">'twister'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%% Split up train and test set</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X = table2array(codon_numerical);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y = categorical(codon.Kingdom);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Partition data selecting 20% for test and the remaining (80%) for</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% training.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>part = cvpartition(codon.Kingdom,</span><span style="color: rgb(170, 4, 249);">'Holdout'</span><span>,0.2,</span><span style="color: rgb(170, 4, 249);">'Stratify'</span><span>,true);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Create training/test set indexes</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>is_train = training(part); </span><span style="color: rgb(2, 128, 9);">% Indexes for training</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>is_test = test(part);      </span><span style="color: rgb(2, 128, 9);">% Indexes for test (quality assessment)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Generate training set</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_train = X(is_train,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_train = y(is_train,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Generate test set to use after the best model selection</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_test = X(is_test,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span class="warning_squiggle_rte457626237">y_test</span><span> = y(is_test,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div  class = 'S5'><span>Define array of classes that will be used to address class names ('arc', 'bct', 'euk') to y arrays for class values (1, 2, 3) respectively.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'><span style="white-space: pre;"><span>codon_classes = [</span><span style="color: rgb(170, 4, 249);">"arc" "bct" "euk"</span><span>];</span></span></div></div></div><h1  class = 'S16' id = 'T_C5D08332' ><span style=' font-weight: bold;'>4. Feature Selection</span></h1><div  class = 'S5'><span style=' font-weight: bold;'>Given the high dimensionality of the resulting dataset (67 variables) we propose the implementation of several feature selection methods and then select the one which is considered most suitable for our objective without loss of generalisation.</span></div><div  class = 'S5'><span style=' font-weight: bold;'>Four methods will be used one as a Embedded Type Feature Selection type (Classification ensemble of decision trees) and the other 3 methods are classified as Filter Type Feature Selection (Sequentialfs, MNMR, and NCA).</span></div><div  class = 'S5'><span style=' font-weight: bold;'>4.1 Classification ensemble of decision trees</span></div><div  class = 'S5'><span style=' font-weight: bold;'>4.2 Sequentialfs</span></div><div  class = 'S5'><span style=' font-weight: bold;'>4.3 MNMR</span></div><div  class = 'S5'><span style=' font-weight: bold;'>4.4 NCA</span></div><div  class = 'S5'><span style=' font-weight: bold;'>We will use codon_numerical and codon.Kingdom as inputs that will be used in the above methods</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'></div></div></div><div  class = 'S5'><span style=' font-weight: bold;'></span></div><h2  class = 'S4' id = 'H_4D1B6D0A' ><span style=' font-weight: bold;'>4.1 Classification ensemble of decision trees</span></h2><div  class = 'S5'><span style=' font-weight: bold;'></span></div><div  class = 'S5'><span>Estimates of predictor importance for classification ensemble of decision trees.</span></div><div  class = 'S5'><span style=' font-family: monospace;'>predictorImportance</span><span> </span><span>estimates predictor importance for each tree learner in the ensemble</span><span> </span><span style=' font-family: monospace;'>ens</span><span> </span><span>and returns the weighted average</span><span> </span><span style=' font-family: monospace;'>imp</span><span> </span><span>computed using</span><span> </span><span style=' font-family: monospace;'>ens.TrainedWeight</span><span>. The output</span><span> </span><span style=' font-family: monospace;'>imp</span><span> </span><span>has one element for each predictor.</span></div><div  class = 'S5'><span style=' font-family: monospace;'>predictorImportance</span><span> </span><span>computes importance measures of the predictors in a tree by summing changes in the node risk due to splits on every predictor, and then dividing the sum by the total number of branch nodes. The change in the node risk is the difference between the risk for the parent node and the total risk for the two children. For example, if a tree splits a parent node (for example, node 1) into two child nodes (for example, nodes 2 and 3), then</span><span> </span><span style=' font-family: monospace;'>predictorImportance</span><span> </span><span>increases the importance of the split predictor by </span></div><div  class = 'S5'><span>(</span><span style=' font-style: italic;'>R1</span><span> – </span><span style=' font-style: italic;'>R2</span><span> – </span><span style=' font-style: italic;'>R3</span><span>) / </span><span style=' font-style: italic;'>N(</span><span>branch)</span></div><div  class = 'S5'><span>We will train a classification ensemble using AdaBoostM2. Specify tree stumps as the weak learners.</span></div><div  class = 'S5'><span>We also identify surrogate splits because trees with surrogate splits are supposed to give better predictions.</span></div><div  class = 'S5'><span>This means that if there is a missing variable used in a primary split to be predicted then a "surrogate split</span><span style=' font-weight: bold;'>"</span><span> is used instead.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>t = templateTree(</span><span style="color: rgb(170, 4, 249);">'MaxNumSplits'</span><span>,1,</span><span style="color: rgb(170, 4, 249);">'Surrogate'</span><span>,</span><span style="color: rgb(170, 4, 249);">'on'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>ens = fitcensemble(codon_numerical,codon.Kingdom,</span><span style="color: rgb(170, 4, 249);">'Method'</span><span>,</span><span style="color: rgb(170, 4, 249);">'AdaBoostM2'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Learners'</span><span>,t);</span></span></div></div></div><div  class = 'S10'><span>And now we estimate the predictor importance for all predictor variables of the ensemble.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>[imp,ma] = predictorImportance(ens)</span></span></div></div></div><div  class = 'S5'><span>And if we rank the imp array</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'><span style="white-space: pre;"><span>[out,</span><span class="warning_squiggle_rte457626237 warningHighlight457626237">idx</span><span>] = sort(imp,</span><span style="color: rgb(170, 4, 249);">'descend'</span><span>)</span></span></div></div></div><div  class = 'S10'><span>Finally we can also sort the predictor importance looking at the difference between each predictor importance and the following to observe larger gaps of difference.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>[out' [0;diff(out')]]</span></span></div></div></div><div  class = 'S10'><span>Even though the 10 first predictors give higher score with values over 0.01 when we compare the differences between them we do not observe a set of predictors with higher node risks due to split. Thus we will not consider this method as relevant for feature selection.</span></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span></span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'><span style="white-space: pre;"><span>disp(</span><span style="color: rgb(170, 4, 249);">'1'</span><span>)</span></span></div></div></div><h2  class = 'S15' id = 'H_50B14154' ><span style=' font-weight: bold;'>4.2 Sequential Feature selection (sequentialfs)</span></h2><div  class = 'S5'><span>Knowing that sequentialfs has poor performance when a large dataset is used we decided to run the algorithm with 20% of the samples as a baseline with a sample of the training set and 5-fold cross validation.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>rng(10,</span><span style="color: rgb(170, 4, 249);">'twister'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>part = cvpartition(codon.Kingdom,</span><span style="color: rgb(170, 4, 249);">'Holdout'</span><span>,0.8,</span><span style="color: rgb(170, 4, 249);">'Stratify'</span><span>,true);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>issampletrain = training(part); </span><span style="color: rgb(2, 128, 9);">% Data for fitting</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_sf = table2array(codon_numerical);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_sf = categorical(codon.Kingdom);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_sf_tr = X_sf(issampletrain,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_sf_tr = y_sf(issampletrain,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>cv = cvpartition(y_sf_tr,</span><span style="color: rgb(170, 4, 249);">'k'</span><span>,5);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%% feature selection</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>opts = statset(</span><span style="color: rgb(170, 4, 249);">'display'</span><span>,</span><span style="color: rgb(170, 4, 249);">'iter'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>costfun = @(XT,yT,Xt,yt)loss(fitcecoc(XT,yT),Xt,yt);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>[fs, history] = sequentialfs(costfun, X_sf_tr, y_sf_tr, </span><span style="color: rgb(170, 4, 249);">'cv'</span><span>, cv, </span><span style="color: rgb(170, 4, 249);">'options'</span><span>, opts); </span></span></div></div></div><div  class = 'S5' id = 'T_A3E4D10D' ><span>Based on the above result we conclude that only the column 1 was included. This means from the initial 67 columns only 1 were selected. But we initially assumed that only 20% would represent the entire distribution, hence the conclusion of sequentialfs could result in poor performance. Therefore we will investigate the next 2 methods to verify if any could be applicable for selecting the most important features frmothe high-dimensional space.</span></div><h2  class = 'S15' id = 'H_E0E87931' ><span>4.3 MSMR</span></h2><div  class = 'S5' id = 'T_CE50D0DA' ><span>Rank features for classification using minimum redundancy maximum relevance (MRMR) algorithm.</span></div><div  class = 'S5'><span>We are not using the same traning samples as the sequentialfs method because the MSMR and NCA have better performance as we would be able to use more data in order to produce a more robust result and also to have a baseline for comparison between both approaches.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>X_fs = table2array(codon_numerical);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_fs = categorical(codon.Kingdom);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Partition the data selecting 20% for test and the remaining (80%) for</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% training.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% We call rng again as we want his experiment to be statistically</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% independent from the previous one.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% And for long-term repeatability we specify the seed and the generator type together.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>rng(10,</span><span style="color: rgb(170, 4, 249);">'twister'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>part = cvpartition(codon.Kingdom,</span><span style="color: rgb(170, 4, 249);">'Holdout'</span><span>,0.2,</span><span style="color: rgb(170, 4, 249);">'Stratify'</span><span>,true);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Create training/val set indexes for training samples</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>idx_fs_train = training(part); </span><span style="color: rgb(2, 128, 9);">% Indexes for training  </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span class="warning_squiggle_rte457626237">idx_fs_val</span><span> = test(part);      </span><span style="color: rgb(2, 128, 9);">% Indexes for validation  </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span class="warning_squiggle_rte457626237">X_fs_train</span><span> = X_fs(idx_fs_train,:)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span class="warning_squiggle_rte457626237">y_fs_train</span><span> = y_fs(idx_fs_train,:)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>[idx,scores] = fscmrmr(X_fs(issampletrain,:),y_fs(issampletrain,:));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>figure</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>bar(scores(idx))</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>xlabel(</span><span style="color: rgb(170, 4, 249);">'Predictor rank'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>ylabel(</span><span style="color: rgb(170, 4, 249);">'Predictor importance score'</span><span>)</span></span></div></div></div><div  class = 'S10'><span>The drop in score between the first/second and third most important predictors is large, while the drops after the 29th predictor are relatively small. A drop in the importance score represents the confidence of feature selection. Therefore, the large drop implies that the software is confident of selecting the most important predictor. The small drops indicate that the difference in predictor importance are not significant.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Below we have the columns</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>idx(1:29)'</span></span></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% And the column names represented by the above indexes</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>msmridx = idx(1:29)';</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>fs_msmr = codon_numerical.Properties.VariableNames(msmridx(1:end,:));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%(selidx(1:end,:));</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'><span style="white-space: pre;"><span>{num2cell(idx(1:39))'}</span></span></div></div></div><h2  class = 'S15' id = 'H_6B6EC885' ><span style=' font-family: monospace;'>4.4 NCA</span></h2><div  class = 'S5'><span style=' font-family: monospace;'></span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Based on the initial data split (from item 3) we partition the data selecting 20% for validation and the remaining (80%) for</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% training.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>part = cvpartition(y_train,</span><span style="color: rgb(170, 4, 249);">'Holdout'</span><span>,0.2,</span><span style="color: rgb(170, 4, 249);">'Stratify'</span><span>,true);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Create training/val set indexes for training samples</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>idx_fs_train = training(part); </span><span style="color: rgb(2, 128, 9);">% Indexes for training of NCA</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>idx_fs_val = test(part);      </span><span style="color: rgb(2, 128, 9);">% Indexes for validation of NCA</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_fs_train = X_train(idx_fs_train,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_fs_train = y_train(idx_fs_train,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_fs_val = X_train(idx_fs_val,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_fs_val = y_train(idx_fs_val,:)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>mdlnca = fscnca(X_fs_train,y_fs_train,</span><span style="color: rgb(170, 4, 249);">'Solver'</span><span>,</span><span style="color: rgb(170, 4, 249);">'sgd'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Verbose'</span><span>,1);</span></span></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>figure()</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>plot(mdlnca.FeatureWeights,</span><span style="color: rgb(170, 4, 249);">'ro'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>grid </span><span style="color: rgb(170, 4, 249);">on</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>xlabel(</span><span style="color: rgb(170, 4, 249);">'Feature index'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>ylabel(</span><span style="color: rgb(170, 4, 249);">'Feature weight'</span><span>)</span></span></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'></div></div></div><div  class = 'S10'><span>Compute generalization error without fitting.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>nca = fscnca(X_fs_train,y_fs_train,</span><span style="color: rgb(170, 4, 249);">'FitMethod'</span><span>,</span><span style="color: rgb(170, 4, 249);">'none'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span class="warning_squiggle_rte457626237">L</span><span> = loss(nca,X_fs_val,y_fs_val)</span></span></div></div></div><div  class = 'S10'><span>First we fit NCA without regularization parameter (Lambda = 0)</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7' id = 'T_50BE77C2' ></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>nca = fscnca(X_fs_train,y_fs_train,</span><span style="color: rgb(170, 4, 249);">'FitMethod'</span><span>,</span><span style="color: rgb(170, 4, 249);">'exact'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Lambda'</span><span>,0,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      </span><span style="color: rgb(170, 4, 249);">'Solver'</span><span>,</span><span style="color: rgb(170, 4, 249);">'sgd'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Standardize'</span><span>,true);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>L = loss(nca,X_fs_val,y_fs_val)</span></span></div></div></div><div  class = 'S5'><span>The improvement on the loss value suggests that feature selection is a good idea. Tuning the </span><span style=' font-style: italic;'>λ</span><span> </span><span>value usually improves the results.</span></div><div  class = 'S5'><span>Tuning</span><span> </span><span style=' font-style: italic;'>λ</span><span> </span><span>means finding the</span><span> </span><span style=' font-style: italic;'>λ</span><span> </span><span>value that produces the minimum classification loss. To tune</span><span> </span><span style=' font-style: italic;'>λ</span><span> </span><span>using cross-validation:</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%1. Partition the training data into ten folds and extract the number of validation (test) sets. </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% For each fold, cvpartition assigns nine-tenth of the data as a training set, and one-tenth of the data as a test set.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>cvp = cvpartition(y_fs_train,</span><span style="color: rgb(170, 4, 249);">'kfold'</span><span>,10);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>numvalidsets = cvp.NumTestSets;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%Assign λ values and create an array to store the loss function values.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>n = length(y_fs_train);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>lambdavals = linspace(0,20,20)/n;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>lossvals = zeros(length(lambdavals),numvalidsets);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>i = 1:length(lambdavals)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">for </span><span>k = 1:numvalidsets</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        X_fs_tr = X_fs_train(cvp.training(k),:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        y_fs_tr = y_fs_train(cvp.training(k),:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        Xvalid = X_fs_train(cvp.test(k),:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        yvalid = y_fs_train(cvp.test(k),:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        nca = fscnca(X_fs_tr,y_fs_tr,</span><span style="color: rgb(170, 4, 249);">'FitMethod'</span><span>,</span><span style="color: rgb(170, 4, 249);">'exact'</span><span>, </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>             </span><span style="color: rgb(170, 4, 249);">'Solver'</span><span>,</span><span style="color: rgb(170, 4, 249);">'sgd'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Lambda'</span><span>,lambdavals(i), </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>             </span><span style="color: rgb(170, 4, 249);">'IterationLimit'</span><span>,30,</span><span style="color: rgb(170, 4, 249);">'GradientTolerance'</span><span>,1e-4, </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>             </span><span style="color: rgb(170, 4, 249);">'Standardize'</span><span>,true);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                  </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        lossvals(i,k) = loss(nca,Xvalid,yvalid,</span><span style="color: rgb(170, 4, 249);">'LossFunction'</span><span>,</span><span style="color: rgb(170, 4, 249);">'classiferror'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div></div><div  class = 'S10'><span>Compute the average loss obtained from the folds for each</span><span> </span><span style=' font-style: italic;'>λ</span><span> </span><span>value.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'><span style="white-space: pre;"><span>meanloss = mean(lossvals,2);</span></span></div></div></div><div  class = 'S10'><span>Plot the average loss values versus the</span><span> </span><span style=' font-style: italic;'>λ</span><span> </span><span>values.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>figure()</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>plot(lambdavals,meanloss,</span><span style="color: rgb(170, 4, 249);">'ro-'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>xlabel(</span><span style="color: rgb(170, 4, 249);">'Lambda'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>ylabel(</span><span style="color: rgb(170, 4, 249);">'Loss (MSE)'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>grid </span><span style="color: rgb(170, 4, 249);">on</span></span></div></div></div><div  class = 'S10' id = 'T_DC8A582C' ><span>Find the best lambda value that corresponds to the minimum average loss.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7' id = 'T_D9930372' ><span style="white-space: pre;"><span>[~,idx] = min(meanloss) </span><span style="color: rgb(2, 128, 9);">% Find the index</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>bestlambda = lambdavals(idx) </span><span style="color: rgb(2, 128, 9);">% Find the best lambda value</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>bestloss = meanloss(idx)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div  class = 'S10'><span style=' font-weight: bold;'></span></div><div  class = 'S5'><span style=' font-weight: bold;'>Fitting the nca model on all data using best</span><span style=' font-weight: bold;'> </span><span style=' font-style: italic;'>λ</span><span style=' font-weight: bold;'> </span><span style=' font-weight: bold;'>and plot the feature weights</span></div><div  class = 'S5'><span>We will now use the solver lbfgs and standardize the predictor values.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>nca = fscnca(X_train,y_train,</span><span style="color: rgb(170, 4, 249);">'FitMethod'</span><span>,</span><span style="color: rgb(170, 4, 249);">'exact'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Solver'</span><span>,</span><span style="color: rgb(170, 4, 249);">'sgd'</span><span>,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(170, 4, 249);">'Lambda'</span><span>,bestlambda,</span><span style="color: rgb(170, 4, 249);">'Standardize'</span><span>,true,</span><span style="color: rgb(170, 4, 249);">'Verbose'</span><span>,1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>figure()</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>plot(nca.FeatureWeights,</span><span style="color: rgb(170, 4, 249);">'ro'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>xlabel(</span><span style="color: rgb(170, 4, 249);">'Feature index'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>ylabel(</span><span style="color: rgb(170, 4, 249);">'Feature weight'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>grid </span><span style="color: rgb(170, 4, 249);">on</span></span></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%Set NCA threshold level</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>threshold_nca    = 0.02;</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>selidx = find(nca.FeatureWeights &gt; threshold_nca*max(1,max(nca.FeatureWeights)))</span></span></div></div></div><div  class = 'S5'><span>Indentify features to be dropped</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'><span style="white-space: pre;"><span>fs_drop = find(nca.FeatureWeights &lt;= threshold_nca*max(1,max(nca.FeatureWeights)))</span></span></div></div></div><div  class = 'S10'><span>And the feature names related to the indexes.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>codon_numerical.Properties.VariableNames(fs_drop)</span></span></div></div></div><div  class = 'S5'><span></span></div><div  class = 'S5' id = 'T_A026E9BD' ><span>Drop the 24 features which are a result from the NCA feature selection</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Take a copy of X_train and X_test for backup purposes</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">if </span><span>(~exist(</span><span style="color: rgb(170, 4, 249);">'X_train_raw'</span><span>,</span><span style="color: rgb(170, 4, 249);">'var'</span><span>) == 1 &amp;&amp; ~exist(</span><span style="color: rgb(170, 4, 249);">'X_test_raw'</span><span>,</span><span style="color: rgb(170, 4, 249);">'var'</span><span>) == 1) </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    || </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    ((exist(</span><span style="color: rgb(170, 4, 249);">'X_train_raw'</span><span>,</span><span style="color: rgb(170, 4, 249);">'var'</span><span>) == 1 &amp;&amp; exist(</span><span style="color: rgb(170, 4, 249);">'X_test_raw'</span><span>,</span><span style="color: rgb(170, 4, 249);">'var'</span><span>) == 1) </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        &amp;&amp; (size(X_train_raw,2) &lt;= size(X_train,2) &amp;&amp; </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    size(X_test_raw,2) &lt;= size(X_test,2) ))</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    X_train_raw = X_train;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    X_test_raw = X_test;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%Extract the features with feature weights greater than 0 from the training data.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span class="warning_squiggle_rte457626237">X_train</span><span> = X_train_raw(:,selidx);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span class="warning_squiggle_rte457626237">X_test</span><span> = X_test_raw(:,selidx);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%Evaluate the accuracy of the trained classifier on the test data which has not been used for selecting features.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%arra=num2cell(selidx);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%fs_nca = codon_numerical.Properties.VariableNames(selidx(1:end,:));</span></span></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7' id = 'T_680EF2F9' ><span style="white-space: pre;"><span>features_to_keep = codon_numerical.Properties.VariableNames(selidx(1:end,:))</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7' id = 'T_C7416912' ></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>codon_numerical(:, codon_numerical.Properties.VariableNames(fs_nca))</span></span></div></div></div><h1  class = 'S17' id = 'T_DFA41BD8' ><span style=' font-weight: bold;'></span></h1><h1  class = 'S16' id = 'T_457F559B' ><span style=' font-weight: bold;'>5. Building, optimising and testing two models: Logistic Regression and Random Forest</span></h1><h2  class = 'S4' id = 'H_1EEBF230' ><span>5.1 Metrics of performance</span></h2><div  class = 'S5'><span></span></div><div  class = 'S5'><span>TP</span></div><div  class = 'S5'><span>FP</span></div><div  class = 'S5'><span>FN</span></div><div  class = 'S5'><span>FP</span></div><div  class = 'S5'><span>Precision</span></div><div  class = 'S5'><span>Recall</span></div><div  class = 'S5'><span>Sensititvity</span></div><div  class = 'S5'><span>Sensibility</span></div><div  class = 'S5'><span>Accuracy</span></div><div  class = 'S5'><span>Balanced Accuracy</span></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span style=' font-weight: bold;'>ROC AUC (ROC)</span><span>:</span></div><div  class = 'S5'><span>ROC curves are typically used in binary classification to study the output of a classifier. In order to extend ROC curve and ROC area to multi-class or multi-label classification, it is necessary to binarize the output. One ROC curve can be drawn per label, but one can also draw a ROC curve by considering each element of the label indicator matrix as a binary prediction (micro-averaging).</span></div><div  class = 'S5' id = 'H_412BFD01' ><span>To get an estimate of the overall classification performance we can use the area under the curve (AUC) for multi-class classification presented in the Hand and Till 2001 paper (doi: 10.1023/A:1010920819831). </span></div><div  class = 'S5' id = 'H_1D87655C' ><a href = "https://stats.stackexchange.com/questions/262616/roc-vs-precision-recall-curves-on-imbalanced-dataset"><span>https://stats.stackexchange.com/questions/262616/roc-vs-precision-recall-curves-on-imbalanced-dataset</span></a></div><div  class = 'S5'><span style=' font-weight: bold;'>PR AUC (PRC)</span><span>:</span></div><div  class = 'S5'><span>Precision-recall curves are typically used in binary classification to study the output of a classifier. In order to extend the precision-recall curve and average precision to multi-class or multi-label classification, it is necessary to binarize the output. One curve can be drawn per label, but one can also draw a precision-recall curve by considering each element of the label indicator matrix as a binary prediction (micro-averaging).</span></div><div  class = 'S5'><span>According to the studies from the </span><a href = "http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf"><span>http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf</span></a><span> paper ROC curves can sometimes be misleading in some very imbalanced applications. A ROC curve can still look pretty good (ie better than random) while misclassifying most or all of the minority class.  </span></div><div  class = 'S5'><span>Because of that we will also use PR AUC curves to assess the models performances.</span></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span></span></div><div  class = 'S5'><a href = "https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html"><span style=' text-decoration: underline;'></span></a></div><h2  class = 'S4' id = 'H_1BA3E410' ><span>4.2 Dataset split (training / testing)</span></h2><div  class = 'S5'><span></span></div><div  class = 'S5'><span>According to several references for smaller datasets a ratio of 70/30 for train/test is used however in large datasets often 80/20 is used. We consider our dataset for the task a large enough dataset with ~10k observations and approx 40 variables.</span></div><div  class = 'S5'><span>To maintain a similar proportion we will utilize 5-fold validation to lower the bias and select hyperparameters for the models.</span></div><div  class = 'S5'><span></span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%% Define a random seed for reproducibility purpose</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% This is to prevent differences that can result in a new set of random numbers after</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% executing again random functions.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>rng(</span><span style="color: rgb(170, 4, 249);">'default'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%% Split up train and test set</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X = table2array(codon_numerical);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y = categorical(codon.Kingdom);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Partition data selecting 20% for test and the remaining (80%) for</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% training.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>part = cvpartition(codon.Kingdom,</span><span style="color: rgb(170, 4, 249);">'Holdout'</span><span>,0.2,</span><span style="color: rgb(170, 4, 249);">'Stratify'</span><span>,true);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Create training/test set indexes</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>is_train = training(part); </span><span style="color: rgb(2, 128, 9);">% Indexes for training</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>is_test = test(part);      </span><span style="color: rgb(2, 128, 9);">% Indexes for test (quality assessment)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Generate training set</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_train = X(is_train,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_train = y(is_train,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Generate test set to use after the best model selection</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_test = X(is_test,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_test = y(is_test,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div  class = 'S5'><span>At this point we can compare the class proportions between the original dataset against the training set to validate if we have a stratified random sample to use.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Original dataset class proportion</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>tabulate(y)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% After splitting dataset class proportion</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>tabulate(y_train)</span></span></div></div></div><div  class = 'S10'><span></span></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span>As we observe above the classes have approximatelly the same proportion when both datasets are compared.</span></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span></span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>[m,n] = size(codon) ;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>P = 0.80; </span><span style="color: rgb(2, 128, 9);">% The size of the training dataset is set to 80% of total size of dataset</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>codon_fs = codon_numerical(:, codon_numerical.Properties.VariableNames(fs_nca))</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>rng(</span><span style="color: rgb(170, 4, 249);">'default'</span><span>); </span><span style="color: rgb(2, 128, 9);">% To prevent randperm function to draw random numbers after each run, "rng" is used. This is to ensure reproducibility </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Create a series of index to randomly split the data into 80% training and 20% testing.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>idx = randperm(m); </span><span style="color: rgb(2, 128, 9);">% Generate a vector of random permutation of all data: m is the size of the datapoints</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>trainingData = codon(idx(1:round(P*m)),:); </span><span style="color: rgb(2, 128, 9);">% Defining the training features of the datasets corresponding to the randomly shuffled vector</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>testingData = codon(idx(round(P*m)+1:end),:);  </span><span style="color: rgb(2, 128, 9);">% Defining the testing features of the datasets corresponding to the randomly shuffled vector</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div  class = 'S10'><span></span></div><div  class = 'S5'><a href = "https://uk.mathworks.com/help/stats/bootstrp.html#mw_4cec271d-3ccd-4df8-959e-37cd686f4119"><span style=' font-family: monospace;'></span></a></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>nboot=10;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>[idx,bootsamp] = bootstrp(nboot,[],xTrain);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>i=1:nboot</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span class="warning_squiggle_rte457626237">newX</span><span>{i} = xTrain(bootsamp(:,i),:)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div></div><h3  class = 'S14' id = 'H_169AE65B' ><span>5.3 Multinomial Logistic regression</span></h3><div  class = 'S5'><a href = "https://uk.mathworks.com/help/stats/multinomial-models-for-nominal-responses.html"><span style=' font-weight: bold;'>Multinomial Models for Nominal Responses</span></a></div><div  class = 'S5'><span>A nominal response variable has a restricted set of possible values with no natural order between them. A nominal response model explains and predicts the probability that an observation is in each category of a categorical response variable.</span></div><div  class = 'S5'><span>A</span><span> </span><span style=' font-weight: bold;'>multinomial logistic regression</span><span> </span><span>model has the following form:</span></div><div  class = 'S18'><span>ln</span><span>[</span><span>p</span><span>A</span><span>p</span><span>C</span><span>]</span><span>=</span><span>β</span><span>0</span><span>,</span><span>1</span><span>+</span><span>β</span><span>1</span><span>,</span><span>1</span><span>⋅</span><span>X</span><span>(</span><span>1</span><span>)</span><span>+</span><span>β</span><span>2</span><span>,</span><span>1</span><span>⋅</span><span>X</span><span>(</span><span>2</span><span>)</span><span>+</span><span>.</span><span>.</span><span>.</span><span>+</span><span>β</span><span>m</span><span>,</span><span>1</span><span>⋅</span><span>X</span><span>(</span><span>m</span><span>)</span><span>ln</span><span>⁡</span><span>[</span><span>p</span><span>A</span><span>p</span><span>C</span><span>]</span><span>=</span><span>β</span><span>0</span><span>,</span><span>1</span><span>+</span><span>β</span><span>1</span><span>,</span><span>1</span><span>⋅</span><span>X</span><span>(</span><span>1</span><span>)</span><span>+</span><span>β</span><span>2</span><span>,</span><span>1</span><span>⋅</span><span>X</span><span>(</span><span>2</span><span>)</span><span>+</span><span>.</span><span>.</span><span>.</span><span>+</span><span>β</span><span>m</span><span>,</span><span>1</span><span>⋅</span><span>X</span><span>(</span><span>m</span><span>)</span></div><div  class = 'S18'><span>ln</span><span>[</span><span>p</span><span>B</span><span>p</span><span>C</span><span>]</span><span>=</span><span>β</span><span>0</span><span>,</span><span>2</span><span>+</span><span>β</span><span>1</span><span>,</span><span>2</span><span>⋅</span><span>X</span><span>(</span><span>1</span><span>)</span><span>+</span><span>β</span><span>2</span><span>,</span><span>2</span><span>⋅</span><span>X</span><span>(</span><span>2</span><span>)</span><span>+</span><span>.</span><span>.</span><span>.</span><span>+</span><span>β</span><span>m</span><span>,</span><span>2</span><span>⋅</span><span>X</span><span>(</span><span>m</span><span>)</span><span>ln</span><span>⁡</span><span>[</span><span>p</span><span>B</span><span>p</span><span>C</span><span>]</span><span>=</span><span>β</span><span>0</span><span>,</span><span>2</span><span>+</span><span>β</span><span>1</span><span>,</span><span>2</span><span>⋅</span><span>X</span><span>(</span><span>1</span><span>)</span><span>+</span><span>β</span><span>2</span><span>,</span><span>2</span><span>⋅</span><span>X</span><span>(</span><span>2</span><span>)</span><span>+</span><span>.</span><span>.</span><span>.</span><span>+</span><span>β</span><span>m</span><span>,</span><span>2</span><span>⋅</span><span>X</span><span>(</span><span>m</span><span>)</span></div><div  class = 'S5'><span>Please note the following comments regarding this model:</span></div><ol  class = 'S11'><li  class = 'S12'><span>Since</span><span> </span><span>p</span><span>A</span><span>+</span><span>p</span><span>B</span><span>+</span><span>p</span><span>C</span><span>=</span><span>1</span><span>p</span><span>A</span><span>+</span><span>p</span><span>B</span><span>+</span><span>p</span><span>C</span><span>=</span><span>1</span><span>, if we know</span><span> </span><span>ln</span><span>[</span><span>p</span><span>A</span><span>/</span><span>p</span><span>C</span><span>]</span><span>ln</span><span>⁡</span><span>[</span><span>p</span><span>A</span><span>/</span><span>p</span><span>C</span><span>]</span><span> </span><span>and</span><span> </span><span>ln</span><span>[</span><span>p</span><span>B</span><span>/</span><span>p</span><span>C</span><span>]</span><span>ln</span><span>⁡</span><span>[</span><span>p</span><span>B</span><span>/</span><span>p</span><span>C</span><span>]</span><span>, then we can calculate all three probabilities.</span></li><li  class = 'S12'><span>In general, if our reponse variable has</span><span> </span><span>k</span><span>k</span><span> </span><span>classes, then our multinomial logistic regression model will need to consist of</span><span> </span><span>k</span><span>−</span><span>1</span><span>k</span><span>−</span><span>1</span><span> </span><span>equations.</span></li><li  class = 'S12'><span>The expression</span><span> </span><span>p</span><span>A</span><span>/</span><span>p</span><span>C</span><span>p</span><span>A</span><span>/</span><span>p</span><span>C</span><span> </span><span>is referred to as the</span><span> </span><span style=' font-weight: bold;'>relative odds ratio</span><span> </span><span>of A with respect to C. We will denote this expression by</span><span> </span><span>O</span><span>d</span><span>d</span><span>s</span><span>[</span><span>A</span><span>:</span><span>C</span><span>]</span><span>O</span><span>d</span><span>d</span><span>s</span><span>[</span><span>A</span><span>:</span><span>C</span><span>]</span><span>.</span></li></ol><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Defining predictors </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>xtrainNames = {</span><span style="color: rgb(170, 4, 249);">'DNAtype'</span><span>, </span><span style="color: rgb(170, 4, 249);">'SpeciesID'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'Ncodons'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'UUU'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'UUC'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'UUA'</span><span>, </span><span style="color: rgb(170, 4, 249);">'UUG'</span><span>, </span><span style="color: rgb(170, 4, 249);">'CUU'</span><span>, </span><span style="color: rgb(170, 4, 249);">'CUC'</span><span>, </span><span style="color: rgb(170, 4, 249);">'CUA'</span><span>, </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(170, 4, 249);">'CUG'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'AUU'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'AUC'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'AUA'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'AUG'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'GUU'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'GUC'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'GUA'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'GUG'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'GCU'</span><span>,	</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(170, 4, 249);">'GCC'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'GCA'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'GCG'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'CCU'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'CCC'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'CCA'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'CCG'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'UGG'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'GGU'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'GGC'</span><span>,	</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(170, 4, 249);">'GGA'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'GGG'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'UCU'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'UCC'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'UCA'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'UCG'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'AGU'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'AGC'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'ACU'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'ACC'</span><span>,	</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(170, 4, 249);">'ACA'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'ACG'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'UAU'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'UAC'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'CAA'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'CAG'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'AAU'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'AAC'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'UGU'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'UGC'</span><span>,	</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(170, 4, 249);">'CAU'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'CAC'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'AAA'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'AAG'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'CGU'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'CGC'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'CGA'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'CGG'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'AGA'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'AGG'</span><span>,	</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(170, 4, 249);">'GAU'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'GAC'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'GAA'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'GAG'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'UAA'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'UAG'</span><span>,	</span><span style="color: rgb(170, 4, 249);">'UGA'</span><span>};</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>xTrain = trainingData(:, xtrainNames); </span><span style="color: rgb(2, 128, 9);">% Predictors</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>xTrain = table2array(xTrain);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Define output response</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>yTrain = trainingData.Kingdom; </span><span style="color: rgb(2, 128, 9);">% Output</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>thresholdmdl = 0.5; </span><span style="color: rgb(2, 128, 9);">% Define a threshold for classification</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>numSamples = length(yTrain); </span><span style="color: rgb(2, 128, 9);">% Number of samples</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>numBoots = 1; </span><span style="color: rgb(2, 128, 9);">% Number of bootstrap samples</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>mdl_boot  = cell(numBoots,1); </span><span style="color: rgb(2, 128, 9);">% Pre-allocate memory for the resampled fit values</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>predBoot_Mdl1 = zeros(numSamples,1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>[Precision,Recall,Specificity,BM,FPR,FNR,FOR,NPV,FDR,MCC,MK,F1,F2,Accuracy,AUC,</span><span class="warning_squiggle_rte457626237 warningHighlight457626237">Time</span><span>] = deal(zeros(numBoots,1)); </span><span style="color: rgb(2, 128, 9);">% Container for storing performance measure obtained  during the loop</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>Time = zeros(numBoots,1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Resample, iterate and model each instance of the resampled data</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>i = 1:numBoots</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    resampling_ix = ceil(numSamples*rand(1,numSamples));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    resampled_x = xTrain(resampling_ix,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    resampled_y = yTrain(resampling_ix);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%Define the nominal response variable using a categorical array.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    resampled_y_cat = categorical(resampled_y);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    tic </span><span style="color: rgb(2, 128, 9);">% Start recording time</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%mdl_boot{i}</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    B = mnrfit(resampled_x,resampled_y_cat); </span><span style="color: rgb(2, 128, 9);">% Fitting multinomial logistic regression</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">    %%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    prob = mnrval(B,resampled_x);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%predict(B,resampled_x)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%predBoot_Mdl1(:,i) = predict(mdl_boot{i},resampled_x) &gt;= thresholdmdl; % Prediction using the the model built above   </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Calculating measures of performance</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%TP(i) = sum((predBoot_Mdl1(:,i) == 0) &amp; (resampled_y == 0)); % True positive</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%FP(i) = sum((predBoot_Mdl1(:,i) == 1) &amp; (resampled_y == 0)); % False positive</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%FN(i) = sum((predBoot_Mdl1(:,i) == 0) &amp; (resampled_y == 1)); % False negative</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%TN(i) = sum((predBoot_Mdl1(:,i) == 1) &amp; (resampled_y == 1)); % True negative</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%Precision(i) = TP(i)/ (TP(i)+FP(i)); % ratio of correct predictions for the positive class out of total possible positives.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%Recall(i) = TP(i)/ (TP(i)+FN(i)); % ratio of correct positive predictions.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%Specificity(i) = TN(i)/ (FP(i)+TN(i)); % Specificity</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%BM(i) = Recall(i)+Specificity(i)-1; % Bookmaker informedness</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%FPR(i) = FP(i)/ (TN(i)+FP(i)); % False positive rate</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%FNR(i) = FN(i)/ (FN(i)+TP(i)); % False negative rate</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%FOR(i) = FN(i)/ (FN(i)+TN(i)); % False ommission rate</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%NPV(i) = TN(i)/ (TN(i)+FN(i)); % Negative predictor value</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%FDR(i) = FP(i)/ (FP(i)+TP(i)); % False discovery rate</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%MCC(i) = (TP(i)*TN(i)-FP(i)*FN(i))/sqrt((TP(i)+FP(i))*(TP(i)+FN(i))*(TN(i)+FP(i))*(TN(i)+FN(i))); % Matthews correlation coefficient</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%MK(i) = Precision(i)+NPV(i)-1; % Markedness </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%F1(i) = (2*Precision(i)*Recall(i))/ (Precision(i)+Recall(i)); % average (weighted) Precision and Recall.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%F2(i) = (5*Precision(i)*Recall(i)/ ((4*Precision(i)) + Recall(i))); % similar to F1 but less weight on Precision, more weight on Recall.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%Accuracy(i) = (TP(i)+TN(i))./(TP(i)+FP(i)+TN(i)+FN(i))*100; % Accuracy</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%scores = mdl_boot{i}.Fitted.Probability;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%[X,Y,T,AUC(i)] = perfcurve(resampled_y,scores,'1');</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%AUC(i); % Area under the curve</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    Time(i) = toc; </span><span style="color: rgb(2, 128, 9);">% End recording time</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>X_train = table2array(X_train);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Define output response</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>y_train = trainingData.Kingdom; </span><span style="color: rgb(2, 128, 9);">% Output</span></span></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>figure</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>plot(X_train(:,2),X_train(:,3),</span><span style="color: rgb(170, 4, 249);">'o'</span><span>)</span></span></div></div></div><div  class = 'S5'><span>First we will define a 5-fold cross validation using a constant value for the LR alpha parameter and we will compare the metrics using SSMOTE to </span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Define 5 as number of folds</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>K=5;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>rng(1, </span><span style="color: rgb(170, 4, 249);">'twister'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Change classes to numerical data</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_train_num = renamecats(y_train,{</span><span style="color: rgb(170, 4, 249);">'arc'</span><span>,</span><span style="color: rgb(170, 4, 249);">'bct'</span><span>,</span><span style="color: rgb(170, 4, 249);">'euk'</span><span>},{</span><span style="color: rgb(170, 4, 249);">'1'</span><span>,</span><span style="color: rgb(170, 4, 249);">'2'</span><span>,</span><span style="color: rgb(170, 4, 249);">'3'</span><span>});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_train_num = str2double(string(y_train_num));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%y_train_n = grp2idx(y_train);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>indices=crossvalind(</span><span style="color: rgb(170, 4, 249);">'Kfold'</span><span>,y_train_num,K);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>[</span><span class="warning_squiggle_rte457626237">TP</span><span>] = deal(zeros(K,1)); </span><span style="color: rgb(2, 128, 9);">% Container for storing each fold performance measure obtained  during the loop</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Initialize variables</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>m = size(X_train, 2); </span><span style="color: rgb(2, 128, 9);">% number of columns</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>numLabels = size(unique(y_train),1); </span><span style="color: rgb(2, 128, 9);">% number of labels</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>theta = zeros(numLabels,m+1,K);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%figure;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%res = [1024 768]; %set desired [horizontal vertical] resolution</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%set(gcf,'PaperPosition',[0 0 res]*2.54); %set paper size (does not affect display)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%set(gcf,'units','normalized','outerposition',[0 0 1 1]);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Variable to store each fold time and total/avg time metrics</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%fTime = </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>i_fold=1:K</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Evaluate time for each fold iteration</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Assigning training and validation set indexes</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    val = (indices == i_fold);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    train = ~val;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Training set</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    Xf_train = X_train(train,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    yf_train = y_train_num(train);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Validation set</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    Xf_val = X_train(val,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    yf_val = y_train_num(val);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>   </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    lambda = 10; </span><span style="color: rgb(2, 128, 9);">% regularization parameter</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%numLabels = size(unique(y_train_num),1); % number of labels</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Training</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>     </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%disp(b)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">    %% Training Multinomial Logistic Regression classifier</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    fprintf(</span><span style="color: rgb(170, 4, 249);">'Training Multinomial Logistic Regression'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    Xf_train_scaled = normalize(Xf_train);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    Xf_val_scaled = normalize(Xf_val);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    theta_temp = LRTraining(Xf_train_scaled, yf_train, numLabels, lambda);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    theta(:,:,i_fold) = theta_temp;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%[W, b] = LRTrain(Xf_train_scaled, yf_train, lambda, numLabels);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Validation</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">    %% Prediction </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%[preds] = LRPrediction(Xf_val_scaled, yf_val, W, b);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    predicted_y = LRPredict(theta_temp, Xf_val_scaled);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    proba = LRPredictProba(theta_temp, Xf_val_scaled);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Add ones to the X data matrix (x0)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%Xf = [ones(size(Xf_val_scaled, 1), 1) Xf_val_scaled];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%pihat = sigmoid(Xf * theta_temp');</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%subplot(3,2,i_fold);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%cm = confusionchart(yf_val,predicted_y);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    lr_stats = confusionMatStats(confusionmat(yf_val, predicted_y));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%(ifold)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%m = size(Xf_val(:,3:end), 1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%Xf_val_scaled = [ones(m, 1) normalize(table2array(Xf_val(:,3:end)))];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%diffscore=zeros;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%for i=1:size(proba,1)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%    temp=proba(i,:); % a row vector holding the scores for the classes [A, B, C, D] for the ith observation out of the total.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%    % score of +ve class minus the maximum of the scores of all the negative classes (similar to the example available via the webpage link) </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%    diffscore(i,:)=temp(2)-max([temp(1),temp(3)]); </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%[X_perf,Y_perf,T,~,OPTROCPT,suby,subnames] = perfcurve(yf_val,diffscore,2); % predicted_y: True class labels</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>   </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    clear </span><span style="color: rgb(170, 4, 249);">plt_roc</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    clear </span><span style="color: rgb(170, 4, 249);">plt_prc</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    figure;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    figure.position = [100 100 540 400];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">if </span><span>(~exist(</span><span style="color: rgb(170, 4, 249);">'plt_roc'</span><span>, </span><span style="color: rgb(170, 4, 249);">'var'</span><span>) || ~exist(</span><span style="color: rgb(170, 4, 249);">'plt_prc'</span><span>, </span><span style="color: rgb(170, 4, 249);">'var'</span><span>))</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        plt_roc = plot([],[],</span><span style="color: rgb(170, 4, 249);">'-'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        plt_prc = plot([],[],</span><span style="color: rgb(170, 4, 249);">'-'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    hold </span><span style="color: rgb(170, 4, 249);">on</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">for </span><span>i=1:size(proba,2)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        tgt=-ones(1,length(yf_val));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        positive_class=find(yf_val==i);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        tgt(</span><span class="warning_squiggle_rte457626237 warningHighlight457626237">positive_class</span><span>)=1;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(2, 128, 9);">%[xr, yr, ~, auc(i)] = perfcurve(yf_val,proba(:, i), i);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(2, 128, 9);">%plot(xr, yr, 'linewidth', 1)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span class="warning_squiggle_rte457626237">legends_auc</span><span>{i} = sprintf(</span><span style="color: rgb(170, 4, 249);">'AUC for %s class'</span><span>, codon_classes{i});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">        %% Plot ROCs</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        plt_roc = compute_prc_roc(tgt,proba(:, i)',</span><span style="color: rgb(170, 4, 249);">"ROC"</span><span>,codon_classes{i},i,i_fold,legends_auc,plt_roc);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    hold </span><span style="color: rgb(170, 4, 249);">off</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    figure</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    hold </span><span style="color: rgb(170, 4, 249);">on</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">for </span><span>i=1:size(proba,2)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        tgt=-ones(1,length(yf_val));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        positive_class=find(yf_val==i);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        tgt(</span><span class="warning_squiggle_rte457626237 warningHighlight457626237">positive_class</span><span>)=1;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span class="warning_squiggle_rte457626237">legends_prc</span><span>{i} = sprintf(</span><span style="color: rgb(170, 4, 249);">'PRC for %s class'</span><span>, codon_classes{i});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">        %% Plot PRCs</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        plt_prc = compute_prc_roc(tgt,proba(:, i)',</span><span style="color: rgb(170, 4, 249);">"PRC"</span><span>,codon_classes{i},i,i_fold,legends_prc,plt_prc);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    hold </span><span style="color: rgb(170, 4, 249);">off</span><span>;            </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%if i==1 %if is the first fold </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%    mean_curve= (interp1(x_adj, Yroc, intervals))/k; </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%else</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%    mean_curve= mean_curve+ (interp1(x_adj, Yroc, intervals))/k; </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%y_hat = mnrval(b,test_x,stats,'interactions','off','type','cumulative','model','ordinal','link','logit');</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%ccdf_yfit=1-y_hat;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%class1 = ccdf_yfit &gt; 0.5;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">    %%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%prob = mnrval(B,resampled_x);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%predict(B,resampled_x)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%predBoot_Mdl1(:,   i) = predict(mdl_boot{i},resampled_x) &gt;= thresholdmdl; % Prediction using the the model built above   </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Calculating measures of performance</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span> </span></span></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>   </span><span style="color: rgb(2, 128, 9);">%TP(i) = sum((pihat(:,i) == 0) &amp; (yf_val_n == 0)); % True positive</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%FP(i) = sum((pihat(:,i) == 1) &amp; (resampled_y == 0)); % False positive</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%FN(i) = sum((pihat(:,i) == 0) &amp; (resampled_y == 1)); % False negative</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%TN(i) = sum((pihat(:,i) == 1) &amp; (resampled_y == 1)); % True negative</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%Precision(i) = TP(i)/ (TP(i)+FP(i)); % ratio of correct predictions for the positive class out of total possible positives.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%Recall(i) = TP(i)/ (TP(i)+FN(i)); % ratio of correct positive predictions.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%Specificity(i) = TN(i)/ (FP(i)+TN(i)); % Specificity</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'></div></div></div><h2  class = 'S4' id = 'H_28117777' ><span>5.3 Using SMOTE for minority class and undersampling of majority class</span></h2><div  class = 'S5'><span></span></div><div  class = 'S5'><span>In our training set if we consider that the proportion between the minority class (arc) and the majority class (euk) has a ratio of approx. 1:50 one can argue  that a oversampling technique alone might not be the best strategy and could be harmful depending on the numer of new samples generated. Therefore we would propose a two-step approach where we can update to first oversample the minority class to have X percent the number of examples of the majority class and then use random undersampling to reduce the number of examples in the majority class to have Y percent more than the minority class, which is considered a safer proportion.</span></div><div  class = 'S5'><span>Thus starting from 1:50 ratio we can increase the minority class 7 times to be at 10 percent of the majority class (with an approx. of 700% increase) and then undersample the majority class to half of the sample size as to reduce the imbalance to appromately 1:3.  </span></div><div  class = 'S5'><span>In the literature SafeLevelSMOTE algorithm performed better than other algorithms such as SMOTE and Borderline SMOTE for a class of problems. Based on that assumption we decided to implement this method for our problem given that our variables could have a degree of dependence between them and a safe margin of synthetic data generation </span></div><h3  class = 'S6' id = 'H_D1D04370' ><span>5.3.1 Validation of class proportions</span></h3><div  class = 'S5'><span>Checking again umber of data for each class before applying the algorithm</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Create table with X_train dataset appended with label data</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_train_label = addvars(array2table(X_train), string(y_train),</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(170, 4, 249);">'NewVariableNames'</span><span>,</span><span style="color: rgb(170, 4, 249);">'label'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>t = tabulate(X_train_label.label);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>uniqueLabels = string(t(:,1));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>labelCounts = cell2mat(t(:,2));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>tbl = tabulate(X_train_label.label);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>tabulate(X_train_label.label)</span></span></div></div></div><div  class = 'S5'><span>Find ratio between minority and majority classes.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>t_ratio_class = array2table(tbl,</span><span style="color: rgb(170, 4, 249);">'VariableNames'</span><span>, </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    {</span><span style="color: rgb(170, 4, 249);">'Value'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Count'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Percent'</span><span>});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Divide minority class by the majority to find the ratio between them</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>cell2mat(table2array(t_ratio_class(1,2))) / cell2mat(table2array(t_ratio_class(3,2)))</span></span></div></div></div><div  class = 'S10'><span>The result above represents the ratio between the classes is approx 1:50 (0.02).</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'><span style="white-space: pre;"><span>(101+505)/(5530/3)</span></span></div></div></div><h3  class = 'S14' id = 'H_ED2B39E9' ><span>5.3.2 Applying SafeLevelSMOTE to class 1 (arc)</span></h3><h4  class = 'S13' id = 'H_8A53F44B' ><span>Applying SafeLevelSMOTE</span></h4><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Define the number of neighbours (k = 10) to use as one of the parameters in the comparison</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% and proportion of increase (5 times)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>k = 10;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>prop_increase = 5;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Define number of samples to add for minority class</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>smote_samples = cell2mat(table2array(t_ratio_class(1,2))) * prop_increase;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% We define samples for minority class and 0 for the other classes</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>num2Add = [smote_samples,0,0];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>newdata = table;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>visdataset = cell(length(uniqueLabels),1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Define for each class</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>ii=1:length(uniqueLabels)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    [tmp,visdata] = SafeLevelSMOTE(X_train_label,uniqueLabels(ii),num2Add(ii),</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                </span><span style="color: rgb(170, 4, 249);">"NumNeighbors"</span><span>,k, </span><span style="color: rgb(170, 4, 249);">"Standardize"</span><span>, false);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span class="warning_squiggle_rte457626237">newdata</span><span> = [newdata; tmp];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    visdataset{ii} = visdata;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Finally we save the added samples to an array (removing the last column)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>smote_class1 = table2array(newdata(:,1:end-1));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_train_raw_2 = X_train;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Finally we save the added samples to an array (removing the last column</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_train = [X_train ; smote_class1];</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>y_train = [y_train; categorical(table2array(newdata(:,end)))];</span></span></div></div></div><h3  class = 'S14' id = 'H_6B75D645' ><span>5.3.3 Random undersampling of majority class (Class 3 (euk))</span></h3><div  class = 'S5'><span>Now we address class-related data imbalance by undersampling the majority (euk) class and reducing X_train size as well.
</span></div><div  class = 'S5'><span>First we should calculate the number of samples that should be removed from the majority class to find a 1:3 ratio between minority and majority classes.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>X_train_label = addvars(array2table(X_train), string(y_train),</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(170, 4, 249);">'NewVariableNames'</span><span>,</span><span style="color: rgb(170, 4, 249);">'label'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>tbl = tabulate(X_train_label.label);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>t_ratio_class = array2table(tbl,</span><span style="color: rgb(170, 4, 249);">'VariableNames'</span><span>, </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    {</span><span style="color: rgb(170, 4, 249);">'Value'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Count'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Percent'</span><span>});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Divide minority class by the majority to find the ratio between them</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>ratio_min_max = cell2mat(table2array(t_ratio_class(1,2))) / cell2mat(table2array(t_ratio_class(3,2)))</span></span></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'><span style="white-space: pre;"><span>under_samples = round(cell2mat(table2array(t_ratio_class(1,2))) / 0.33,0)</span></span></div></div></div><div  class = 'S10'><span>Given that k_samples is approx 1984 then we should remove (5530 - 1985) samples =  3545 from the majority class.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'><span style="white-space: pre;"><span>samples_num = cell2mat(table2array(t_ratio_class(3,2))) - under_samples</span></span></div></div></div><div  class = 'S5'><span>However instead of removing samples we will create a new dataset with 1985 samples randomly selected without replacement from the 5530 original samples from the majority class.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Input an imbalanced data and number of samples</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% For reproducibility</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>rng(1,</span><span style="color: rgb(170, 4, 249);">'twister'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Create arrays for sampling purposes</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>x_rus = table2array(X_train_label);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_rus = x_rus(:,end);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Filter between majority class and the other 2 classes</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_maj = x_rus(</span><span class="warning_squiggle_rte457626237 warningHighlight457626237">find</span><span>(y_rus == </span><span style="color: rgb(170, 4, 249);">"euk"</span><span>),:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_rest = x_rus(</span><span class="warning_squiggle_rte457626237 warningHighlight457626237">find</span><span>(y_rus == </span><span style="color: rgb(170, 4, 249);">"arc" </span><span>| y_rus == </span><span style="color: rgb(170, 4, 249);">"bct"</span><span>),:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Generate random indexes for random undersampling</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>rp = randperm(size(X_maj,1));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>random_sample = rp(1:under_samples);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_rand_maj = X_maj(random_sample,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_train_final = [str2double(X_rand_maj(:,1:end-1))  ; str2double(X_rest(:,1:end-1))];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_train_final = [X_rand_maj(:,end) ; X_rest(:,end)];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%for i = 1 : 10</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Select indexes randomly to be removed</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%    out1 = randperm(size(r,1),p);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Include indexes randomly selected in the previous step</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%    out1 = r(out1,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%    randSamp = [out1];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%    random_sample{i, :} = randSamp(randperm(size(randSamp, 1)), :); </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><h3  class = 'S14' id = 'H_9D93B27D' ><span>5.3.4 Validate new dataset</span></h3><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>X_train_label = addvars(array2table(X_train_final(:,1:end-1)), string(y_train_final),</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(170, 4, 249);">'NewVariableNames'</span><span>,</span><span style="color: rgb(170, 4, 249);">'label'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%uniqueLabels = string(t(:,1));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%labelCounts = cell2mat(t(:,2));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%tbl = tabulate(X_train_label.label);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>tabulate(X_train_label.label)</span></span></div></div></div><div  class = 'S10'><span></span></div><h4  class = 'S19' id = 'H_45DA9F37' ><span>3</span></h4><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_train_label_t = addvars(array2table(X_train(:,1:end-1)), string(y_train),</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(170, 4, 249);">'NewVariableNames'</span><span>,</span><span style="color: rgb(170, 4, 249);">'label'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%uniqueLabels = string(t(:,1));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%labelCounts = cell2mat(t(:,2));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%tbl = tabulate(X_train_label.label);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>tabulate(X_train_label_t.label)</span></span></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Appending performance measures to a table</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>LR_MaleMdlPerformance = table(Precision,Recall,Specificity, BM, FPR, FNR, FOR, NPV, FDR, MCC, MK, F1, F2, Accuracy,AUC,Time,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(170, 4, 249);">'RowNames'</span><span>,{</span><span style="color: rgb(170, 4, 249);">'Model 1' 'Model 2' 'Model 3' 'Model 4' 'Model 5' 'Model 6' 'Model 7' 'Model 8' 'Model 9' 'Model 10' </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                </span><span style="color: rgb(170, 4, 249);">'Model 11' 'Model 12' 'Model 13' 'Model 14' 'Model 15' 'Model 16' 'Model 17' 'Model 18' 'Model 19' 'Model 20' </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>                </span><span style="color: rgb(170, 4, 249);">'Model 21' 'Model 22' 'Model 23' 'Model 24' 'Model 25' 'Model 26' 'Model 27' 'Model 28' 'Model 29' 'Model 30'</span><span>})</span></span></div></div></div><div  class = 'S10'><span>prediction = predict(theta, X1Test(:,129:131));</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Define 5 as number of folds</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>K=5;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>rng(1, </span><span style="color: rgb(170, 4, 249);">'twister'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Change classes to numerical data</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_train_num = renamecats(categorical(y_train),{</span><span style="color: rgb(170, 4, 249);">'arc'</span><span>,</span><span style="color: rgb(170, 4, 249);">'bct'</span><span>,</span><span style="color: rgb(170, 4, 249);">'euk'</span><span>},{</span><span style="color: rgb(170, 4, 249);">'1'</span><span>,</span><span style="color: rgb(170, 4, 249);">'2'</span><span>,</span><span style="color: rgb(170, 4, 249);">'3'</span><span>});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_train_num = str2double(string(y_train_num));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%y_train_n = grp2idx(y_train);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>indices=crossvalind(</span><span style="color: rgb(170, 4, 249);">'Kfold'</span><span>,y_train_num,K);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>[</span><span class="warning_squiggle_rte457626237">TP</span><span>] = deal(zeros(K,1)); </span><span style="color: rgb(2, 128, 9);">% Container for storing each fold performance measure obtained  during the loop</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Initialize variables</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>m = size(X_train, 2); </span><span style="color: rgb(2, 128, 9);">% number of columns</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>numLabels = size(unique(y_train),1); </span><span style="color: rgb(2, 128, 9);">% number of labels</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span class="warning_squiggle_rte457626237">theta</span><span> = zeros(numLabels,m+1,K);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Variable to store each fold time and total/avg time metrics</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%fTime = </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>i_fold=1:K</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Evaluate time for each fold iteration</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Assigning training and validation set indexes</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    val = (indices == i_fold);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    train = ~val;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Training set</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    Xf_train = X_train(train,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    yf_train = y_train_num(train);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Validation set</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    Xf_val = X_train(val,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    yf_val = y_train_num(val);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>   </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    lambda = 10; </span><span style="color: rgb(2, 128, 9);">% regularization parameter</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%numLabels = size(unique(y_train_num),1); % number of labels</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Training</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% No oversampling/undersampling </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%Xf_train_balanced = Xf_train;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%yf_train_balanced = y_train(train);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Apply SMOTE/Undersampling</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%[Xf_train_balanced, yf_train_balanced] = smote_and_undersampling(Xf_train, y_train(train), 3, 0.8,"smote_undersampling");</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Apply SMOTE only (300 % more synthetic samples)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    [Xf_train_balanced, yf_train_balanced] = smote_and_undersampling(Xf_train, y_train(train), 3, 0,</span><span style="color: rgb(170, 4, 249);">"smote"</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Normalise dataset</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    Xf_train_scaled = normalize(Xf_train_balanced);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Change classes to numerical data</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    yf_train_num = renamecats(categorical(yf_train_balanced),{</span><span style="color: rgb(170, 4, 249);">'arc'</span><span>,</span><span style="color: rgb(170, 4, 249);">'bct'</span><span>,</span><span style="color: rgb(170, 4, 249);">'euk'</span><span>},{</span><span style="color: rgb(170, 4, 249);">'1'</span><span>,</span><span style="color: rgb(170, 4, 249);">'2'</span><span>,</span><span style="color: rgb(170, 4, 249);">'3'</span><span>});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    yf_train_num = str2double(string(yf_train_num));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">    %% Training Multinomial Logistic Regression classifier</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    fprintf(</span><span style="color: rgb(170, 4, 249);">'Training Multinomial Logistic Regression'</span><span>);    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%theta_temp = LRTraining(Xf_train_scaled, yf_train_num, numLabels, lambda);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%theta(:,:,i_fold) = theta_temp;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%Mdl = fitcecoc(X,Y,'OptimizeHyperparameters','auto',...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%'HyperparameterOptimizationOptions',struct('AcquisitionFunctionName',...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%'expected-improvement-plus'))  </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    t=templateLinear(</span><span style="color: rgb(170, 4, 249);">'Regularization'</span><span>,</span><span style="color: rgb(170, 4, 249);">'ridge'</span><span>, </span><span style="color: rgb(170, 4, 249);">'Lambda'</span><span>, 0.1,</span><span style="color: rgb(170, 4, 249);">'Learner'</span><span>,</span><span style="color: rgb(170, 4, 249);">'logistic'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Solver'</span><span>,</span><span style="color: rgb(170, 4, 249);">'lbfgs'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    LR_model=fitcecoc(Xf_train_scaled,yf_train_num,</span><span style="color: rgb(170, 4, 249);">'Learners'</span><span>,t);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">    %% Prediction </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%[preds] = LRPrediction(Xf_val_scaled, yf_val, W, b);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    Xf_val_scaled = normalize(Xf_val);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Predict class values and calculate probability of each class</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%predicted_y = LRPredict(theta_temp, Xf_val_scaled);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%proba = LRPredictProba(theta_temp, Xf_val_scaled);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    [predicted_y </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">scores</span><span>] = predict(LR_model,Xf_val_scaled);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%cm = confusionchart(yf_val,predicted_y);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    weight_classes = [sum(yf_val==1)/length(yf_val);sum(yf_val==2)/length(yf_val);</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                  sum(yf_val==3)/length(yf_val)];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    lr_val_stats = confusionMatStats(yf_val, predicted_y, weight_classes);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%(ifold)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%m = size(Xf_val(:,3:end), 1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%Xf_val_scaled = [ones(m, 1) normalize(table2array(Xf_val(:,3:end)))];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%diffscore=zeros;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">for </span><span>i=1:size(proba,1)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(2, 128, 9);">% a row vector holding the scores for the classes [A, B, C, D] for the ith observation out of the total.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(2, 128, 9);">%temp=scores(i,:); </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%    % score of +ve class minus the maximum of the scores of all the negative classes (similar to the example available via the webpage link) </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%    diffscore(i,:)=temp(2)-max([temp(1),temp(3)]); </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">if </span><span>i==1</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            diffscore = scores(:,1) - max(scores(:,2),scores(:,3));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">elseif </span><span>i==2</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            diffscore = scores(:,2) - max(scores(:,1),scores(:,3));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">else</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            diffscore = scores(:,3) - max(scores(:,1),scores(:,2));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">if </span><span>i == 1</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            [X,Y,T,~,OPTROCPT,</span><span class="warning_squiggle_rte457626237 warningHighlight457626237">suby</span><span>,subnames] = perfcurve(yf_val,diffscore,i);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            plot(X,Y)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            hold </span><span style="color: rgb(170, 4, 249);">on</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            plot(OPTROCPT(1),OPTROCPT(2),</span><span style="color: rgb(170, 4, 249);">'ro'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            xlabel(</span><span style="color: rgb(170, 4, 249);">'False positive rate'</span><span>) </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            ylabel(</span><span style="color: rgb(170, 4, 249);">'True positive rate'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            title(</span><span style="color: rgb(170, 4, 249);">'ROC Curve for Classification by Classification Trees'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            hold </span><span style="color: rgb(170, 4, 249);">off</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">else</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span><span style="color: rgb(2, 128, 9);">%plot(suby(:,i),X)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%hold off;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%[X_perf,Y_perf,T,~,OPTROCPT,suby,subnames] = perfcurve(yf_val,diffscore,2); % predicted_y: True class labels</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%if i==1 %if is the first fold </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%    mean_curve= (interp1(x_adj, Yroc, intervals))/k; </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%else</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%    mean_curve= mean_curve+ (interp1(x_adj, Yroc, intervals))/k; </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">if </span><span>i_fold == 1</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(2, 128, 9);">% Save results of performance to a table of measures</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span>    </span><span>LR_BaselinePerf = table(i_fold, {lr_val_stats.precision},{lr_val_stats.recall},{lr_val_stats.specificity}, </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            {lr_val_stats.tp}, {lr_val_stats.tn}, {lr_val_stats.fp}, {lr_val_stats.fn}, </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>             lr_val_stats.Fscore_macro, lr_val_stats.Fscore_micro,lr_val_stats.accuracy, </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>             lr_val_stats.balanced_accuracy,lr_val_stats.weighted_balanced_accuracy);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(2, 128, 9);">% Modify variable names</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        LR_BaselinePerf.Properties.VariableNames = {</span><span style="color: rgb(170, 4, 249);">'Fold_number' 'Precision' 'Recall' 'Specificity' </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>          </span><span style="color: rgb(170, 4, 249);">'TP' 'TN' 'FP' 'FN' 'FScore_Macro' 'FScore_Micro' 'Accuracy' 'Balanced_Accuracy' </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>          </span><span style="color: rgb(170, 4, 249);">'Weighted_Balanced_Accuracy'</span><span>};</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">else</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span class="warning_squiggle_rte457626237">LR_BaselinePerf</span><span> = [LR_BaselinePerf ; {i_fold, {lr_val_stats.precision},{lr_val_stats.recall},{lr_val_stats.specificity}, </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        {lr_val_stats.tp}, {lr_val_stats.tn}, {lr_val_stats.fp}, {lr_val_stats.fn}, </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>         lr_val_stats.Fscore_macro, lr_val_stats.Fscore_micro,lr_val_stats.accuracy, </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>         lr_val_stats.balanced_accuracy,lr_val_stats.weighted_balanced_accuracy}];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper outputs"><div  class = 'S20'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div><div  class = 'S21'><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="C29974F4" data-testid="output_0" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">Training Multinomial Logistic Regression</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="97A6D7E7" data-testid="output_1" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">test</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="2B3CD0F9" data-testid="output_2" data-width="813" data-height="17" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">Training Multinomial Logistic Regression</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="F3CB01E2" data-testid="output_3" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">test</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="BEE81E18" data-testid="output_4" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">Training Multinomial Logistic Regression</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="FF2FDD66" data-testid="output_5" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">test</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="7E5BF873" data-testid="output_6" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">Training Multinomial Logistic Regression</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="6C69535C" data-testid="output_7" data-width="813" data-height="17" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">test</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="1B831228" data-testid="output_8" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">Training Multinomial Logistic Regression</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="C3D60CDD" data-testid="output_9" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">test</div></div></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%lr_precision={lr_val_stats.precision};</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>LR_BaselinePerf = table(i_fold, {lr_val_stats.precision},</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    {</span><span style="color: rgb(170, 4, 249);">'Fold_number' 'Precision'</span><span>});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Visualising in 4D the performance of above model using scatter3 and stacked plot</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>figure</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>scatter3(LR_MdlPerformance.Precision, LR_MdlPerformance.Recall, LR_MdlPerformance.Specificity, 100, LR_MdlPerformance.Accuracy, </span><span style="color: rgb(170, 4, 249);">'filled'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>set(gca,</span><span style="color: rgb(170, 4, 249);">'color'</span><span>,</span><span style="color: rgb(170, 4, 249);">"#ecf0f1"</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>title(</span><span style="color: rgb(170, 4, 249);">'Performance measures of 30 logistic regression models'</span><span>, </span><span style="color: rgb(170, 4, 249);">'FontSize'</span><span>, 20)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>xlabel(</span><span style="color: rgb(170, 4, 249);">'Precision'</span><span>, </span><span style="color: rgb(170, 4, 249);">'FontSize'</span><span>, 20)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>ylabel(</span><span style="color: rgb(170, 4, 249);">'Recall'</span><span>, </span><span style="color: rgb(170, 4, 249);">'FontSize'</span><span>, 20)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>zlabel(</span><span style="color: rgb(170, 4, 249);">'Specificity'</span><span>, </span><span style="color: rgb(170, 4, 249);">'FontSize'</span><span>, 20)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>colormap(jet)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>hcb = colorbar(</span><span style="color: rgb(170, 4, 249);">'Location'</span><span>, </span><span style="color: rgb(170, 4, 249);">'EastOutside'</span><span>, </span><span style="color: rgb(170, 4, 249);">'FontSize'</span><span>, 20);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>hcb.Title.String = </span><span style="color: rgb(170, 4, 249);">"Accuracy"</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>xplot = </span><span class="warning_squiggle_rte457626237">[</span><span>0:1:29]; </span><span style="color: rgb(2, 128, 9);">% stacked plot to visualise the remainder measures of performance to aid selecting the best performing model</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>stackedplot(LR_MdlPerformance,[</span><span style="color: rgb(170, 4, 249);">"BM"</span><span>,</span><span style="color: rgb(170, 4, 249);">"FPR"</span><span>,</span><span style="color: rgb(170, 4, 249);">"FNR"</span><span>,</span><span style="color: rgb(170, 4, 249);">"FOR"</span><span>,</span><span style="color: rgb(170, 4, 249);">"NPV"</span><span>,</span><span style="color: rgb(170, 4, 249);">"FDR"</span><span>,</span><span style="color: rgb(170, 4, 249);">"MCC"</span><span>,</span><span style="color: rgb(170, 4, 249);">"MK"</span><span>,</span><span style="color: rgb(170, 4, 249);">"F1"</span><span>,</span><span style="color: rgb(170, 4, 249);">"F2"</span><span>,</span><span style="color: rgb(170, 4, 249);">"AUC"</span><span>,</span><span style="color: rgb(170, 4, 249);">"Time"</span><span>]);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><h2  class = 'S15' id = 'H_E451C2B5' ><span style=' font-family: monospace;'>5.4 Regularization and best model selection</span></h2><div  class = 'S5'><span style=' font-family: monospace;'> </span></div><div  class = 'S5'><span style=' font-family: monospace;'>%</span><span style=' font-family: monospace;'>  In this part, you will get to try different values of lambda and</span></div><div  class = 'S5'><span style=' font-family: monospace;'>%</span><span style=' font-family: monospace;'>  see how regularization affects the decision coundart</span></div><div  class = 'S5'><span style=' font-family: monospace;'> </span></div><div  class = 'S5'><span style=' font-family: monospace;'>%</span><span style=' font-family: monospace;'>  We will try the following values of lambda (0, 0.1, 1, 10, 100).</span></div><div  class = 'S5'><span style=' font-family: monospace;'> and investigate how does the decision boundary change when we vary lambda and how does</span></div><div  class = 'S5'><span style=' font-family: monospace;'> the metrics vary. We will also test with differents values of solver ('quasi-newton' and ' marquart'</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'><span style="white-space: pre;"><span>find(yf_val==3)</span></span></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span> </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Define 5 as number of folds</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>K=5;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>rng(1, </span><span style="color: rgb(170, 4, 249);">'twister'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Change classes to numerical data</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_train_num = renamecats(categorical(y_train),{</span><span style="color: rgb(170, 4, 249);">'arc'</span><span>,</span><span style="color: rgb(170, 4, 249);">'bct'</span><span>,</span><span style="color: rgb(170, 4, 249);">'euk'</span><span>},{</span><span style="color: rgb(170, 4, 249);">'1'</span><span>,</span><span style="color: rgb(170, 4, 249);">'2'</span><span>,</span><span style="color: rgb(170, 4, 249);">'3'</span><span>});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_train_num = str2double(string(y_train_num));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%y_train_n = grp2idx(y_train);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>indices=crossvalind(</span><span style="color: rgb(170, 4, 249);">'Kfold'</span><span>,y_train_num,K);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>[TP] = deal(zeros(K,1)); </span><span style="color: rgb(2, 128, 9);">% Container for storing each fold performance measure obtained  during the loop</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Initialize variables</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>m = size(X_train, 2); </span><span style="color: rgb(2, 128, 9);">% number of columns</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>numLabels = size(unique(y_train),1); </span><span style="color: rgb(2, 128, 9);">% number of labels</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>theta = zeros(numLabels,m+1,K);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>alpha_values = [0.1, 1, 10, 10];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>solver_values = [</span><span style="color: rgb(170, 4, 249);">'quasi-newton'</span><span>,</span><span style="color: rgb(170, 4, 249);">''</span><span>]</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>i_fold=1:K</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Evaluate time for each fold iteration</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Assigning training and validation set indexes</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    val = (indices == i_fold);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    train = ~val;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Training set</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    Xf_train = X_train(train,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    yf_train = y_train_num(train);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Validation set</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    Xf_val = X_train(val,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    yf_val = y_train_num(val);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>   </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    lambda = 10; </span><span style="color: rgb(2, 128, 9);">% regularization parameter</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%numLabels = size(unique(y_train_num),1); % number of labels</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Trainin</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% No oversampling/undersampling </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%Xf_train_balanced = Xf_train;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%yf_train_balanced = y_train(train);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Apply SMOTE/Undersampling</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%[Xf_train_balanced, yf_train_balanced] = smote_and_undersampling(Xf_train, y_train(train), 3, 0.8,"smote_undersampling");</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Apply SMOTE only (300 % more synthetic samples)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    [Xf_train_balanced, yf_train_balanced] = smote_and_undersampling(Xf_train, y_train(train), 3, 0,</span><span style="color: rgb(170, 4, 249);">"smote"</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Normalise dataset</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    Xf_train_scaled = normalize(Xf_train_balanced);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Change classes to numerical data</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    yf_train_num = renamecats(categorical(yf_train_balanced),{</span><span style="color: rgb(170, 4, 249);">'arc'</span><span>,</span><span style="color: rgb(170, 4, 249);">'bct'</span><span>,</span><span style="color: rgb(170, 4, 249);">'euk'</span><span>},{</span><span style="color: rgb(170, 4, 249);">'1'</span><span>,</span><span style="color: rgb(170, 4, 249);">'2'</span><span>,</span><span style="color: rgb(170, 4, 249);">'3'</span><span>});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    yf_train_num = str2double(string(yf_train_num));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">    %% Training Multinomial Logistic Regression classifier</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    fprintf(</span><span style="color: rgb(170, 4, 249);">'Training Multinomial Logistic Regression'</span><span>);    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    theta_temp = LRTraining(Xf_train_scaled, yf_train_num, numLabels, lambda);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    theta(:,:,i_fold) = theta_temp;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%[W, b] = LRTrain(Xf_train_scaled, yf_train, lambda, numLabels);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">    %% Prediction </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%[preds] = LRPrediction(Xf_val_scaled, yf_val, W, b);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    Xf_val_scaled = normalize(Xf_val);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Using MLR</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    predicted_y = LRPredict(theta_temp, Xf_val_scaled);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    proba = LRPredictProba(theta_temp, Xf_val_scaled);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Add ones to the X data matrix (x0)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%Xf = [ones(size(Xf_val_scaled, 1), 1) Xf_val_scaled];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%pihat = sigmoid(Xf * theta_temp');</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%cm = confusionchart(yf_val,predicted_y);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    lr_stats = confusionmatStats(confusionmat(yf_val, predicted_y),</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        [sum(yf_val==1) sum(yf_val==2) sum(yf_val==3)]);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%(ifold)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%m = size(Xf_val(:,3:end), 1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%Xf_val_scaled = [ones(m, 1) normalize(table2array(Xf_val(:,3:end)))];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%diffscore=zeros;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%for i=1:size(proba,1)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%    temp=proba(i,:); % a row vector holding the scores for the classes [A, B, C, D] for the ith observation out of the total.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%    % score of +ve class minus the maximum of the scores of all the negative classes (similar to the example available via the webpage link) </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%    diffscore(i,:)=temp(2)-max([temp(1),temp(3)]); </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%[X_perf,Y_perf,T,~,OPTROCPT,suby,subnames] = perfcurve(yf_val,diffscore,2); % predicted_y: True class labels</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%if i==1 %if is the first fold </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%    mean_curve= (interp1(x_adj, Yroc, intervals))/k; </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%else</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%    mean_curve= mean_curve+ (interp1(x_adj, Yroc, intervals))/k; </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><h2  class = 'S15' id = 'H_102C5F97' ><span>5.2.9 Generating SMOTE dataset for training with entire set</span></h2><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Apply SMOTE (500 % more synthetic samples) and undersampling of majority</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% class</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>[X_train_balanced, y_RF_train_balanced] = smote_and_undersampling(X_train, y_train, 5, 0.33,</span><span style="color: rgb(170, 4, 249);">"smote_undersampling"</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span></span></div><div  class = 'S5' id = 'H_BB772AEE' ><span></span></div><h2  class = 'S4' id = 'H_AE5E8193' ><span>5.3 Random Forest</span></h2><div  class = 'S5'><span></span></div><div  class = 'S5'><span style=' font-weight: bold;'>Model validation choice</span></div><div  class = 'S5'><span>Random forests already have a unique, convenient property which is bootstrapping that is used to fit the individual trees, which readily yields the out-of-bag (OOB) error. This is an unbiased estimate of the error on future data, and can therefore take the place of the validation or test set error. This leaves more data available for training, and is computationally cheaper than nested cross validation.</span></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span style=' font-weight: bold;'>Hyperparameter optimisation choice</span></div><div  class = 'S5'><span>First we opted to implement grid search optimization to verify if there is any region of best performance and then we will implement Bayesian Optimisation.</span></div><div  class = 'S5'><span>Tuning the number of trees is unnecessary; instead, simply set the number of trees to a large, computationally feasible number, and let the asymptotic behavior of LLN do the rest.</span></div><div  class = 'S5'><span>In the case that you have some kind of constraint (a cap on the total number of terminal nodes, a cap on the model estimation time, a limit to the size of the model on disk), this amounts to choosing the largest</span><span> </span><span>T</span><span>T</span><span> </span><span>that satisfies your constraint.</span></div><div  class = 'S5'><span>We need to define a few hyperparameters that will be important to be analysed by the random forest:</span></div><div  class = 'S5'><span style=' font-weight: bold;'>MinLeafSize</span></div><div  class = 'S5'><span>For boosting ensemble methods, specify the maximum number of splits or branch points to control the depth of your tree learners. Many branches tend to overfit, and simpler trees can be more robust and easy to interpret. Experiment to choose the best tree depth for the trees in the ensemble.</span></div><div  class = 'S5'><span>NumTrees</span></div><div  class = 'S5'><span>NumPredictorstoSample</span></div><div  class = 'S5'><span>NumSplits</span></div><div  class = 'S5'><span>Grid search and random forest implementation</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>leaf = [5 10 20 30 40];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>NumTrees = [5 10 20 30 40];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>NumSplits = [5 10 15 20 25];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>numPredictors = [1 3 5 7 9];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>gsErrors = [];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>Accuracy = [];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>Time = [];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>i=1:length(leaf)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">for </span><span>j=1:length(NumTrees)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">for </span><span>s=1:length(numSplits)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span><span style="color: rgb(14, 0, 255);">for </span><span>p=1:length(numPredictors)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                t_old = clock;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                b = TreeBagger(numTree(j),X_train,y_train, </span><span style="color: rgb(170, 4, 249);">"SampleWithReplacement"</span><span>, </span><span style="color: rgb(170, 4, 249);">"on"</span><span>,</span><span style="color: rgb(170, 4, 249);">'Method'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Classification'</span><span>,</span><span style="color: rgb(170, 4, 249);">'OOBPrediction'</span><span>,</span><span style="color: rgb(170, 4, 249);">'On'</span><span>,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            			</span><span style="color: rgb(170, 4, 249);">'OOBPredictorImportance'</span><span>,</span><span style="color: rgb(170, 4, 249);">'On'</span><span>,</span><span style="color: rgb(170, 4, 249);">'MinLeafSize'</span><span>,leaf(i),</span><span style="color: rgb(170, 4, 249);">'MaxNumSplits'</span><span>,numSplits(s),</span><span style="color: rgb(170, 4, 249);">'NumPredictorsToSample'</span><span>,numPredictors(p));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                [predicted_labels, </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">scores</span><span>] = cell2mat(oobPredict(b)); </span><span style="color: rgb(2, 128, 9);">%str2num(cell2mat(oobPredict(b)));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                cm_rf = confusionmat(y_train, predicted_labels);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                Accuracy_model = 100*sum(diag(cm_rf))./sum(cm_rf(:));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                </span><span class="warning_squiggle_rte457626237">Accuracy</span><span> = [Accuracy; Accuracy_model];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                </span><span class="warning_squiggle_rte457626237">gsErrors</span><span> = [gsErrors; leaf(i) numTree(j) numSplits(s) numPredictors(p) sum(1-(y_train == predicted_labels)) / length(y_train)];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                </span><span class="warning_squiggle_rte457626237">Time</span><span> = [Time; etime(clock, t_old)];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                Final_Male = [gsErrors Accuracy Time];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><h3  class = 'S14' id = 'H_583EBF9B' ><span>5.3.1 Using Bayesian Optimisation</span></h3><div  class = 'S5'><span></span></div><div  class = 'S5'><span>We know that matlab function TreeBagger doesn't have built-in hyperparameter optimization therefore we need to use 'bayesopt' function. </span></div><div  class = 'S5'><span>Efficiently find the best target solution.</span></div><div  class = 'S5'><span>It is a iterative process and it starts with a selection of a sampling set.</span></div><div  class = 'S5'><span>Given the sampling set then we train a gaussian process, after that we calculate an acquisition function and finally identify the input vector minimizing the acquisition function value.</span></div><div  class = 'S5'><span></span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_RF_train = array2table(X_train,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(170, 4, 249);">'VariableNames'</span><span>,features_to_keep);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_RF_train = array2table(y_train,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(170, 4, 249);">'VariableNames'</span><span>,{</span><span style="color: rgb(170, 4, 249);">'Kingdom'</span><span>});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_RF_train_label = [X_RF_train y_RF_train];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Merge tables</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%T2 = outerjoin(T,tempTable,'MergeKeys', 1)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span>NumSplits = [5 10 15 20 25];</span></div><div  class = 'S5'><span>We decided to leave off a few set parameters out of the algorithm (e.g. prune).</span></div><div  class = 'S5'><span style=' font-weight: bold;'>Pruning</span><span> decision trees is not recommended for ensembles.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>rng(</span><span style="color: rgb(170, 4, 249);">'default'</span><span>); </span><span style="color: rgb(2, 128, 9);">% For reproducibility</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>maxminLeafSize = 30;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>minNumSplits = 5; </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>maxNumSplits = 40; </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%maxNumTrees = 500;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Define variables that should be optimised with Bayes Optimisation (BO)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>Hyperparameters = [optimizableVariable(</span><span style="color: rgb(170, 4, 249);">'minLeafSize'</span><span>,[1,maxminLeafSize], </span><span style="color: rgb(170, 4, 249);">'Type'</span><span>,</span><span style="color: rgb(170, 4, 249);">'integer'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                   optimizableVariable(</span><span style="color: rgb(170, 4, 249);">'numPredictorstoSample'</span><span>, [1,size(X_RF_train_label,2)-1], </span><span style="color: rgb(170, 4, 249);">'Type'</span><span>,</span><span style="color: rgb(170, 4, 249);">'integer'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                   optimizableVariable(</span><span style="color: rgb(170, 4, 249);">'maxNumSplits'</span><span>, [minNumSplits,maxNumSplits], </span><span style="color: rgb(170, 4, 249);">'Type'</span><span>,</span><span style="color: rgb(170, 4, 249);">'integer'</span><span>)];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                   </span><span style="color: rgb(2, 128, 9);">%optimizableVariable('NumTrees', [1,maxNumTrees], 'Type','integer')];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Define the objective function to be the out-of-bag Quantile Error. </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>fun = @(hparams)oobErrorRF(hparams,X_RF_train_label);          </span><span style="color: rgb(2, 128, 9);">% It must be a function of only the hyperparameters.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Call bayesopt to optimize Quantile Error</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>results = bayesopt(fun, Hyperparameters,</span><span style="color: rgb(170, 4, 249);">'AcquisitionFunctionName'</span><span>,</span><span style="color: rgb(170, 4, 249);">'expected-improvement-plus'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Verbose'</span><span>,1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Look at the best hyperparameters found</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%bestHyperparameters = bestPoint(results)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>bestOOBErr = results.MinObjective</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>bestHyperparameters = results.XAtMinObjective</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Fit final Random Forest  model to the full dataset using the best hyperparameters</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%FinalModel = TreeBagger(300,X,'MPG','Method','regression',...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%                        'MinLeafSize', bestHyperparameters.MinLeafSize,...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%                        'NumPredictorstoSample', bestHyperparameters.NumPredictorstoSample)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div  class = 'S10'><span></span></div><div  class = 'S5'><span>Reference:https://uk.mathworks.com/help/stats/tune-random-forest-using-quantile-error-and-bayesian-optimization.html</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'></div></div></div><h2  class = 'S15' id = 'H_5D0A9B6D' ><span>5.3.2 Performing training using best hyperparameters choice</span></h2><div  class = 'S5'><span></span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>bestminLeafSize = bestHyperparameters.minLeafSize;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>bestnumPredictorstoSample = bestHyperparameters.numPredictorstoSample;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>bestmaxNumSplits = bestHyperparameters.maxNumSplits;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>oobRF = TreeBagger(400,X_RF_train_label,</span><span style="color: rgb(170, 4, 249);">'Kingdom'</span><span>,</span><span style="color: rgb(170, 4, 249);">"SampleWithReplacement"</span><span>, </span><span style="color: rgb(170, 4, 249);">"on"</span><span>,</span><span style="color: rgb(170, 4, 249);">'Method'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Classification'</span><span>,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                          </span><span style="color: rgb(170, 4, 249);">'OOBPrediction'</span><span>,</span><span style="color: rgb(170, 4, 249);">'On'</span><span>, </span><span style="color: rgb(170, 4, 249);">'OOBPredictorImportance'</span><span>,</span><span style="color: rgb(170, 4, 249);">'On'</span><span>,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                          </span><span style="color: rgb(170, 4, 249);">'MinLeafSize'</span><span>,bestminLeafSize,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                          </span><span style="color: rgb(170, 4, 249);">'NumPredictorstoSample'</span><span>,bestnumPredictorstoSample,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                          </span><span style="color: rgb(170, 4, 249);">'MaxNumSplits'</span><span>,bestmaxNumSplits);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span class="warning_squiggle_rte457626237">oobErr</span><span> = oobError(oobRF, </span><span style="color: rgb(170, 4, 249);">'Mode'</span><span>,</span><span style="color: rgb(170, 4, 249);">'ensemble'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div  class = 'S5'><span>Prediction of Out-of-Bag samples with training set (without oversampling / undersampling)</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%pred = str2num(cell2mat(predict(oobRF,X_RF_train)));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>[predicted_labels, </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">scores</span><span>] = oobPredict(oobRF);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%cm_RF = confusionmat(cellstr(table2array(y_RF_train)), cell2mat(predicted_labels));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%Accuracy_model = 100*sum(diag(ConfMat))./sum(ConfMat(:));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%Accuracy = [Accuracy; Accuracy_model];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%gsErrors = [gsErrors; leaf(i) numTree(j) numSplits(s) numPredictors(p) sum(1-(yTrain_Male == predicted_labels)) / length(yTrain_Male)];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%Time = [Time; etime(clock, t_old)];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>weight_classes = [sum(y_train==</span><span style="color: rgb(170, 4, 249);">'arc'</span><span>)/length(y_train);sum(y_train==</span><span style="color: rgb(170, 4, 249);">'bct'</span><span>)/length(y_train);</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                  sum(y_train==</span><span style="color: rgb(170, 4, 249);">'euk'</span><span>)/length(y_train)];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span class="warning_squiggle_rte457626237">rf_train_scores</span><span> = confusionMatStats(cellstr(y_train),predicted_labels,weight_classes);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Plotting performance</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>tiledlayout(</span><span style="color: rgb(170, 4, 249);">'flow'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>nexttile</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>Confmat_RFTrain = confusionchart(cellstr(table2array(y_RF_train)), predicted_labels,</span><span style="color: rgb(170, 4, 249);">'RowSummary'</span><span>,</span><span style="color: rgb(170, 4, 249);">'row-normalized'</span><span>,</span><span style="color: rgb(170, 4, 249);">'FontSize'</span><span>,12,</span><span style="color: rgb(170, 4, 249);">'FontName'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Arial'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>sortClasses(Confmat_RFTrain,[</span><span style="color: rgb(170, 4, 249);">"arc"</span><span>,</span><span style="color: rgb(170, 4, 249);">"bct"</span><span>,</span><span style="color: rgb(170, 4, 249);">"euk"</span><span>]);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>Confmat_RFTrain.Normalization = </span><span style="color: rgb(170, 4, 249);">'absolute'</span><span>; </span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>title(</span><span style="color: rgb(170, 4, 249);">"Confusion chart"</span><span>);</span></span></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>bar(oobRF.OOBPermutedVarDeltaError)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>xlabel(</span><span style="color: rgb(170, 4, 249);">'Feature Index'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>ylabel(</span><span style="color: rgb(170, 4, 249);">'Out-of-Bag Feature Importance'</span><span>)</span></span></div></div></div><h2  class = 'S15' id = 'H_ECD804FF' ><span>5.5.4 with oversampling</span></h2><div  class = 'S5'><span></span></div><div  class = 'S5'><span>In this step we generate a new set of samples for the minority class 1 and Generate syn</span></div><div  class = 'S5'><span></span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S0'></div></div></div><h2  class = 'S15' id = 'H_974F380A' ><span></span></h2><h2  class = 'S15' id = 'H_8DD34397' ><span></span></h2><h2  class = 'S4' id = 'H_FB024E77' ><span>5.5.4 with oversampling</span></h2><div  class = 'S5'><span></span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>rng(</span><span style="color: rgb(170, 4, 249);">'default'</span><span>); </span><span style="color: rgb(2, 128, 9);">% For reproducibility</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>maxminLeafSize = 30;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>minNumSplits = 2;  </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>maxNumSplits = 50; </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>maxNumTrees = 500;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>splitCriterion = </span><span style="color: rgb(170, 4, 249);">'gdi'</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Define variables that should be optimised with Bayes Optimisation (BO)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>Hyperparameters = [optimizableVariable(</span><span style="color: rgb(170, 4, 249);">'minLeafSize'</span><span>,[1,maxminLeafSize], </span><span style="color: rgb(170, 4, 249);">'Type'</span><span>,</span><span style="color: rgb(170, 4, 249);">'integer'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                   optimizableVariable(</span><span style="color: rgb(170, 4, 249);">'numPredictorstoSample'</span><span>, [1,size(X_RF_SMOTE_train_label,2)-1], </span><span style="color: rgb(170, 4, 249);">'Type'</span><span>,</span><span style="color: rgb(170, 4, 249);">'integer'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                   optimizableVariable(</span><span style="color: rgb(170, 4, 249);">'maxNumSplits'</span><span>, [minNumSplits,maxNumSplits], </span><span style="color: rgb(170, 4, 249);">'Type'</span><span>,</span><span style="color: rgb(170, 4, 249);">'integer'</span><span>),</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                   optimizableVariable(</span><span style="color: rgb(170, 4, 249);">'maxNumTrees'</span><span>, [1,maxNumTrees], </span><span style="color: rgb(170, 4, 249);">'Type'</span><span>,</span><span style="color: rgb(170, 4, 249);">'integer'</span><span>)];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Define the objective function to be the out-of-bag Quantile Error. </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>fun = @(hparams)oobErrorRF(hparams,X_RF_SMOTE_train_label,splitCriterion);          </span><span style="color: rgb(2, 128, 9);">% It must be a function of only the hyperparameters.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Call bayesopt to optimize Quantile Error</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>results = bayesopt(fun, Hyperparameters,</span><span style="color: rgb(170, 4, 249);">'AcquisitionFunctionName'</span><span>,</span><span style="color: rgb(170, 4, 249);">'expected-improvement-plus'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Verbose'</span><span>,1);</span></span></div></div></div><div  class = 'S10'><span></span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>bestminLeafSize = 16; </span><span style="color: rgb(2, 128, 9);">%bestHyperparameters.minLeafSize;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>bestnumPredictorstoSample = 15; </span><span style="color: rgb(2, 128, 9);">%bestHyperparameters.numPredictorstoSample;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>bestmaxNumSplits = 5; </span><span style="color: rgb(2, 128, 9);">%bestHyperparameters.maxNumSplits;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>bestmaxNumTrees = 128; </span><span style="color: rgb(2, 128, 9);">%bestHyperparameters.maxNumTrees;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>rng(1,</span><span style="color: rgb(170, 4, 249);">'twister'</span><span>); </span><span style="color: rgb(2, 128, 9);">% For reproducibility</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%oobRF = TreeBagger(128,X_RF_SMOTE_train_label,'Kingdom',"SampleWithReplacement", "on",'Method','Classification',...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%                          'OOBPrediction','On', 'OOBPredictorImportance','On',...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%                          'MinLeafSize',bestminLeafSize,...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%                          'NumPredictorstoSample',bestnumPredictorstoSample,...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%                          'MaxNumSplits',bestmaxNumSplits);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>oobRF = TreeBagger(bestmaxNumTrees,X_RF_SMOTE_train_label,</span><span style="color: rgb(170, 4, 249);">'Kingdom'</span><span>,</span><span style="color: rgb(170, 4, 249);">"SampleWithReplacement"</span><span>, </span><span style="color: rgb(170, 4, 249);">"on"</span><span>,</span><span style="color: rgb(170, 4, 249);">'Method'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Classification'</span><span>,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                          </span><span style="color: rgb(170, 4, 249);">'OOBPrediction'</span><span>,</span><span style="color: rgb(170, 4, 249);">'On'</span><span>, </span><span style="color: rgb(170, 4, 249);">'OOBPredictorImportance'</span><span>,</span><span style="color: rgb(170, 4, 249);">'On'</span><span>,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                          </span><span style="color: rgb(170, 4, 249);">'MinLeafSize'</span><span>,bestminLeafSize,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                          </span><span style="color: rgb(170, 4, 249);">'NumPredictorstoSample'</span><span>,bestnumPredictorstoSample,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                          </span><span style="color: rgb(170, 4, 249);">'MaxNumSplits'</span><span>,bestmaxNumSplits, </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                          </span><span style="color: rgb(170, 4, 249);">'AlgorithmForCategorical'</span><span>,</span><span style="color: rgb(170, 4, 249);">'PCA'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Prior'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Empirical'</span><span>, </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                          </span><span style="color: rgb(170, 4, 249);">'SplitCriterion'</span><span>,splitCriterion);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>oobErr = oobError(oobRF, </span><span style="color: rgb(170, 4, 249);">'Mode'</span><span>,</span><span style="color: rgb(170, 4, 249);">'ensemble'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div  class = 'S10'><span>Prediction of Out-of-Bag samples with training set (without oversampling / undersampling)</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%pred = str2num(cell2mat(predict(oobRF,X_RF_train)));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>[predicted_labels, scores] = oobPredict(oobRF);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%cm_RF = confusionmat(cellstr(table2array(y_RF_train)), cell2mat(predicted_labels));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%Accuracy_model = 100*sum(diag(ConfMat))./sum(ConfMat(:));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%Accuracy = [Accuracy; Accuracy_model];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%gsErrors = [gsErrors; leaf(i) numTree(j) numSplits(s) numPredictors(p) sum(1-(yTrain_Male == predicted_labels)) / length(yTrain_Male)];</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%Time = [Time; etime(clock, t_old)];</span></span></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%% plot PRCs</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_train_num = renamecats(categorical(table2array(y_RF_SMOTE_train)),{</span><span style="color: rgb(170, 4, 249);">'arc'</span><span>,</span><span style="color: rgb(170, 4, 249);">'bct'</span><span>,</span><span style="color: rgb(170, 4, 249);">'euk'</span><span>},{</span><span style="color: rgb(170, 4, 249);">'1'</span><span>,</span><span style="color: rgb(170, 4, 249);">'2'</span><span>,</span><span style="color: rgb(170, 4, 249);">'3'</span><span>});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_train_num = str2double(string(y_train_num));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>i=1;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>tgt=-ones(1,length(y_RF_SMOTE_train));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>positive_class=find(y_RF_SMOTE_train==i);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>tgt(positive_class)=1;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>legends_prc{i} = sprintf(</span><span style="color: rgb(170, 4, 249);">'PRC for %s class'</span><span>, codon_classes{i});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>fprintf(PR1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%% Plot PRCs</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>plt_prc = compute_prc_roc(tgt,proba(:, i)',</span><span style="color: rgb(170, 4, 249);">"PRC"</span><span>,codon_classes{i},i,i_fold,legends_prc,plt_prc);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>drawnow();</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>i=2:length(codon_classes)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    tgt=-ones(1,length(y_RF_SMOTE_train));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    positive_class=find(y_RF_SMOTE_train==i);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    tgt(positive_class)=1;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    legends_prc{i} = sprintf(</span><span style="color: rgb(170, 4, 249);">'PRC for %s class'</span><span>, codon_classes{i});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    fprintf(PR1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">    %% Plot PRCs</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    plt_prc = compute_prc_roc(tgt,proba(:, i)',</span><span style="color: rgb(170, 4, 249);">"PRC"</span><span>,codon_classes{i},i,i_fold,legends_prc,plt_prc);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    drawnow();</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>  </span></span></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>figure;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>[x,y,</span><span class="warning_squiggle_rte457626237 warningHighlight457626237">t</span><span>,auc,optrocpt,suby,subynames] = perfcurve(y_train_num,scores(:, i),</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>1,</span><span style="color: rgb(170, 4, 249);">'negClass'</span><span>,[2 3],</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(170, 4, 249);">'ycrit'</span><span>,</span><span style="color: rgb(170, 4, 249);">'fpr'</span><span>,</span><span style="color: rgb(170, 4, 249);">'xcrit'</span><span>,</span><span style="color: rgb(170, 4, 249);">'tpr'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>plot(suby(:,1),x)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>hold</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>plot(suby(:,2),x,</span><span style="color: rgb(170, 4, 249);">'r'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>hold </span><span style="color: rgb(170, 4, 249);">off</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>title(</span><span style="color: rgb(170, 4, 249);">'Two ROC curves'</span><span>)</span></span></div></div></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Plotting Confusion Matrix</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>weight_classes = [sum(table2array(y_RF_SMOTE_train)==</span><span style="color: rgb(170, 4, 249);">'arc'</span><span>)/length(table2array(y_RF_SMOTE_train));</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                  sum(table2array(y_RF_SMOTE_train)==</span><span style="color: rgb(170, 4, 249);">'bct'</span><span>)/length(table2array(y_RF_SMOTE_train));</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                  sum(table2array(y_RF_SMOTE_train)==</span><span style="color: rgb(170, 4, 249);">'euk'</span><span>)/length(table2array(y_RF_SMOTE_train))];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>rf_train_scores = confusionMatStats(cellstr(table2array(y_RF_SMOTE_train)),predicted_labels,weight_classes);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>tiledlayout(</span><span style="color: rgb(170, 4, 249);">'flow'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>nexttile</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>Confmat_RFTrain = confusionchart(cellstr(table2array(y_RF_SMOTE_train)), predicted_labels,</span><span style="color: rgb(170, 4, 249);">'RowSummary'</span><span>,</span><span style="color: rgb(170, 4, 249);">'row-normalized'</span><span>,</span><span style="color: rgb(170, 4, 249);">'FontSize'</span><span>,12,</span><span style="color: rgb(170, 4, 249);">'FontName'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Arial'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>sortClasses(Confmat_RFTrain,[</span><span style="color: rgb(170, 4, 249);">"arc"</span><span>,</span><span style="color: rgb(170, 4, 249);">"bct"</span><span>,</span><span style="color: rgb(170, 4, 249);">"euk"</span><span>]);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>Confmat_RFTrain.Normalization = </span><span style="color: rgb(170, 4, 249);">'absolute'</span><span>; </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>title(</span><span style="color: rgb(170, 4, 249);">"Confusion chart"</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%rf_smote_train_scores = confusionMatStats(cellstr(y_RF_SMOTE_train),predicted_labels,weight_classes);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Saving metrics to a table</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%RF_SMOTETraining = table(Precision,Recall,Specificity, BM, FPR, FNR, FOR, NPV, FDR, MCC, MK, F1, F2, Accuracy,AUC,Time,...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%    'RowNames',{'Optimised RF model with SMOTE'}) % Creating a table of performance for the best performing model</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><h2  class = 'S15' id = 'H_D8CE37C4' ><span>Using cross-validation to improve performance of Bayesian Optimisation function</span></h2><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>rng(</span><span style="color: rgb(170, 4, 249);">'default'</span><span>); </span><span style="color: rgb(2, 128, 9);">% For reproducibility</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>maxminLeafSize = 30;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>minNumSplits = 2;  </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>maxNumSplits = 50; </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span><span style="color: rgb(2, 128, 9);">maxNumTrees</span><span style="color: rgb(2, 128, 9);"> = 500;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>numkfold = 5;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Gini Index</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>splitCriterion = </span><span style="color: rgb(170, 4, 249);">'gdi'</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Define variables that should be optimised with Bayes Optimisation (BO)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>Hyperparameters = [optimizableVariable(</span><span style="color: rgb(170, 4, 249);">'minLeafSize'</span><span>,[1,maxminLeafSize], </span><span style="color: rgb(170, 4, 249);">'Type'</span><span>,</span><span style="color: rgb(170, 4, 249);">'integer'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                   optimizableVariable(</span><span style="color: rgb(170, 4, 249);">'numPredictorstoSample'</span><span>, [1,size(X_RF_SMOTE_train_label,2)-1], </span><span style="color: rgb(170, 4, 249);">'Type'</span><span>,</span><span style="color: rgb(170, 4, 249);">'integer'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                   optimizableVariable(</span><span style="color: rgb(170, 4, 249);">'maxNumSplits'</span><span>, [minNumSplits,maxNumSplits], </span><span style="color: rgb(170, 4, 249);">'Type'</span><span>,</span><span style="color: rgb(170, 4, 249);">'integer'</span><span>)];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                   </span><span style="color: rgb(2, 128, 9);">%,optimizableVariable('maxNumTrees', [1,maxNumTrees], 'Type','integer')];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Define the objective function to be the out-of-bag classification Error. </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%ObjFcn = @(hparams)makeObjFcn(hparams,numkfold,X_RF_train_label,splitCriterion);          % It must be a function of only the hyperparameters.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>ObjFcn = makeObjFcn(numkfold,X_RF_train_label,splitCriterion); </span><span style="color: rgb(2, 128, 9);">% It must be a function of only the hyperparameters.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Call bayesopt to optimize Classification Error</span></span></div></div><div class="inlineWrapper outputs"><div  class = 'S20'><span style="white-space: pre;"><span>results_bo_smote = bayesopt(ObjFcn, Hyperparameters,</span><span style="color: rgb(170, 4, 249);">'AcquisitionFunctionName'</span><span>,</span><span style="color: rgb(170, 4, 249);">'expected-improvement-plus'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Verbose'</span><span>,1);</span></span></div><div  class = 'S21'><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="3757ECD0" data-scroll-top="null" data-scroll-left="null" data-testid="output_10" data-width="813" data-height="75" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|====================================================================================================================|
| Iter | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   |  minLeafSize | numPredictor-| maxNumSplits |
|      | result |             | runtime     | (observed)  | (estim.)    |              | stoSample    |              |
|====================================================================================================================|
|    1 | Best   |    0.062391 |      123.18 |    0.062391 |    0.062391 |           28 |           39 |           17 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="BD9C38A3" data-scroll-top="null" data-scroll-left="null" data-testid="output_11" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|    2 | Best   |    0.060256 |      136.36 |    0.060256 |     0.06127 |            5 |           41 |           22 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="78214F7F" data-scroll-top="null" data-scroll-left="null" data-testid="output_12" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|    3 | Best   |    0.040547 |      181.02 |    0.040547 |    0.040549 |           10 |           35 |           49 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="C317C9D9" data-scroll-top="null" data-scroll-left="null" data-testid="output_13" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|    4 | Accept |    0.047829 |      79.451 |    0.040547 |    0.040549 |            3 |           11 |           19 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="E681ABA9" data-scroll-top="null" data-scroll-left="null" data-testid="output_14" data-width="813" data-height="17" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|    5 | Best   |    0.035777 |      155.94 |    0.035777 |    0.035766 |            8 |           25 |           50 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="A6FEABDF" data-scroll-top="null" data-scroll-left="null" data-testid="output_15" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|    6 | Accept |    0.070048 |      107.18 |    0.035777 |    0.035779 |            5 |            1 |           50 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="C389CEEF" data-scroll-top="null" data-scroll-left="null" data-testid="output_16" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|    7 | Accept |     0.03992 |      143.61 |    0.035777 |    0.035781 |            3 |           26 |           41 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="38316E10" data-scroll-top="null" data-scroll-left="null" data-testid="output_17" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|    8 | Accept |    0.038162 |      167.08 |    0.035777 |    0.035787 |           23 |           29 |           50 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="6D14BE62" data-scroll-top="null" data-scroll-left="null" data-testid="output_18" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|    9 | Best   |    0.033266 |      142.86 |    0.033266 |    0.033274 |           20 |           20 |           50 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="442C0B16" data-scroll-top="null" data-scroll-left="null" data-testid="output_19" data-width="813" data-height="17" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|   10 | Accept |    0.035777 |      137.57 |    0.033266 |    0.033774 |           27 |           18 |           50 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="6F2CE25B" data-scroll-top="null" data-scroll-left="null" data-testid="output_20" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|   11 | Accept |    0.034898 |      144.25 |    0.033266 |    0.034306 |           17 |           21 |           50 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="8CE4A4F0" data-scroll-top="null" data-scroll-left="null" data-testid="output_21" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|   12 | Accept |    0.033266 |      144.97 |    0.033266 |    0.033991 |            9 |           21 |           50 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="0B13B318" data-scroll-top="null" data-scroll-left="null" data-testid="output_22" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|   13 | Accept |    0.034396 |      142.14 |    0.033266 |    0.034078 |            1 |           21 |           50 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="E31C9CC4" data-scroll-top="null" data-scroll-left="null" data-testid="output_23" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|   14 | Accept |      0.2183 |      18.291 |    0.033266 |    0.034154 |            9 |            1 |            2 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="593E161B" data-scroll-top="null" data-scroll-left="null" data-testid="output_24" data-width="813" data-height="17" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|   15 | Accept |    0.084233 |       77.04 |    0.033266 |    0.034151 |           24 |            1 |           28 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="9B43426C" data-scroll-top="null" data-scroll-left="null" data-testid="output_25" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|   16 | Accept |    0.036656 |      157.17 |    0.033266 |    0.034169 |           30 |           22 |           46 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="4F204AC4" data-scroll-top="null" data-scroll-left="null" data-testid="output_26" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|   17 | Accept |    0.051343 |      233.71 |    0.033266 |    0.034144 |           30 |           43 |           40 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="B11AC66B" data-scroll-top="null" data-scroll-left="null" data-testid="output_27" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|   18 | Accept |    0.043686 |      127.62 |    0.033266 |     0.03421 |            8 |           21 |           25 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="876FCB28" data-scroll-top="null" data-scroll-left="null" data-testid="output_28" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|   19 | Accept |    0.048833 |      102.78 |    0.033266 |    0.034183 |            5 |           23 |           20 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="AD41DEBF" data-scroll-top="null" data-scroll-left="null" data-testid="output_29" data-width="813" data-height="17" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|   20 | Accept |     0.04469 |      135.61 |    0.033266 |    0.034186 |            6 |           29 |           33 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="0CAC4976" data-scroll-top="null" data-scroll-left="null" data-testid="output_30" data-width="813" data-height="76" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|====================================================================================================================|
| Iter | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   |  minLeafSize | numPredictor-| maxNumSplits |
|      | result |             | runtime     | (observed)  | (estim.)    |              | stoSample    |              |
|====================================================================================================================|
|   21 | Accept |    0.040045 |      176.19 |    0.033266 |    0.034172 |            2 |           30 |           45 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="765AC31A" data-scroll-top="null" data-scroll-left="null" data-testid="output_31" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|   22 | Accept |    0.046824 |      218.82 |    0.033266 |    0.034198 |            6 |           43 |           50 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="E998B581" data-scroll-top="null" data-scroll-left="null" data-testid="output_32" data-width="813" data-height="17" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|   23 | Accept |     0.15039 |       52.29 |    0.033266 |    0.034229 |            4 |           43 |            2 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="17FD1AFB" data-scroll-top="null" data-scroll-left="null" data-testid="output_33" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|   24 | Accept |    0.077079 |      56.092 |    0.033266 |    0.034151 |            3 |           22 |            6 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="116406BB" data-scroll-top="null" data-scroll-left="null" data-testid="output_34" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|   25 | Accept |    0.039292 |      114.63 |    0.033266 |    0.034121 |            4 |           13 |           32 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="49F442D5" data-scroll-top="null" data-scroll-left="null" data-testid="output_35" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|   26 | Accept |     0.13332 |       46.42 |    0.033266 |    0.034086 |            1 |           32 |            2 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="FE6C6BF2" data-scroll-top="null" data-scroll-left="null" data-testid="output_36" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|   27 | Accept |     0.15164 |      29.847 |    0.033266 |    0.034161 |            4 |           12 |            2 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="FD0DD7E5" data-scroll-top="null" data-scroll-left="null" data-testid="output_37" data-width="813" data-height="17" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|   28 | Accept |    0.038037 |       143.6 |    0.033266 |    0.034164 |            2 |           19 |           35 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="85A3A6E9" data-scroll-top="null" data-scroll-left="null" data-testid="output_38" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|   29 | Accept |    0.075195 |      139.75 |    0.033266 |    0.034173 |            2 |            1 |           40 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="D8F17479" data-scroll-top="null" data-scroll-left="null" data-testid="output_39" data-width="813" data-height="18" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 261px;"><div class="textElement">|   30 | Accept |      0.1411 |      78.894 |    0.033266 |    0.034079 |           24 |            1 |           13 |</div></div><div class="inlineElement eoOutputWrapper embeddedOutputsFigure" uid="151EAD0B" data-testid="output_40" style="width: 843.026px;"><div class="figureElement"><div class="figureContainingNode" style="width: 560px; max-width: 100%; display: inline-block;"><div class="GraphicsView" data-dojo-attach-point="graphicsViewNode,backgroundColorNode" id="uniqName_164_679" widgetid="uniqName_164_679" style="width: 100%; height: auto;"><img class="ImageView figureImage" data-dojo-attach-point="imageViewNode" draggable="false" ondragstart="return false;" id="uniqName_164_681" widgetid="uniqName_164_681" src="data:image/png;base64,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" style="width: 100%; height: auto;"></div></div></div></div><div class="inlineElement eoOutputWrapper embeddedOutputsTextElement" uid="C7C42A56" data-scroll-top="null" data-scroll-left="null" data-testid="output_41" data-width="813" data-height="366" data-hashorizontaloverflow="false" style="width: 843.026px; max-height: 377px;"><div class="textElement">__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 3746.9723 seconds
Total objective function evaluation time: 3714.3437

Best observed feasible point:
    <strong>minLeafSize</strong>    <strong>numPredictorstoSample</strong>    <strong>maxNumSplits</strong>
    <strong>___________</strong>    <strong>_____________________</strong>    <strong>____________</strong>

        20                  20                   50     

Observed objective function value = 0.033266
Estimated objective function value = 0.034208
Function evaluation time = 142.8601

Best estimated feasible point (according to models):
    <strong>minLeafSize</strong>    <strong>numPredictorstoSample</strong>    <strong>maxNumSplits</strong>
    <strong>___________</strong>    <strong>_____________________</strong>    <strong>____________</strong>

         9                  21                   50     

Estimated objective function value = 0.034079
Estimated function evaluation time = 144.1061</div></div></div></div></div><div  class = 'S10' id = 'H_EB7DE0DB' ><span></span></div><h2  class = 'S15' id = 'H_80A954B4' ><span>5.9 Generate best model from the training set (using all data)</span></h2><div  class = 'S5'><span>We will use the same training dataset with 300% of synthetic samples generated from Logistic regression</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Convert X and y arrays to table</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_RF_SMOTE_train = array2table(X_RF_train_balanced,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(170, 4, 249);">'VariableNames'</span><span>,features_to_keep);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_RF_SMOTE_train = array2table(y_RF_train_balanced,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(170, 4, 249);">'VariableNames'</span><span>,{</span><span style="color: rgb(170, 4, 249);">'Kingdom'</span><span>});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_RF_SMOTE_train_label = [X_RF_SMOTE_train y_RF_SMOTE_train];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>tabulate(y_RF_train_balanced)</span></span></div></div></div><div  class = 'S10'><span></span></div><div  class = 'S5' id = 'H_F2AC7C56' ><span></span></div><h2  class = 'S4' id = 'H_535B9C39' ><span>5.10 Validating the optimised RF model on the test set</span></h2><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>tic; </span><span style="color: rgb(2, 128, 9);">% Start recording execution time</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>predicted_test = cellstr(predict(oobRF,X_test)); </span><span style="color: rgb(2, 128, 9);">% Prediction of RF model for testing set</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span> </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Build metric scores based on pred_test</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>weight_classes = [sum(y_test==</span><span style="color: rgb(170, 4, 249);">'arc'</span><span>)/length(y_test);sum(y_test==</span><span style="color: rgb(170, 4, 249);">'bct'</span><span>)/length(y_test);</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                  sum(y_test==</span><span style="color: rgb(170, 4, 249);">'euk'</span><span>)/length(y_test)];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>rf_test_scores = confusionMatStats(cellstr(y_test),predicted_test,weight_classes);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Visualising performance of RF prediction for test set</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>figure;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>t = tiledlayout(</span><span style="color: rgb(170, 4, 249);">'flow'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>t.Title.String = </span><span style="color: rgb(170, 4, 249);">'Performance of optimised random forest model on test set'</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>nexttile</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>Confmat_RFTest = confusionchart(cellstr(y_test),predicted_test,</span><span style="color: rgb(170, 4, 249);">'RowSummary'</span><span>,</span><span style="color: rgb(170, 4, 249);">'row-normalized'</span><span>,</span><span style="color: rgb(170, 4, 249);">'FontSize'</span><span>,12,</span><span style="color: rgb(170, 4, 249);">'FontName'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Arial'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>sortClasses(Confmat_RFTest,[</span><span style="color: rgb(170, 4, 249);">"arc"</span><span>,</span><span style="color: rgb(170, 4, 249);">"bct"</span><span>,</span><span style="color: rgb(170, 4, 249);">"euk"</span><span>]);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>Confmat_RFTest.Normalization = </span><span style="color: rgb(170, 4, 249);">'absolute'</span><span>; </span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>title(</span><span style="color: rgb(170, 4, 249);">"Confusion chart"</span><span>);</span></span></div></div></div><div  class = 'S5'><span>Prediction on </span></div><div  class = 'S5'><span>Plot performance of the best model</span></div><div  class = 'S5'><span></span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>pred = </span><span class="warning_squiggle_rte457626237">str2num</span><span>(cell2mat(predict(oobRF,xTest_Male))); </span><span style="color: rgb(2, 128, 9);">% Prediction of RF model for male testing dataset</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Plotting performance</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>tiledlayout(</span><span style="color: rgb(170, 4, 249);">'flow'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>nexttile</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>Confmat_RFTrain = confusionchart(yTrain_Male,pred,</span><span style="color: rgb(170, 4, 249);">'RowSummary'</span><span>,</span><span style="color: rgb(170, 4, 249);">'row-normalized'</span><span>,</span><span style="color: rgb(170, 4, 249);">'FontSize'</span><span>,12,</span><span style="color: rgb(170, 4, 249);">'FontName'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Arial'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>sortClasses(Confmat_RFTrain,[</span><span style="color: rgb(170, 4, 249);">"1"</span><span>,</span><span style="color: rgb(170, 4, 249);">"0"</span><span>]);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>Confmat_RFTrain.Normalization = </span><span style="color: rgb(170, 4, 249);">'absolute'</span><span>; </span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>title(</span><span style="color: rgb(170, 4, 249);">"Confusion chart"</span><span>);</span></span></div></div></div><div  class = 'S5'><span style=' font-weight: bold;'>6. Comparison of LR &amp; RF models for predicting Kingdom classes</span></div><div  class = 'S5'><span style=' font-weight: bold;'>Based on the best models we will compare metrics related to the minority class such as the weighted balance accuracy and Precision-Recall curves</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span>figure</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>scatter3(combined_performance.Precision, combined_performance.Recall, combined_performance.Specificity, 100, combined_performance.Accuracy, </span><span style="color: rgb(170, 4, 249);">'filled'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>set(gca,</span><span style="color: rgb(170, 4, 249);">'color'</span><span>,</span><span style="color: rgb(170, 4, 249);">"#ecf0f1"</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>title(</span><span style="color: rgb(170, 4, 249);">'Performance measures of LR and RF models'</span><span>, </span><span style="color: rgb(170, 4, 249);">'FontSize'</span><span>, 20)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>xlabel(</span><span style="color: rgb(170, 4, 249);">'Precision'</span><span>, </span><span style="color: rgb(170, 4, 249);">'FontSize'</span><span>, 20)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>ylabel(</span><span style="color: rgb(170, 4, 249);">'Recall'</span><span>, </span><span style="color: rgb(170, 4, 249);">'FontSize'</span><span>, 20)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>zlabel(</span><span style="color: rgb(170, 4, 249);">'Specificity'</span><span>, </span><span style="color: rgb(170, 4, 249);">'FontSize'</span><span>, 20)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>colormap(jet)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>hcb = colorbar(</span><span style="color: rgb(170, 4, 249);">'Location'</span><span>, </span><span style="color: rgb(170, 4, 249);">'EastOutside'</span><span>, </span><span style="color: rgb(170, 4, 249);">'FontSize'</span><span>, 20);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>hcb.Title.String = </span><span style="color: rgb(170, 4, 249);">"Accuracy"</span><span>;</span></span></div></div><div class="inlineWrapper outputs"><div  class = 'S20'></div><div  class = 'S21'><div class="inlineElement eoOutputWrapper embeddedOutputsVariableMatrixElement" uid="99850F95" data-testid="output_42" data-width="813" style="width: 843.026px; white-space: normal; font-style: normal; color: rgb(64, 64, 64); font-size: 12px;"><div class="matrixElement veSpecifier" style="white-space: normal; font-style: normal; color: rgb(64, 64, 64); font-size: 12px;"><div class="veVariableName variableNameElement double" style="width: 813px; white-space: normal; font-style: normal; color: rgb(64, 64, 64); font-size: 12px;"><div class="headerElementClickToInteract" style="white-space: normal; font-style: normal; color: rgb(64, 64, 64); font-size: 12px;"><span style="white-space: normal; font-style: normal; color: rgb(64, 64, 64); font-size: 12px;">abctn = </span><span class="veVariableValueSummary veMetaSummary" style="white-space: normal; font-style: normal; color: rgb(179, 179, 179); font-size: 12px;">3×1</span></div></div><div class="valueContainer focusedInteractiveOutput" data-layout="{&quot;columnWidth&quot;:66,&quot;totalColumns&quot;:1,&quot;totalRows&quot;:3,&quot;charsPerColumn&quot;:10}" style="white-space: nowrap; font-style: normal; color: rgb(64, 64, 64); font-size: 12px;"><div class="variableValue" style="width: 68px; white-space: pre; font-style: normal; color: rgb(64, 64, 64); font-size: 12px;">    1.0000
    0.0241
         0
</div><div class="horizontalEllipsis hide" style="white-space: nowrap; font-style: normal; color: rgb(64, 64, 64); font-size: 12px;"></div><div class="verticalEllipsis hide" style="white-space: nowrap; font-style: normal; color: rgb(64, 64, 64); font-size: 12px;"></div></div></div></div></div></div></div><div  class = 'S5'><span></span></div><div  class = 'S5'><span style=' font-weight: bold;'>7. Auxiliary functions </span></div><div  class = 'S5'><span style=' font-weight: bold;'>Functions list:</span></div><div  class = 'S5'><span style=' font-weight: bold;'>Violinplot</span></div><div  class = 'S5'><span style=' font-weight: bold;'>LRTraining</span></div><div  class = 'S5'><span style=' font-weight: bold;'>LRPredict</span></div><div  class = 'S5'><span style=' font-weight: bold;'>SafeLevelSMOTE (apply SafeLevelSMOTE oversampling algorithm based on a class and return a new sample)</span></div><div  class = 'S5'><span style=' font-weight: bold;'>generateGap (</span></div><div  class = 'S5'><span style=' font-weight: bold;'>sigmoid (compute sigmoid of a variable z)</span></div><div  class = 'S5'><span style=' font-weight: bold;'>fmincg (Minimize a continuous differentialble multivariate function)</span></div><div  class = 'S5'><span style=' font-weight: bold;'>costFunctionReg (Compute cost and gradient for logistic regression with regularization)</span></div><div  class = 'S5'><span style=' font-weight: bold;'>confusionMatStats (calculate metrics to assess the algorithms comparison)</span></div><div  class = 'S5'><span style=' font-weight: bold;'>oobErrRF (Bayesian Optimisation hyperparameter function)</span></div><div  class = 'S5'><span style=' font-weight: bold;'>boxplot_statistics (calculate data description statistics)</span></div><div  class = 'S5'><span style=' font-weight: bold;'>compute_prc_roc (receiver operating characteristic curve)</span></div><div  class = 'S5'><span style=' font-weight: bold;'></span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S7'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>violins = violinplot(data, cats, varargin)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%Violinplots plots violin plots of some data and categories</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   VIOLINPLOT(DATA) plots a violin of a double vector DATA</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   VIOLINPLOT(DATAMATRIX) plots violins for each column in</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   DATAMATRIX.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   VIOLINPLOT(TABLE), VIOLINPLOT(STRUCT), VIOLINPLOT(DATASET)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   plots violins for each column in TABLE, each field in STRUCT, and</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   each variable in DATASET. The violins are labeled according to</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   the table/dataset variable name or the struct field name.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   VIOLINPLOT(DATAMATRIX, CATEGORYNAMES) plots violins for each</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   column in DATAMATRIX and labels them according to the names in the</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   cell-of-strings CATEGORYNAMES.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   VIOLINPLOT(DATA, CATEGORIES) where double vector DATA and vector</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   CATEGORIES are of equal length; plots violins for each category in</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   DATA.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   violins = VIOLINPLOT(...) returns an object array of</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   &lt;a href="matlab:help('Violin')"&gt;Violin&lt;/a&gt; objects.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   VIOLINPLOT(..., 'PARAM1', val1, 'PARAM2', val2, ...)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   specifies optional name/value pairs for all violins:</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     'Width'        Width of the violin in axis space.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%                    Defaults to 0.3</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     'Bandwidth'    Bandwidth of the kernel density estimate.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%                    Should be between 10% and 40% of the data range.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     'ViolinColor'  Fill color of the violin area and data points.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%                    Defaults to the next default color cycle.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     'ViolinAlpha'  Transparency of the violin area and data points.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%                    Defaults to 0.3.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     'EdgeColor'    Color of the violin area outline.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%                    Defaults to [0.5 0.5 0.5]</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     'BoxColor'     Color of the box, whiskers, and the outlines of</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%                    the median point and the notch indicators.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%                    Defaults to [0.5 0.5 0.5]</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     'MedianColor'  Fill color of the median and notch indicators.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%                    Defaults to [1 1 1]</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     'ShowData'     Whether to show data points.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%                    Defaults to true</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     'ShowNotches'  Whether to show notch indicators.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%                    Defaults to false</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     'ShowMean'     Whether to show mean indicator</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%                    Defaults to false</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     'GroupOrder'   Cell of category names in order to be plotted.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%                    Defaults to alphabetical ordering</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Copyright (c) 2016, Bastian Bechtold</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% This code is released under the terms of the BSD 3-clause license</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    hascategories = exist(</span><span style="color: rgb(170, 4, 249);">'cats'</span><span>,</span><span style="color: rgb(170, 4, 249);">'var'</span><span>) &amp;&amp; not(isempty(cats));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%parse the optional grouporder argument </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%if it exists parse the categories order </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% but also delete it from the arguments passed to Violin</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    grouporder = {};</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    idx=find(strcmp(varargin, </span><span style="color: rgb(170, 4, 249);">'GroupOrder'</span><span>));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">if </span><span>~isempty(idx) &amp;&amp; numel(varargin)&gt;idx</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">if </span><span>iscell(varargin{idx+1})</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            grouporder = varargin{idx+1};</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            varargin(idx:idx+1)=[];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">else</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            error(</span><span style="color: rgb(170, 4, 249);">'Second argument of ''GroupOrder'' optional arg must be a cell of category names'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% tabular data</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">if </span><span>isa(data, </span><span style="color: rgb(170, 4, 249);">'dataset'</span><span>) || isstruct(data) || istable(data)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">if </span><span>isa(data, </span><span style="color: rgb(170, 4, 249);">'dataset'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            colnames = data.Properties.VarNames;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">elseif </span><span>istable(data)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            colnames = data.Properties.VariableNames;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">elseif </span><span>isstruct(data)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            colnames = fieldnames(data);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        catnames = {};</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">for </span><span>n=1:length(colnames)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span><span style="color: rgb(14, 0, 255);">if </span><span>isnumeric(data.(colnames{n}))</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                </span><span class="warning_squiggle_rte457626237">catnames</span><span> = [catnames colnames{n}];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">for </span><span>n=1:length(catnames)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            thisData = data.(catnames{n});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span><span class="warning_squiggle_rte457626237">violins</span><span>(n) = Violin(thisData, n, varargin{:});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        set(gca, </span><span style="color: rgb(170, 4, 249);">'XTick'</span><span>, 1:length(catnames), </span><span style="color: rgb(170, 4, 249);">'XTickLabels'</span><span>, catnames);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% 1D data, one category for each data point</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">elseif </span><span>hascategories &amp;&amp; numel(data) == numel(cats)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">if </span><span>isempty(grouporder)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            cats = categorical(cats);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">else</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            cats = categorical(cats, grouporder);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        catnames = (unique(cats)); </span><span style="color: rgb(2, 128, 9);">% this ignores categories without any data</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        catnames_labels = {};</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">for </span><span>n = 1:length(catnames)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            thisCat = catnames(n);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span><span class="warning_squiggle_rte457626237">catnames_labels</span><span>{n} = char(thisCat);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            thisData = data(cats == thisCat);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span><span class="warning_squiggle_rte457626237">violins</span><span>(n) = Violin(thisData, n, varargin{:});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        set(gca, </span><span style="color: rgb(170, 4, 249);">'XTick'</span><span>, 1:length(catnames), </span><span style="color: rgb(170, 4, 249);">'XTickLabels'</span><span>, catnames_labels);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% 1D data, no categories</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">elseif </span><span>not(hascategories) &amp;&amp; isvector(data)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        violins = Violin(data, 1, varargin{:});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        set(gca, </span><span style="color: rgb(170, 4, 249);">'XTick'</span><span>, 1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% 2D data with or without categories</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">elseif </span><span>ismatrix(data)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">for </span><span>n=1:size(data, 2)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            thisData = data(:, n);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span><span class="warning_squiggle_rte457626237">violins</span><span>(n) = Violin(thisData, n, varargin{:});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        set(gca, </span><span style="color: rgb(170, 4, 249);">'XTick'</span><span>, 1:size(data, 2));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">if </span><span>hascategories &amp;&amp; length(cats) == size(data, 2)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            set(gca, </span><span style="color: rgb(170, 4, 249);">'XTickLabels'</span><span>, cats);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>[newdata,visdata] = SafeLevelSMOTE(data, minorityLabel, num2Add, options)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Input</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% data: table data with features and labels</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% 1. The right-most variable is treated as labels</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% 2. Features are expected to be numeric values</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% minorityLabel (scalar string): Label to oversample</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% num2Add (scalar numeric): Number of data to generate</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% options.NumNeighbors (scalar integer): number of neighbors to consider</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% options.Standardize (scalar logical):</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Standard-euclidean (true) or Euclidean distance (false) distance to search the neighbors</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Output</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% newdata: generated dataset</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% visdata: optional output for debugging</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%-------------------------------------------------------------------------</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Copyright (c) 2019 Michio Inoue</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">arguments</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    data </span><span style="color: rgb(160, 82, 45);">{mustBeTableWithClassname}</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    minorityLabel </span><span style="color: rgb(160, 82, 45);">(1,1) string</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    num2Add </span><span style="color: rgb(160, 82, 45);">(1,1) double {mustBeNonnegative, mustBeInteger}</span><span> = 0</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    options.NumNeighbors </span><span style="color: rgb(160, 82, 45);">(1,1) double {mustBePositive, mustBeInteger}</span><span> = 5</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    options.Standardize </span><span style="color: rgb(160, 82, 45);">(1,1) logical </span><span>= false;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>numNeighbors = options.NumNeighbors;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">if </span><span>options.Standardize</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    distance = </span><span style="color: rgb(170, 4, 249);">'seuclidean'</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">else</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    distance = </span><span style="color: rgb(170, 4, 249);">'euclidean'</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% If N is smaller than zero, do not oversample data</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">if</span><span>  num2Add &lt;= 0</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    newdata = table;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    visdata = cell(1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">return</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>visdata = cell(num2Add,4);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Optional output for visualization purpose only</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% 1: y, 2: nnarray, 3: y2, 4: synthetic</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% labels of whote dataset</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>labelsAll = string(data{:,end});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% all feature dataset</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>featuresAll = data{:,1:end-1};</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% feature dataset of the minority label</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>featuresMinority = data{labelsAll == minorityLabel,1:end-1};</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Number of minority data</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>NofMinorityData = size(featuresMinority,1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% safe-level of each minority class data</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>safeLevels = zeros(NofMinorityData,1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Save list of neighboring points for each minority data</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>nnarrays = cell(NofMinorityData,1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>ii=1:NofMinorityData</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    y = featuresMinority(ii,:); </span><span style="color: rgb(2, 128, 9);">% a minority data</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    [nnarray, ~] = knnsearch(featuresAll,y,</span><span style="color: rgb(170, 4, 249);">'k'</span><span>,numNeighbors+1,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(170, 4, 249);">'Distance'</span><span>,distance, </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(170, 4, 249);">'SortIndices'</span><span>,true); </span><span style="color: rgb(2, 128, 9);">% search for neighboring points</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% NOTE: this include self y, needs to omit y from nnarray</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    nnarray = nnarray(2:end);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    idx = labelsAll(nnarray) == minorityLabel;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    NofNonMinority = sum(~idx); </span><span style="color: rgb(2, 128, 9);">% number of non-minority data</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    nnarrays{ii} = nnarray(idx); </span><span style="color: rgb(2, 128, 9);">% keeps minority dataset only</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    safeLevels(ii) = numNeighbors-NofNonMinority;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% safe level of y, safeLevelP</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% safe level of nnarray, saveLevelN</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% If the number of minority data is smaller than the requested number of new</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% data set (num2Add), we randomly pick num2Add of minority data to be used to generate</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% data.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">if </span><span>NofMinorityData &gt;= num2Add</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    idx = randperm(NofMinorityData,num2Add);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    featuresMinoritySubset = featuresMinority(idx,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    T1 = num2Add; </span><span style="color: rgb(2, 128, 9);">% Number of data from minority dataset to be used</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    T2 = 1; </span><span style="color: rgb(2, 128, 9);">% Number of newdata from each minority dataset</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">else</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Otherwise we use all minority data</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    idx = randperm(NofMinorityData); </span><span style="color: rgb(2, 128, 9);">% just to randamize</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    featuresMinoritySubset = featuresMinority(idx,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    T1 = NofMinorityData; </span><span style="color: rgb(2, 128, 9);">% Number of data from minority dataset to be used</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    T2 = ceil(num2Add/NofMinorityData); </span><span style="color: rgb(2, 128, 9);">% Number of newdata from each minority dataset</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Note: doe to CEIL the total number of newdata may exceeds the</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% requested #, num2Add. Currently, the below has the routine to stop the process at num2Add.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Array to save the synthesized features</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>newFeatures = zeros(num2Add,size(featuresMinority,2));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>index = 1;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">while </span><span>index &lt; num2Add </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Make sure if num2Add is satisfied since it skips when gan = nan;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">for </span><span>ii=1:T1 </span><span style="color: rgb(2, 128, 9);">% Number of data from minority dataset to be used</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        y = featuresMinoritySubset(ii,:); </span><span style="color: rgb(2, 128, 9);">% a minority data</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        safeLevelP = safeLevels(ii);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        [nnarray, ~] = knnsearch(featuresMinoritySubset,y,</span><span style="color: rgb(170, 4, 249);">'k'</span><span>,numNeighbors+1,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span><span style="color: rgb(170, 4, 249);">'Distance'</span><span>,distance, </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span><span style="color: rgb(170, 4, 249);">'SortIndices'</span><span>,true); </span><span style="color: rgb(2, 128, 9);">% search for neighboring points</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(2, 128, 9);">% NOTE: this include self y, needs to omit y from nnarray</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        nnarray = nnarray(2:end);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">for </span><span>kk=1:T2 </span><span style="color: rgb(2, 128, 9);">% Number of newdata from each minority dataset</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            nn = datasample(nnarray, 1); </span><span style="color: rgb(2, 128, 9);">% pick one (randomly)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            safeLevelN = safeLevels(nn);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            diff = featuresMinoritySubset(nn,:) - y;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            gap = generateGap(safeLevelP, safeLevelN);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span><span style="color: rgb(14, 0, 255);">if </span><span>isnan(gap)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                </span><span style="color: rgb(14, 0, 255);">continue</span><span>; </span><span style="color: rgb(2, 128, 9);">% for case 1</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            synthetic = y + gap.*diff; </span><span style="color: rgb(2, 128, 9);">% “à‘}</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            newFeatures(index,:) = synthetic;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            visdata{index,1} = y;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            visdata{index,2} = featuresMinoritySubset(nnarray,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            visdata{index,3} = featuresMinoritySubset(nn,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            visdata{index,4} = synthetic;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            index = index + 1;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span><span style="color: rgb(14, 0, 255);">if </span><span>index &gt; num2Add</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                </span><span style="color: rgb(14, 0, 255);">break</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% make newFeature to table data with the same variable names</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>tmp = array2table(newFeatures,</span><span style="color: rgb(170, 4, 249);">'VariableNames'</span><span>,data.Properties.VariableNames(1:end-1));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% add label variable</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>newdata = addvars(tmp,repmat(minorityLabel,height(tmp),1),</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(170, 4, 249);">'NewVariableNames'</span><span>,data.Properties.VariableNames(end));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>gap = generateGap(safeLevelP, safeLevelN)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">if </span><span>safeLevelN ~= 0</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    safeLevelRatio = safeLevelP/safeLevelN;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">else</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    safeLevelRatio = inf;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">if </span><span>(isinf(safeLevelRatio) &amp;&amp; safeLevelP == 0) </span><span style="color: rgb(2, 128, 9);">% 1st case</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% When neighbors are all non-minority class (y and its neighbors)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    gap = nan;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% does not generate positive synthetic instance</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">elseif </span><span>(isinf(safeLevelRatio) &amp;&amp; safeLevelP ~= 0) </span><span style="color: rgb(2, 128, 9);">% 2nd case</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% When neighbors' neighbors are all non-minority, but there are</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% minority class around y</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    gap = 0;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">elseif </span><span>(safeLevelRatio == 1) </span><span style="color: rgb(2, 128, 9);">% 3rd case</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    gap = rand();</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">elseif </span><span>(safeLevelRatio &gt; 1) </span><span style="color: rgb(2, 128, 9);">% 4th case</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% When there are more minority class around y</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    gap = rand()/safeLevelRatio;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">elseif </span><span>(safeLevelRatio &lt; 1)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% When there are more minority class around y's neighbor</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    gap = rand()*safeLevelRatio + (1-safeLevelRatio);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">else</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% warning('generateGap() in SafeLevelSmote.m: something is wrong in getting gap');</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    gap = rand();</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>g = sigmoid(z)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Computes sigmoid of z</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>g = 1.0 ./ (1.0 + exp(-z));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>[X, fX, i] = fmincg(</span><span class="warning_squiggle_rte457626237 warningHighlight457626237">f</span><span>, X, options, </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">P1</span><span>, </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">P2</span><span>, </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">P3</span><span>, </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">P4</span><span>, </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">P5</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Minimize a continuous differentialble multivariate function. Starting point</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% is given by "X" (D by 1), and the function named in the string "f", must</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% return a function value and a vector of partial derivatives. The Polack-</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Ribiere flavour of conjugate gradients is used to compute search directions,</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% and a line search using quadratic and cubic polynomial approximations and the</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Wolfe-Powell stopping criteria is used together with the slope ratio method</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% for guessing initial step sizes. Additionally a bunch of checks are made to</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% make sure that exploration is taking place and that extrapolation will not</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% be unboundedly large. The "length" gives the length of the run: if it is</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% positive, it gives the maximum number of line searches, if negative its</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% absolute gives the maximum allowed number of function evaluations. You can</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% (optionally) give "length" a second component, which will indicate the</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% reduction in function value to be expected in the first line-search (defaults</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% to 1.0). The function returns when either its length is up, or if no further</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% progress can be made (ie, we are at a minimum, or so close that due to</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% numerical problems, we cannot get any closer). If the function terminates</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% within a few iterations, it could be an indication that the function value</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% and derivatives are not consistent (ie, there may be a bug in the</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% implementation of your "f" function). The function returns the found</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% solution "X", a vector of function values "fX" indicating the progress made</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% and "i" the number of iterations (line searches or function evaluations,</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% depending on the sign of "length") used.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Usage: [X, fX, i] = fmincg(f, X, options, P1, P2, P3, P4, P5)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% See also: checkgrad </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Copyright (C) 2001 and 2002 by Carl Edward Rasmussen. Date 2002-02-13</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% (C) Copyright 1999, 2000 &amp; 2001, Carl Edward Rasmussen</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Permission is granted for anyone to copy, use, or modify these</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% programs and accompanying documents for purposes of research or</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% education, provided this copyright notice is retained, and note is</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% made of any changes that have been made.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% These programs and documents are distributed without any warranty,</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% express or implied.  As the programs were written for research</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% purposes only, they have not been tested to the degree that would be</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% advisable in any important application.  All use of these programs is</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% entirely at the user's own risk.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% [ml-class] Changes Made:</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% 1) Function name and argument specifications</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% 2) Output display</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Read options</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">if </span><span>exist(</span><span style="color: rgb(170, 4, 249);">'options'</span><span>, </span><span style="color: rgb(170, 4, 249);">'var'</span><span>) &amp;&amp; ~isempty(options) &amp;&amp; isfield(options, </span><span style="color: rgb(170, 4, 249);">'MaxIter'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    length = options.MaxIter;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">else</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    length = 100;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>RHO = 0.01;                            </span><span style="color: rgb(2, 128, 9);">% a bunch of constants for line searches</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>SIG = 0.5;       </span><span style="color: rgb(2, 128, 9);">% RHO and SIG are the constants in the Wolfe-Powell conditions</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>INT = 0.1;    </span><span style="color: rgb(2, 128, 9);">% don't reevaluate within 0.1 of the limit of the current bracket</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>EXT = 3.0;                    </span><span style="color: rgb(2, 128, 9);">% extrapolate maximum 3 times the current bracket</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>MAX = 20;                         </span><span style="color: rgb(2, 128, 9);">% max 20 function evaluations per line search</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>RATIO = 100;                                      </span><span style="color: rgb(2, 128, 9);">% maximum allowed slope ratio</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>argstr = </span><span class="warning_squiggle_rte457626237">[</span><span style="color: rgb(170, 4, 249);">'feval(f, X'</span><span>];                      </span><span style="color: rgb(2, 128, 9);">% compose string used to call function</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>i = 1:(nargin - 3)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>  </span><span class="warning_squiggle_rte457626237">argstr</span><span> = [argstr, </span><span style="color: rgb(170, 4, 249);">',P'</span><span>, int2str(i)];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>argstr = [argstr, </span><span style="color: rgb(170, 4, 249);">')'</span><span>];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">if </span><span>max(size(length)) == 2, red=length(2); length=length(1); </span><span style="color: rgb(14, 0, 255);">else </span><span class="warning_squiggle_rte457626237">red</span><span>=1; </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>S=</span><span class="warning_squiggle_rte457626237">[</span><span style="color: rgb(170, 4, 249);">'Iteration '</span><span>];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>i = 0;                                            </span><span style="color: rgb(2, 128, 9);">% zero the run length counter</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>ls_failed = 0;                             </span><span style="color: rgb(2, 128, 9);">% no previous line search has failed</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>fX = [];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>[f1 </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">df1</span><span>] = eval(argstr);                      </span><span style="color: rgb(2, 128, 9);">% get function value and gradient</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>i = i + (length&lt;0);                                            </span><span style="color: rgb(2, 128, 9);">% count epochs?!</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>s = -df1;                                        </span><span style="color: rgb(2, 128, 9);">% search direction is steepest</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>d1 = -s'*s;                                                 </span><span style="color: rgb(2, 128, 9);">% this is the slope</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>z1 = red/(1-d1);                                  </span><span style="color: rgb(2, 128, 9);">% initial step is red/(|s|+1)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">while </span><span>i &lt; abs(length)                                      </span><span style="color: rgb(2, 128, 9);">% while not finished</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>  i = i + (length&gt;0);                                      </span><span style="color: rgb(2, 128, 9);">% count iterations?!</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>  X0 = X; f0 = f1; df0 = df1;                   </span><span style="color: rgb(2, 128, 9);">% make a copy of current values</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>  X = X + z1*s;                                             </span><span style="color: rgb(2, 128, 9);">% begin line search</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>  [f2 </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">df2</span><span>] = eval(argstr);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>  i = i + (length&lt;0);                                          </span><span style="color: rgb(2, 128, 9);">% count epochs?!</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>  d2 = df2'*s;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>  f3 = f1; d3 = d1; z3 = -z1;             </span><span style="color: rgb(2, 128, 9);">% initialize point 3 equal to point 1</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>  </span><span style="color: rgb(14, 0, 255);">if </span><span>length&gt;0, M = MAX; </span><span style="color: rgb(14, 0, 255);">else </span><span class="warning_squiggle_rte457626237">M</span><span> = min(MAX, -length-i); </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>  success = 0; limit = -1;                     </span><span style="color: rgb(2, 128, 9);">% initialize quanteties</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>  </span><span style="color: rgb(14, 0, 255);">while </span><span>1</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">while </span><span>((f2 &gt; f1+z1*RHO*d1) </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">|</span><span> (d2 &gt; -SIG*d1)) </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">&amp;</span><span> (M &gt; 0) </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      limit = z1;                                         </span><span style="color: rgb(2, 128, 9);">% tighten the bracket</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      </span><span style="color: rgb(14, 0, 255);">if </span><span>f2 &gt; f1</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        z2 = z3 - (0.5*d3*z3*z3)/(d3*z3+f2-f3);                 </span><span style="color: rgb(2, 128, 9);">% quadratic fit</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      </span><span style="color: rgb(14, 0, 255);">else</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        A = 6*(f2-f3)/z3+3*(d2+d3);                                 </span><span style="color: rgb(2, 128, 9);">% cubic fit</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        B = 3*(f3-f2)-z3*(d3+2*d2);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        z2 = (sqrt(B*B-A*d2*z3*z3)-B)/A;       </span><span style="color: rgb(2, 128, 9);">% numerical error possible - ok!</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      </span><span style="color: rgb(14, 0, 255);">if </span><span>isnan(z2) </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">|</span><span> isinf(z2)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        z2 = z3/2;                  </span><span style="color: rgb(2, 128, 9);">% if we had a numerical problem then bisect</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      z2 = max(min(z2, INT*z3),(1-INT)*z3);  </span><span style="color: rgb(2, 128, 9);">% don't accept too close to limits</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      z1 = z1 + z2;                                           </span><span style="color: rgb(2, 128, 9);">% update the step</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      X = X + z2*s;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      [f2 </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">df2</span><span>] = eval(argstr);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      M = M - 1; i = i + (length&lt;0);                           </span><span style="color: rgb(2, 128, 9);">% count epochs?!</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      d2 = df2'*s;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      z3 = z3-z2;                    </span><span style="color: rgb(2, 128, 9);">% z3 is now relative to the location of z2</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">if </span><span>f2 &gt; f1+z1*RHO*d1 </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">|</span><span> d2 &gt; -SIG*d1</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      </span><span style="color: rgb(14, 0, 255);">break</span><span>;                                                </span><span style="color: rgb(2, 128, 9);">% this is a failure</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">elseif </span><span>d2 &gt; SIG*d1</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      success = 1; </span><span style="color: rgb(14, 0, 255);">break</span><span>;                                             </span><span style="color: rgb(2, 128, 9);">% success</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">elseif </span><span>M == 0</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      </span><span style="color: rgb(14, 0, 255);">break</span><span>;                                                          </span><span style="color: rgb(2, 128, 9);">% failure</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    A = 6*(f2-f3)/z3+3*(d2+d3);                      </span><span style="color: rgb(2, 128, 9);">% make cubic extrapolation</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    B = 3*(f3-f2)-z3*(d3+2*d2);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    z2 = -d2*z3*z3/(B+sqrt(B*B-A*d2*z3*z3));        </span><span style="color: rgb(2, 128, 9);">% num. error possible - ok!</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">if </span><span>~isreal(z2) </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">|</span><span> isnan(z2) </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">|</span><span> isinf(z2) </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">|</span><span> z2 &lt; 0   </span><span style="color: rgb(2, 128, 9);">% num prob or wrong sign?</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      </span><span style="color: rgb(14, 0, 255);">if </span><span>limit &lt; -0.5                               </span><span style="color: rgb(2, 128, 9);">% if we have no upper limit</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        z2 = z1 * (EXT-1);                 </span><span style="color: rgb(2, 128, 9);">% the extrapolate the maximum amount</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      </span><span style="color: rgb(14, 0, 255);">else</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        z2 = (limit-z1)/2;                                   </span><span style="color: rgb(2, 128, 9);">% otherwise bisect</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">elseif </span><span>(limit &gt; -0.5) </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">&amp;</span><span> (z2+z1 &gt; limit)          </span><span style="color: rgb(2, 128, 9);">% extraplation beyond max?</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      z2 = (limit-z1)/2;                                               </span><span style="color: rgb(2, 128, 9);">% bisect</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">elseif </span><span>(limit &lt; -0.5) </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">&amp;</span><span> (z2+z1 &gt; z1*EXT)       </span><span style="color: rgb(2, 128, 9);">% extrapolation beyond limit</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      z2 = z1*(EXT-1.0);                           </span><span style="color: rgb(2, 128, 9);">% set to extrapolation limit</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">elseif </span><span>z2 &lt; -z3*INT</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      z2 = -z3*INT;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">elseif </span><span>(limit &gt; -0.5) </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">&amp;</span><span> (z2 &lt; (limit-z1)*(1.0-INT))   </span><span style="color: rgb(2, 128, 9);">% too close to limit?</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      z2 = (limit-z1)*(1.0-INT);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    f3 = f2; d3 = d2; z3 = -z2;                  </span><span style="color: rgb(2, 128, 9);">% set point 3 equal to point 2</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    z1 = z1 + z2; X = X + z2*s;                      </span><span style="color: rgb(2, 128, 9);">% update current estimates</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    [f2 </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">df2</span><span>] = eval(argstr);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    M = M - 1; i = i + (length&lt;0);                             </span><span style="color: rgb(2, 128, 9);">% count epochs?!</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    d2 = df2'*s;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>  </span><span style="color: rgb(14, 0, 255);">end</span><span>                                                      </span><span style="color: rgb(2, 128, 9);">% end of line search</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>  </span><span style="color: rgb(14, 0, 255);">if </span><span>success                                         </span><span style="color: rgb(2, 128, 9);">% if line search succeeded</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    f1 = f2; fX = [fX' f1]';</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    fprintf(</span><span style="color: rgb(170, 4, 249);">'%s %4i | Cost: %4.6e\r'</span><span>, S, i, f1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    s = (df2'*df2-df1'*df2)/(df1'*df1)*s - df2;      </span><span style="color: rgb(2, 128, 9);">% Polack-Ribiere direction</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    tmp = df1; df1 = df2; </span><span class="warning_squiggle_rte457626237">df2</span><span> = tmp;                         </span><span style="color: rgb(2, 128, 9);">% swap derivatives</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    d2 = df1'*s;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">if </span><span>d2 &gt; 0                                      </span><span style="color: rgb(2, 128, 9);">% new slope must be negative</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      s = -df1;                              </span><span style="color: rgb(2, 128, 9);">% otherwise use steepest direction</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      d2 = -s'*s;    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    z1 = z1 * min(RATIO, d1/(d2-realmin));          </span><span style="color: rgb(2, 128, 9);">% slope ratio but max RATIO</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    d1 = d2;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    ls_failed = 0;                              </span><span style="color: rgb(2, 128, 9);">% this line search did not fail</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>  </span><span style="color: rgb(14, 0, 255);">else</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    X = X0; f1 = f0; df1 = df0;  </span><span style="color: rgb(2, 128, 9);">% restore point from before failed line search</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">if </span><span>ls_failed </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">|</span><span> i &gt; abs(length)          </span><span style="color: rgb(2, 128, 9);">% line search failed twice in a row</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>      </span><span style="color: rgb(14, 0, 255);">break</span><span>;                             </span><span style="color: rgb(2, 128, 9);">% or we ran out of time, so we give up</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    tmp = df1; df1 = df2; </span><span class="warning_squiggle_rte457626237">df2</span><span> = tmp;                         </span><span style="color: rgb(2, 128, 9);">% swap derivatives</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    s = -df1;                                                    </span><span style="color: rgb(2, 128, 9);">% try steepest</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    d1 = -s'*s;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    z1 = 1/(1-d1);                     </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    ls_failed = 1;                                    </span><span style="color: rgb(2, 128, 9);">% this line search failed</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>  </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>  </span><span style="color: rgb(14, 0, 255);">if </span><span class="warning_squiggle_rte457626237">exist</span><span>(</span><span style="color: rgb(170, 4, 249);">'OCTAVE_VERSION'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    fflush(stdout);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>  </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>fprintf(</span><span style="color: rgb(170, 4, 249);">'\n'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>[J, grad] = cost(theta, X, y, lambda)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Computes the cost of using theta as the parameter for regularized </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% logistic regression and the gradient of the cost w.r.t. to the parameters. </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Initialize some useful values</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>m = length(y); </span><span style="color: rgb(2, 128, 9);">% number of training examples</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span class="warning_squiggle_rte457626237">J</span><span> = 0;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>grad = zeros(size(theta));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Compute cost function</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>templog(:,1) = log(sigmoid(X*theta));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>templog(:,2) = log(1-(sigmoid(X*theta)));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>tempy(:,1) = y;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>tempy(:,2) = 1-y;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>temp = templog.*tempy;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Formula for cost function. Note theta0 not involved in regularization</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>J = (1/m)*(-sum(temp(:,1))-sum(temp(:,2))) + </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    (lambda/(2*m))*sum(theta(2:end,1).^2);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Compute gradient </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% theta0 not calclated with regularization</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>grad(1,1) = (1/m)*sum((sigmoid(X*theta)-y).*X(:,1)); </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>grad(2:end,1)=((1/m)*((sigmoid(X*theta)-y)'*X(:,2:end)))'+(lambda/m)*theta(2:end);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>grad = grad(:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>[J, grad] = costFunctionReg(theta, X, y, lambda)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   costFunctionReg Compute cost and gradient for logistic regression with regularization</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   J = costFunctionReg(theta, X, y, lambda) computes the cost of using</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   theta as the parameter for regularized logistic regression and the</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   gradient of the cost w.r.t. to the parameters.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Initialize some useful values</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>m = length(y); </span><span style="color: rgb(2, 128, 9);">% number of training examples</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% You need to return the following variables correctly</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span class="warning_squiggle_rte457626237">J</span><span> = 0;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span class="warning_squiggle_rte457626237">grad</span><span> = zeros(size(theta));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% ====================== YOUR CODE HERE ======================</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Instructions: Compute the cost of a particular choice of theta.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%               You should set J to the cost.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%               Compute the partial derivatives and set grad to the partial</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%               derivatives of the cost w.r.t. each parameter in theta</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% calculate cost function</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>h = sigmoid(X*theta);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% calculate penalty</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% excluded the first theta value</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>theta1 = [0 ; theta(2:size(theta), :)];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>p = lambda*(theta1'*theta1)/(2*m);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>J = ((-y)'*log(h) - (1-y)'*log(1-h))/m + p;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% calculate grads</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>grad = (X'*(h - y)+lambda*theta1)/m;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% =============================================================</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>theta = LRTraining(X, y, numLabels, lambda, hessUpdate)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% LRTraining returns the values of theta. Each row of theta corresponds</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% to a single classifier for the number being considered.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Some useful variables</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>m = size(X, 1); </span><span style="color: rgb(2, 128, 9);">% number of examples</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>n = size(X, 2); </span><span style="color: rgb(2, 128, 9);">% how many parameters (features)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>theta = zeros(numLabels, n+1); </span><span style="color: rgb(2, 128, 9);">% (n+1) to account for the x0 term</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>initialTheta = zeros(n+1,1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%options = optimset('GradObj','on','MaxIter',150); % used in fmincg</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%options = optimoptions(@fminunc,'Display','iter','Algorithm','quasi-newton');</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>options = optimoptions(</span><span style="color: rgb(170, 4, 249);">'fminunc'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Algorithm'</span><span>,</span><span style="color: rgb(170, 4, 249);">'quasi-newton'</span><span>,</span><span style="color: rgb(170, 4, 249);">'SpecifyObjectiveGradient'</span><span>,true,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(170, 4, 249);">'HessUpdate'</span><span>,hessUpdate);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Add ones to the X data matrix to account for x0</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X = [ones(m, 1) X];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% fmincg works similarly to fminunc, but is more efficient when </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% dealing with large number of parameters.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>i=1:numLabels</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    yTemp = (y==i); </span><span style="color: rgb(2, 128, 9);">% select all examples of particular number for training</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%disp(yTemp)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%[tempTheta(:,i)] = fmincg(@(t)(cost(t,X,yTemp,lambda)),...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%                           initialTheta,options);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Optimize</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    [</span><span class="warning_squiggle_rte457626237">tempTheta</span><span>(:,i), </span><span class="warning_squiggle_rte457626237">J</span><span>, </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">exit_flag</span><span>] = </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        fminunc(@(t)(costFunctionReg(t, X, yTemp, lambda)), initialTheta, options);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% fmincg was taken from Andrew Ng machine learning course</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    theta(i,:) = tempTheta(:,i)';</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>prediction = LRPredict(theta, X)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% This function returns the predicted label for the given X based on the</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% highest probablity compared among each of the classifiers.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>m = size(X, 1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span class="warning_squiggle_rte457626237">prediction</span><span> = zeros(size(X, 1), 1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Add ones to the X data matrix to account for x0</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X = [ones(m, 1) X];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>tempProb = X * theta';</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>[~,prediction] = max(tempProb ,[],2);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>proba = LRPredictProba(theta, X)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% This function returns the predicted label for the given X based on the</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% highest probablity compared among each of the classifiers.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>m = size(X, 1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Add ones to the X data matrix to account for x0</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X = [ones(m, 1) X];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>proba = sigmoid(X * theta');</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>[h, display_array] = displayData(X, example_width)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%DISPLAYDATA Display 2D data in a nice grid</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   [h, display_array] = DISPLAYDATA(X, example_width) displays 2D data</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   stored in X in a nice grid. It returns the figure handle h and the </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   displayed array if requested.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Set example_width automatically if not passed in</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">if </span><span>~exist(</span><span style="color: rgb(170, 4, 249);">'example_width'</span><span>, </span><span style="color: rgb(170, 4, 249);">'var'</span><span>) || isempty(example_width) </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>	example_width = round(sqrt(size(X, 2)));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Gray Image</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>colormap(gray);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Compute rows, cols</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>[m </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">n</span><span>] = size(X);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>example_height = (n / example_width);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Compute number of items to display</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>display_rows = floor(sqrt(m));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>display_cols = ceil(m / display_rows);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Between images padding</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>pad = 1;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Setup blank display</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>display_array = - ones(pad + display_rows * (example_height + pad), </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                       pad + display_cols * (example_width + pad));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Copy each example into a patch on the display array</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>curr_ex = 1;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>j = 1:display_rows</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>	</span><span style="color: rgb(14, 0, 255);">for </span><span>i = 1:display_cols</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>		</span><span style="color: rgb(14, 0, 255);">if </span><span>curr_ex &gt; m</span><span class="warning_squiggle_rte457626237 warningHighlight457626237">,</span><span> </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>			</span><span style="color: rgb(14, 0, 255);">break</span><span>; </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>		</span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>		</span><span style="color: rgb(2, 128, 9);">% Copy the patch</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>		</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>		</span><span style="color: rgb(2, 128, 9);">% Get the max value of the patch</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>		max_val = max(abs(X(curr_ex, :)));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>		display_array(pad + (j - 1) * (example_height + pad) + (1:example_height), </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>		              pad + (i - 1) * (example_width + pad) + (1:example_width)) = </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>						reshape(X(curr_ex, :), example_height, example_width) / max_val;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>		curr_ex = curr_ex + 1;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>	</span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>	</span><span style="color: rgb(14, 0, 255);">if </span><span>curr_ex &gt; m</span><span class="warning_squiggle_rte457626237 warningHighlight457626237">,</span><span> </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>		</span><span style="color: rgb(14, 0, 255);">break</span><span>; </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>	</span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Display Image</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>h = imagesc(display_array, [-1 1]);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Do not show axis</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>axis </span><span style="color: rgb(170, 4, 249);">image off</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>drawnow;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>p = predictOneVsAll(all_theta, X)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%PREDICT Predict the label for a trained one-vs-all classifier. The labels </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%are in the range 1..K, where K = size(all_theta, 1). </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%  p = PREDICTONEVSALL(all_theta, X) will return a vector of predictions</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%  for each example in the matrix X. Note that X contains the examples in</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%  rows. all_theta is a matrix where the i-th row is a trained logistic</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%  regression theta vector for the i-th class. You should set p to a vector</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%  of values from 1..K (e.g., p = [1; 3; 1; 2] predicts classes 1, 3, 1, 2</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%  for 4 examples) </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>m = size(X, 1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span class="warning_squiggle_rte457626237">num_labels</span><span> = size(all_theta, 1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% You need to return the following variables correctly </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span class="warning_squiggle_rte457626237">p</span><span> = zeros(size(X, 1), 1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Add ones to the X data matrix</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X = [ones(m, 1) X];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% ====================== YOUR CODE HERE ======================</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Instructions: Complete the following code to make predictions using</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%               your learned logistic regression parameters (one-vs-all).</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%               You should set p to a vector of predictions (from 1 to</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%               num_labels).</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Hint: This code can be done all vectorized using the max function.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%       In particular, the max function can also return the index of the </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%       max element, for more information see 'help max'. If your examples </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%       are in rows, then, you can use max(A, [], 2) to obtain the max </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%       for each row.    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>[</span><span class="warning_squiggle_rte457626237 warningHighlight457626237">dummy</span><span>, p] = max(sigmoid(X * all_theta'), [],2);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>stats = confusionMatStats(group,grouphat,weight)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% http://www.mathworks.com/matlabcentral/fileexchange/46035-confusion-matrix--accuracy--precision--specificity--sensitivity--recall--f-score</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% INPUT</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% group = true class labels</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% grouphat = predicted class labels</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% OR INPUT</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% stats = confusionmatStats(group);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% group = confusion matrix from matlab function (confusionmat)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% OUTPUT</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% stats is a structure array</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% stats.confusionMat</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%               Predicted Classes</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%                    p'    n'</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%              ___|_____|_____| </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%       Actual  p |     |     |</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%      Classes  n |     |     |</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Accuracy returns an overall measure of how much the model is correctly predicting on the entire set of data. The basic</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% element of the metric are the single individuals in the dataset: each unit has the same weight and they contribute equally</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% to the Accuracy value.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% When we think about classes instead of individuals, there will be classes with a high number of units and others with</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% just few ones. In this situation, highly populated classes will have higher weight compared to the smallest ones.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Therefore, Accuracy is most suited when we just care about single individuals instead of multiple classes. The key</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% question is "Am I interested in a predicting the highest number of individuals in the right class, without caring about</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% class distribution and other indicators?". If the answer is positive, then the Accuracy is the right indicator.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% stats.accuracy = (TP + TN)/(TP + FP + FN + TN) ; the average accuracy is returned</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% stats.precision = TP / (TP + FP)                  % for each class label</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% stats.sensitivity = TP / (TP + FN)                % for each class label</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% stats.specificity = TN / (FP + TN)                % for each class label</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% stats.recall = sensitivity                        % for each class label</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% stats.Fscore = 2*TP /(2*TP + FP + FN)            % for each class label</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% TP: true positive, TN: true negative, </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% FP: false positive, FN: false negative</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>field1 = </span><span style="color: rgb(170, 4, 249);">'confusionMat'</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">if </span><span>nargin &lt; 3</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    value1 = group;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">else</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    value1 = confusionmat(group,grouphat);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>disp(</span><span style="color: rgb(170, 4, 249);">'test'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>numOfClasses = size(value1,1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span class="warning_squiggle_rte457626237">totalSamples</span><span> = sum(sum(value1));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>rowMat = 0;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>[TP,TN,FP,FN,sensitivity,specificity,precision,f_score_macro,</span><span class="warning_squiggle_rte457626237 warningHighlight457626237">f_score_micro</span><span>,weighted_balanced_accuracy]</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    = deal(zeros(numOfClasses,1));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>class = 1:numOfClasses</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>   TP(class) = value1(class,class);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>   tempMat = value1;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>   tempMat(:,class) = []; </span><span style="color: rgb(2, 128, 9);">% remove column</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>   tempMat(class,:) = []; </span><span style="color: rgb(2, 128, 9);">% remove row</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>   TN(class) = sum(sum(tempMat));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>   FP(class) = sum(value1(:,class))-TP(class);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>   FN(class) = sum(value1(class,:))-TP(class);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>   rowMat = rowMat + (value1(class,class) / sum(value1(class,:)));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>   weight(class) = 1/weight(class); </span><span style="color: rgb(2, 128, 9);">% calculate inverse of frequency</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%field2 = 'accuracy';  value2 = (trace(value1)) / (totalSamples);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>nweight = normalize(weight,</span><span style="color: rgb(170, 4, 249);">'range'</span><span>); </span><span style="color: rgb(2, 128, 9);">%normalize weights</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>class = 1:numOfClasses</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    sensitivity(class) = TP(class) / (TP(class) + FN(class));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    specificity(class) = TN(class) / (FP(class) + TN(class));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    precision(class) = TP(class) / (TP(class) + FP(class));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    f_score_macro(class) = TP(class)/(TP(class) + FP(class));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%f_score_micro(class) = 2*TP(class)/(2*TP(class) + FP(class) + FN(class));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    weighted_balanced_accuracy(class) = sensitivity(class) * nweight(class);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>field2 = </span><span style="color: rgb(170, 4, 249);">'accuracy'</span><span>;  value2 = sum(TP)/sum(TP+FP);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>field3 = </span><span style="color: rgb(170, 4, 249);">'balanced_accuracy'</span><span>;  value3 = sum(sensitivity) / (numOfClasses); </span><span style="color: rgb(2, 128, 9);">%(rowMat)/(numOfClasses);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>field4 = </span><span style="color: rgb(170, 4, 249);">'weighted_balanced_accuracy'</span><span>; value4 = sum(weighted_balanced_accuracy);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>field5 = </span><span style="color: rgb(170, 4, 249);">'weights'</span><span>; value5 = weight;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>field6 = </span><span style="color: rgb(170, 4, 249);">'tp'</span><span>;  value6 = TP;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>field7 = </span><span style="color: rgb(170, 4, 249);">'tn'</span><span>;  value7 = TN;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>field8 = </span><span style="color: rgb(170, 4, 249);">'fp'</span><span>;  value8 = FP;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>field9 = </span><span style="color: rgb(170, 4, 249);">'fn'</span><span>;  value9 = FN;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>field10 = </span><span style="color: rgb(170, 4, 249);">'sensitivity'</span><span>;  value10 = sensitivity;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>field11 = </span><span style="color: rgb(170, 4, 249);">'specificity'</span><span>;  value11 = specificity;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>field12 = </span><span style="color: rgb(170, 4, 249);">'precision'</span><span>;  value12 = precision;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>field13 = </span><span style="color: rgb(170, 4, 249);">'recall'</span><span>;  value13 = sensitivity;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>field14 = </span><span style="color: rgb(170, 4, 249);">'Fscore_macro'</span><span>;  value14 = sum(f_score_macro)/numOfClasses;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>field15 = </span><span style="color: rgb(170, 4, 249);">'Fscore_micro'</span><span>;  value15 = sum(TP)/sum(TP+FP);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>stats = struct(field1,value1,field2,value2,field3,value3,field4,value4,field5,value5,field6,value6,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>               field7,value7,field8,value8,field9,value9,field10,value10,field11,value11,field12,value12,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>               field13,value13,field14,value14,field15,value15);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>[W, b] = LRTrain(X_train, y_train, lambda, </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">n</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%Logistic Regression that operates a multinomial Logistic Regression on input</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%% INITIALIZATIONS</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%lambda = 0.01;  %regularization coef</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>epochs = 50; </span><span style="color: rgb(2, 128, 9);">%Change to 300 for final training</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>[n,D] = size(X_train);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>W = rand(D, n);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>b = zeros(1, n);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>l2 = 0.0;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span class="warning_squiggle_rte457626237">epochs_costs</span><span> = [];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% converting labels to one-hot represatiation</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_hot = full(ind2vec(y_train',n))';</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%% TRAIN</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Gradient Descent</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>e=1:epochs</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    diff = softmax((X_train * W + b)')' - y_hot; </span><span style="color: rgb(2, 128, 9);">% calculating gradient</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    grad = X_train' * diff;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    W = W - (lambda * grad + (lambda * l2 * W)); </span><span style="color: rgb(2, 128, 9);">% Updating W &amp; b</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    b = b - (lambda * sum(diff));    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>[preds] = LRPrediction(X_test, </span><span class="warning_squiggle_rte457626237 warningHighlight457626237">y_test</span><span>, W ,b)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%% TEST</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>sm = softmax((X_test * W + b)')';</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>[~ , preds] = </span><span class="warning_squiggle_rte457626237">max</span><span>(sm, [], 2);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Custom validation function</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% https://jp.mathworks.com/help/matlab/matlab_prog/function-argument-validation-1.html</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%-------------------------------------------------------------------------</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Copyright (c) 2019 Michio Inoue</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>mustBeTableWithClassname(arg)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    features = arg{:,1:end-1};</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    class = arg{:,end};</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">if </span><span>~isnumeric(features)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        error(</span><span class="warning_squiggle_rte457626237">[</span><span style="color: rgb(170, 4, 249);">'not numeric features'</span><span>])</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">if </span><span>~isstring(class)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        display(class)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        error(</span><span class="warning_squiggle_rte457626237">[</span><span style="color: rgb(170, 4, 249);">'not a string classname'</span><span>])</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>oobErr = oobErrorRF(params,X,split_criterion)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%oobErrRF Trains random forest and estimates out-of-bag quantile error</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   oobErr trains a random forest of classification trees using the</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   predictor data in X and the parameter specification in params, and then</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   returns the out-of-bag quantile error based on the median. X is a table</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   and params is an array of OptimizableVariable objects corresponding to</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%   the minimum leaf size and number of predictors to sample at each node.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>randomForest = TreeBagger(params.maxNumTrees,X,</span><span style="color: rgb(170, 4, 249);">'Kingdom'</span><span>,</span><span style="color: rgb(170, 4, 249);">"SampleWithReplacement"</span><span>, </span><span style="color: rgb(170, 4, 249);">"on"</span><span>,</span><span style="color: rgb(170, 4, 249);">'Method'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Classification'</span><span>,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                          </span><span style="color: rgb(170, 4, 249);">'OOBPrediction'</span><span>,</span><span style="color: rgb(170, 4, 249);">'On'</span><span>, </span><span style="color: rgb(170, 4, 249);">'OOBPredictorImportance'</span><span>,</span><span style="color: rgb(170, 4, 249);">'On'</span><span>,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                          </span><span style="color: rgb(170, 4, 249);">'MinLeafSize'</span><span>,params.minLeafSize,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                          </span><span style="color: rgb(170, 4, 249);">'NumPredictorstoSample'</span><span>,params.numPredictorstoSample,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                          </span><span style="color: rgb(170, 4, 249);">'MaxNumSplits'</span><span>,params.maxNumSplits, </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                          </span><span style="color: rgb(170, 4, 249);">'Prior'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Empirical'</span><span>, </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                          </span><span style="color: rgb(170, 4, 249);">'SplitCriterion'</span><span>,split_criterion);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>oobErr = oobError(randomForest, </span><span style="color: rgb(170, 4, 249);">'Mode'</span><span>,</span><span style="color: rgb(170, 4, 249);">'ensemble'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>[q1,q2,q3,w0,w1,outliers] = boxplot_statistics(data, whisker)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">if </span><span>~exist(</span><span style="color: rgb(170, 4, 249);">'whisker'</span><span>, </span><span style="color: rgb(170, 4, 249);">'var'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        </span><span style="color: rgb(2, 128, 9);">% whisker is 1.5 by default</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        whisker = 1.5;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% quantile(data,3) will return the 25th, 50th, and 75th percentile</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% for each column</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    quants = quantile(data, 3);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    q1 = quants(1,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    q2 = quants(2,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    q3 = quants(3,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Compute the upper and lower thresholds for outlier classification</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    upper_thresh = q3 + whisker .* (q3-q1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    lower_thresh = q1 - whisker .* (q3-q1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Outliers are points above the upper_thresh or below lower_thresh</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    outliers = (data &gt; upper_thresh) | (data &lt; lower_thresh);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% To compute the whiskers, take max and min (per column). Setting</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% outlier values to NaN causes them to be ignored.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    data(outliers) = NaN;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    w0 = min(data,[],1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    w1 = max(data,[],1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Computes several quantities based on the model-based confusion matrix of</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% a classifier. The model specification could be the ground truth or an</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% estimate of it.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Usage:</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     [TPR, FPR, PPV, AUC, AP] = prc_compute_stats(alpha, muN, sigmaN, muP, sigmaP)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Arguments:</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     alpha: fraction of examples from positive class (0 &lt; alpha &lt; 1)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     muN: mean of decision values from negative class</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     sigmaN: std.dev. of decision values from negative class (must be &gt; 0)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     muP: mean of decision values from positive class</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     sigmaP: std.dev. of decision values from positive class  (must be &gt; 0)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     nPoints (optional): number of thresholds to consider (default: 1000)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Return values:</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     TPR: true positive rate (recall)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     FPR: false positive rate</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     PPV: positive predictive value (precision)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     AUC: area under the ROC curve</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     AP: area under the PR curve (average precision)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Literature:</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     K.H. Brodersen, C.S. Ong, K.E. Stephan, J.M. Buhmann (2010). The</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     binormal assumption on precision-recall curves. In: Proceedings of</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     the 20th International Conference on Pattern Recognition (ICPR).</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Kay H. Brodersen &amp; Cheng Soon Ong, ETH Zurich, Switzerland</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% $Id: prc_stats.m 6393 2010-06-14 15:24:46Z bkay $</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% -------------------------------------------------------------------------</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>[TPR, FPR, PPV, AUC, AP] = prc_stats(alpha, muN, sigmaN, muP, sigmaP, nPoints)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Set interpolation accuracy: the higher the more accurate</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">try</span><span class="warning_squiggle_rte457626237 warningHighlight457626237">;</span><span> </span><span class="warning_squiggle_rte457626237">nPoints</span><span>; </span><span style="color: rgb(14, 0, 255);">catch</span><span>; nPoints = 1000; </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Check input</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    assert(isscalar(alpha) &amp;&amp; isscalar(muN) &amp;&amp; isscalar(sigmaN) &amp;&amp; isscalar(muP) &amp;&amp; isscalar(sigmaP) &amp;&amp; isscalar(nPoints));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    assert(0&lt;alpha &amp;&amp; alpha&lt;1, </span><span style="color: rgb(170, 4, 249);">'class balance ''alpha'' must be strictly between 0 and 1'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    assert(sigmaN&gt;0 &amp;&amp; sigmaP&gt;0, </span><span style="color: rgb(170, 4, 249);">'variances must be positive'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    assert(nPoints&gt;1, </span><span style="color: rgb(170, 4, 249);">'must use at least 2 interpolation points (nPoints)'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">if </span><span>nPoints&lt;10, warning(</span><span style="color: rgb(170, 4, 249);">'nPoints is very small and may result in highly inaccurate estimates'</span><span>); </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Set thresholds between data points</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    thr = linspace(muN-5*sigmaN, muP+5*sigmaP, nPoints);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    assert(length(thr)&gt;1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Compute parametric confusion matrix</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    TP = alpha.*(1-normcdf(thr,muP,sigmaP));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    FP = (1-alpha).*(1-normcdf(thr,muN,sigmaN));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    FN = alpha.*normcdf(thr,muP,sigmaP);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    TN = (1-alpha).*normcdf(thr,muN,sigmaN);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Compute rates</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    TPR = TP./(TP+FN);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    FPR = FP./(FP+TN);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    PPV = TP./(TP+FP);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Area under the ROC curve</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    A = (muP-muN)/sigmaP; B = sigmaN/sigmaP;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    AUC = normcdf(A/sqrt(1+B^2));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Area under the PR curve</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    AP = abs(trapz(TPR,PPV));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Computes smooth estimates of statistics based on classification output,</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% based on either the binormal or the alpha-binormal model.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Usage:</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     [TPR, FPR, PPV, AUC, AP] = prc_stats_binormal(targs, dvs, alpha_binormal)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Arguments:</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     targs: a vector of true class labels (targets). The vector must only</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%         contain the values -1 (for negative examples) and +1 (for</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%         positive examples).</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     dvs: a vector of decision values. The vector must have the same size</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%         as 'targs'</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     alpha_binormal: whether to use the alpha-binormal model, in</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%         which the class imbalance is estimated from the data (default =</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%         false, i.e., classes are assumed to be perfectly balanced).</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%         This setting is highly recommended for smooth estimates of the</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%         precision-recall curve.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Return values:</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     TPR: true positive rate (recall)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     FPR: false positive rate</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     PPV: positive predictive value (precision)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     AUC: area under the ROC curve</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     AP: area under the PR curve (average precision)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Literature:</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     K.H. Brodersen, C.S. Ong, K.E. Stephan, J.M. Buhmann (2010). The</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     binormal assumption on precision-recall curves. In: Proceedings of</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     the 20th International Conference on Pattern Recognition (ICPR).</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Kay H. Brodersen &amp; Cheng Soon Ong, ETH Zurich, Switzerland</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% $Id: prc_stats_binormal.m 6393 2010-06-14 15:24:46Z bkay $</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% -------------------------------------------------------------------------</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>[TPR, FPR, PPV, AUC, AP] = prc_stats_binormal(targs, dvs, alpha_binormal)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Set default values</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">try</span><span class="warning_squiggle_rte457626237 warningHighlight457626237">,</span><span> </span><span class="warning_squiggle_rte457626237">estimateClassImbalance</span><span>; </span><span style="color: rgb(14, 0, 255);">catch</span><span>; </span><span class="warning_squiggle_rte457626237">estimateClassImbalance</span><span> = false; </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Check input</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    targs = targs(:)';</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    assert(all(targs==-1 | targs==1), </span><span style="color: rgb(170, 4, 249);">'targs must only contain -1 and 1'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    dvs = dvs(:)';</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    assert(length(targs)==length(dvs), </span><span style="color: rgb(170, 4, 249);">'targs and dvs must have the same number of elements'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    assert(isscalar(alpha_binormal) &amp;&amp; ~</span><span class="warning_squiggle_rte457626237">isstr</span><span>(alpha_binormal), </span><span style="color: rgb(170, 4, 249);">'alpha_binormal must be true or false'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Get class-conditional decision values</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    pos = dvs(targs == 1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    neg = dvs(targs == -1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    assert(length(pos)&gt;=2 &amp;&amp; length(neg)&gt;=2, </span><span style="color: rgb(170, 4, 249);">'targs must contain at least two examples of either class'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Estimate mean and std.dev. from the data</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    muP = mean(pos);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    muN = mean(neg);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    sigmaP = std(pos);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    sigmaN = std(neg);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    assert(sigmaP&gt;0 &amp; sigmaN&gt;0, </span><span style="color: rgb(170, 4, 249);">'dvs must allow for estimation of positive class-conditional standard deviations'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Estimate class balance as well?</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">if </span><span>alpha_binormal</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        alpha = length(pos)/length(targs);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        assert(alpha&gt;=0 &amp;&amp; alpha&lt;=1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">else</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        alpha = 0.5;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Compute stats</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    [TPR, FPR, PPV, AUC, AP] = prc_stats(alpha, muN, sigmaN, muP, sigmaP);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>plt = compute_prc_roc(targs, dvs,PRC_or_ROC,</span><span class="warning_squiggle_rte457626237 warningHighlight457626237">codon_class</span><span>,class_number,kfold,legends,plt)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Modified by Bernardo Azevedo for multi-classification </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Application of methods for estimating a</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% precision-recall curve (PRC) and receiver operator curve (ROC) .</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Generates decision values from a binormal distribution and plots true vs.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% empirical vs. model-based quantities derived from the confusion matrix of</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% the simulated classifier.</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Usage:</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     prc_demo</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Literature:</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     K.H. Brodersen, C.S. Ong, K.E. Stephan, J.M. Buhmann (2010). The</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     binormal assumption on precision-recall curves. In: Proceedings of</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%     the 20th International Conference on Pattern Recognition (ICPR).</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Kay H. Brodersen &amp; Cheng Soon Ong, ETH Zurich, Switzerland</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% $Id: prc_demo.m 5529 2010-04-22 21:10:32Z bkay $</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% -------------------------------------------------------------------------</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Compute empirical curves</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%[TPR_emp, FPR_emp, PPV_emp] = prc_stats_empirical(targs, dvs);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Compute smooth curves (binormal model)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>[TPR_bin, FPR_bin, PPV_bin] = prc_stats_binormal(targs, dvs, false);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Compute smooth curves (alpha-binormal model)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%[TPR_abin, FPR_abin, PPV_abin] = prc_stats_binormal(targs, dvs, true);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>CM = jet(3);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% -------------------------------------------------------------------------</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span class="warning_squiggle_rte457626237">cols</span><span> = [200 45 43; 37 64 180; 0 176 80; 0 0 0]/255;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">if </span><span>PRC_or_ROC==</span><span style="color: rgb(170, 4, 249);">"PRC"</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Plot PR curves</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%figure; hold on;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    pl = plot(TPR_bin, PPV_bin, </span><span style="color: rgb(170, 4, 249);">'-'</span><span>, </span><span style="color: rgb(170, 4, 249);">'color'</span><span>, [CM(class_number,:) 0.6], </span><span style="color: rgb(170, 4, 249);">'linewidth'</span><span>, 2);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    plt(class_number) = pl; </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    axis([0 1 0 1]);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%xlabel('TPR (recall)'); ylabel('PPV (precision)'); title('PR curves');</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    xlabel(</span><span style="color: rgb(170, 4, 249);">'Recall'</span><span>); ylabel(</span><span style="color: rgb(170, 4, 249);">'Precision'</span><span>); title([</span><span style="color: rgb(170, 4, 249);">'PR AUC curves for Fold: '</span><span>, num2str(kfold)]);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">if </span><span>class_number == 3</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        legend(plt,legends,</span><span style="color: rgb(170, 4, 249);">'location'</span><span>,</span><span style="color: rgb(170, 4, 249);">'southeast'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    set(gca, </span><span style="color: rgb(170, 4, 249);">'box'</span><span>, </span><span style="color: rgb(170, 4, 249);">'on'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">elseif </span><span>PRC_or_ROC==</span><span style="color: rgb(170, 4, 249);">"ROC"</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Plot ROC curves</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%figure; hold on;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    pl = plot(FPR_bin, TPR_bin, </span><span style="color: rgb(170, 4, 249);">'-'</span><span>, </span><span style="color: rgb(170, 4, 249);">'color'</span><span>, [CM(class_number,:) 0.6], </span><span style="color: rgb(170, 4, 249);">'linewidth'</span><span>, 1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    plt(class_number) = pl;   </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    plot([0 1], [0 1], </span><span style="color: rgb(170, 4, 249);">'-'</span><span>, </span><span style="color: rgb(170, 4, 249);">'color'</span><span>, [0.7 0.7 0.7], </span><span style="color: rgb(170, 4, 249);">'linewidth'</span><span>, 2);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    axis([0 1 0 1]);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    xlabel(</span><span style="color: rgb(170, 4, 249);">'FPR'</span><span>); ylabel(</span><span style="color: rgb(170, 4, 249);">'TPR'</span><span>); title([</span><span style="color: rgb(170, 4, 249);">'ROC curves for Fold: '</span><span>, num2str(kfold)]);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">if </span><span>class_number == 3</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        legend(plt,legends,</span><span style="color: rgb(170, 4, 249);">'location'</span><span>,</span><span style="color: rgb(170, 4, 249);">'southeast'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    set(gca, </span><span style="color: rgb(170, 4, 249);">'box'</span><span>, </span><span style="color: rgb(170, 4, 249);">'on'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>[X_train_balanced, y_train_balanced] = smote_and_undersampling(X_train,y_train,smote_proportion,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    undersampling_proportion,smote_undersampling_choice)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% 1 - SMOTE</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Define the number of neighbours (k = 10) to use as one of the parameters in the comparison</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% and proportion of increase (5 times)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>k = 10;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%smote_proportion = 5;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_train_label = addvars(array2table(X_train), string(y_train),</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(170, 4, 249);">'NewVariableNames'</span><span>,</span><span style="color: rgb(170, 4, 249);">'label'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>tbl = tabulate(X_train_label.label);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>t_ratio_class = array2table(tbl,</span><span style="color: rgb(170, 4, 249);">'VariableNames'</span><span>, </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    {</span><span style="color: rgb(170, 4, 249);">'Value'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Count'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Percent'</span><span>});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>uniqueLabels = string(tbl(:,1));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Define number of samples to add for minority class</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>smote_samples = round(cell2mat(table2array(t_ratio_class(1,2))) * smote_proportion,0);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% We define samples for minority class and 0 for the other classes</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>num2Add = [smote_samples,0,0];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>newdata = table;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>visdataset = cell(length(uniqueLabels),1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Define for each class</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>ii=1:length(uniqueLabels)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    [tmp,visdata] = SafeLevelSMOTE(X_train_label,uniqueLabels(ii),num2Add(ii),</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>                </span><span style="color: rgb(170, 4, 249);">"NumNeighbors"</span><span>,k, </span><span style="color: rgb(170, 4, 249);">"Standardize"</span><span>, false);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span class="warning_squiggle_rte457626237">newdata</span><span> = [newdata; tmp];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    visdataset{ii} = visdata;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Finally we save the added samples to an array (removing the last column)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>smote_class1 = table2array(newdata(:,1:end-1));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Finally we save the added samples to an array (removing the last column)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_train = [X_train ; smote_class1];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% For y_train we save only the last column (label) </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% which is composed of the original training set with added samples</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_train = [y_train; categorical(table2array(newdata(:,end)))];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">if </span><span>smote_undersampling_choice == </span><span style="color: rgb(170, 4, 249);">"smote_undersampling"</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% 2 - Undersampling</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% For reproducibility</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    rng(1,</span><span style="color: rgb(170, 4, 249);">'twister'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Concatenate X_Train columns after SMOTE with label columns</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    X_train_label = addvars(array2table(X_train), string(y_train),</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(170, 4, 249);">'NewVariableNames'</span><span>,</span><span style="color: rgb(170, 4, 249);">'label'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    tbl = tabulate(X_train_label.label);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    t_ratio_class = array2table(tbl,</span><span style="color: rgb(170, 4, 249);">'VariableNames'</span><span>, </span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>        {</span><span style="color: rgb(170, 4, 249);">'Value'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Count'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Percent'</span><span>});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Calculate number of samples for undersampling step</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    under_samples = round(cell2mat(table2array(t_ratio_class(1,2))) / undersampling_proportion,0);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    disp(under_samples)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Create arrays for sampling purposes</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    x_rus = table2array(X_train_label);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    y_rus = x_rus(:,end);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Filter between majority class and the other 2 classes</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    X_maj = x_rus(</span><span class="warning_squiggle_rte457626237 warningHighlight457626237">find</span><span>(y_rus == </span><span style="color: rgb(170, 4, 249);">"euk"</span><span>),:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    X_rest = x_rus(</span><span class="warning_squiggle_rte457626237 warningHighlight457626237">find</span><span>(y_rus == </span><span style="color: rgb(170, 4, 249);">"arc" </span><span>| y_rus == </span><span style="color: rgb(170, 4, 249);">"bct"</span><span>),:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Generate random indexes for random undersampling</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    rp = randperm(size(X_maj,1));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    random_sample = rp(1:under_samples);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    X_rand_maj = X_maj(random_sample,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    X_train_balanced = [str2double(X_rand_maj(:,1:end-1))  ; str2double(X_rest(:,1:end-1))];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    y_train_balanced = [X_rand_maj(:,end) ; X_rest(:,end)];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">else</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>   X_train_balanced = X_train;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>   y_train_balanced = y_train;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>ObjFcn = makeObjFcn(</span><span class="nonlocalVariableHighlighting">k_fold</span><span>, </span><span class="nonlocalVariableHighlighting">X</span><span>, </span><span class="nonlocalVariableHighlighting">splitCriterion</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>     </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>ObjFcn = @valErrorFun;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>objective = valErrorFun(optVars,~)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Set KFold</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>K = </span><span class="nonlocalVariableHighlighting">k_fold</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>rng(1, </span><span style="color: rgb(170, 4, 249);">'twister'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>X_train = table2array(</span><span class="nonlocalVariableHighlighting">X</span><span>(:,1:end-1));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_train = table2array(</span><span class="nonlocalVariableHighlighting">X</span><span>(:,end));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Change classes to numerical data</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_train_num = renamecats(categorical(y_train),{</span><span style="color: rgb(170, 4, 249);">'arc'</span><span>,</span><span style="color: rgb(170, 4, 249);">'bct'</span><span>,</span><span style="color: rgb(170, 4, 249);">'euk'</span><span>},{</span><span style="color: rgb(170, 4, 249);">'1'</span><span>,</span><span style="color: rgb(170, 4, 249);">'2'</span><span>,</span><span style="color: rgb(170, 4, 249);">'3'</span><span>});</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>y_train_num = str2double(string(y_train_num));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>indices=crossvalind(</span><span style="color: rgb(170, 4, 249);">'Kfold'</span><span>,y_train_num,K);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">%leaf = 5;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span class="warning_squiggle_rte457626237">numSplits</span><span> = 50; </span><span style="color: rgb(2, 128, 9);">% 20 25];</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span class="warning_squiggle_rte457626237">numPredictors</span><span> = 15;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>errorMat = zeros(1,K);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">for </span><span>i_fold=1:K</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Assigning training and validation set indexes</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    val = (indices == i_fold);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    train = ~val;</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Training set</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    Xf_train = X_train(train,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    yf_train = y_train(train);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Validation set</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    Xf_val = X_train(val,:);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    yf_val = y_train(val);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Apply SMOTE only (300 % more synthetic samples)</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    [Xf_train_balanced, yf_train_balanced] = smote_and_undersampling(Xf_train, yf_train, 3, 0,</span><span style="color: rgb(170, 4, 249);">"smote"</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    rfGS = TreeBagger(128,Xf_train_balanced,yf_train_balanced, </span><span style="color: rgb(170, 4, 249);">"SampleWithReplacement"</span><span>, </span><span style="color: rgb(170, 4, 249);">"on"</span><span>,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span><span style="color: rgb(170, 4, 249);">'Method'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Classification'</span><span>,</span><span style="color: rgb(170, 4, 249);">'OOBPrediction'</span><span>,</span><span style="color: rgb(170, 4, 249);">'On'</span><span>,</span><span style="color: rgb(170, 4, 249);">'OOBPredictorImportance'</span><span>,</span><span style="color: rgb(170, 4, 249);">'On'</span><span>,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span><span style="color: rgb(170, 4, 249);">'MinLeafSize'</span><span>,optVars.minLeafSize,</span><span style="color: rgb(170, 4, 249);">'MaxNumSplits'</span><span>,optVars.maxNumSplits,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span><span style="color: rgb(170, 4, 249);">'NumPredictorsToSample'</span><span>,optVars.numPredictorstoSample,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>            </span><span style="color: rgb(170, 4, 249);">'SplitCriterion'</span><span>,</span><span class="nonlocalVariableHighlighting">splitCriterion</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    predicted_val = cellstr(predict(rfGS,Xf_val)); </span><span style="color: rgb(2, 128, 9);">% Prediction of RF model for testing set</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Check the success of the classifier</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%cp = classperf(cellstr(yf_val), predicted_val);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">%testval = testval + cp.ErrorRate;  </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    index = cellfun(@strcmp,predicted_val,cellstr(yf_val));</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    errorMat(i_fold) = sum(index)/length(yf_val);</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Calculate misclassification error (1 - mean(errors))</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>objective = 1-mean(errorMat); </span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>    </span><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div><div class="inlineWrapper"><div  class = 'S8'></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div></div><div  class = 'S10'></div></div>
<br>
<!-- 
##### SOURCE BEGIN #####

%% 0. Problem statement
% 
% 
% RNA is the code that creates proteins inside organisms.
% 
% RNA is organised into groups of 3 and each group is a triple nitrogenous base.
% 
% Codon is a triple nitrogenous base sequence present on mRNA (RNA messenger).
% 
% A codon is a sequence of three DNA or RNA nucleotides that corresponds with 
% a specific amino acid or stop signal during protein synthesis. DNA and RNA molecules 
% are written in a language of four nucleotides; meanwhile, the language of proteins 
% includes 20 amino acids. Codons provide the key that allows these two languages 
% to be translated into each other. Each codon corresponds to a single amino acid 
% (or stop signal), and the full set of codons is called the genetic code. The 
% genetic code includes 64 possible permutations, or combinations, of three-letter 
% nucleotide sequences that can be made from the four nucleotides. Of the 64 codons, 
% 61 represent amino acids, and three are stop signals mark the end of a protein.
% 
% The mRNA sequence is thus used as a template to assemble—in order—the chain 
% of amino acids that form a protein. 
% 
% The frequency of codon use in each organism can be determined and was originally 
% developed by Professor Toshimichi Ikemura at <http://spinner.lab.nig.ac.jp/lab_evol/home-e.html 
% Laboratory of Evolutionary Genetics,> <http://www.nig.ac.jp/ National Institute 
% of Genetics.>
% 
% 
% 
% The dataset is made of 64 features
%% 1. Data loading and preprocessing
% Our dataset is availabe to download in <https://archive.ics.uci.edu/ml/datasets/Codon+usage 
% https://archive.ics.uci.edu/ml/datasets/Codon+usage> in CSV file format and 
% can be publicly accessed. 
% 
% We are assuming the dataset is located in the folder below considering the 
% script is located in the root folder:
% 
% root\Dataset\CodonUsageDataset
% 1.1 Data Load

% Clear variables and close any open document

clear, close all;
% Add path to reproduce the code in another environment
addpath('.\Dataset\CodonUsageDataset')
% Placeholder text to treat as an empty value, 

% specified as the comma-separated pair consisting of 'TreatAsMissing' and a character vector, % cell array of character vectors, string, or string array. Table elements corresponding to these characters are set to NaN.
% 'TreatAsEmpty' only applies to numeric columns in the file and cannot handle numeric values specified as text, such as '-99'.
codon = readtable('codon_usage.csv',"TreatAsEmpty",{'.','NA'});

head(codon)

% 1.2 Data understanding and scope definition
% let's take a copy of the raw file if we need to pre process again

codonOriginal = codon;
%% 
% We use the method *head* to plot and investigate a few samples of the dataset 
% and understand the relation between the dependent variable and independent variables.
% 
% 

head(codon,10)
%% 
% Now a few properties of the dataset

codon.Properties.VariableNames'

%% 
% The variable names are already self explanatory therefore we don't need to 
% rename them can categorise them accordingly.
% 
% Column 1: Kingdom
%% 
% * The 'Kingdom' is a 3-letter code corresponding to `xxx' in the CUTG database 
% name: 'arc'(archaea), 'bct'(bacteria), 'phg'(bacteriophage), 'plm' (plasmid), 
% 'pln' (plant), 'inv' (invertebrate), 'vrt' (vertebrate), 'mam' (mammal), 'rod' 
% (rodent), 'pri' (primate), and 'vrl'(virus) sequence entries. Note that the 
% CUTG database does not contain 'arc' and 'plm' (these have been manually curated 
% ourselves).
%% 
% Column 2: DNAtype
%% 
% * The 'DNAtype' is denoted as an integer for the genomic composition in the 
% species: 0-genomic, 1-mitochondrial, 2-chloroplast, 3-cyanelle, 4-plastid, 5-nucleomorph, 
% 6-secondary_endosymbiont, 7-chromoplast, 8-leucoplast, 9-NA, 10-proplastid, 
% 11-apicoplast, and 12-kinetoplast.
%% 
% Column 3: SpeciesID
% 
% Column 4: Ncodons
% 
% Column 5: SpeciesName
% 
% Columns 6-69: codon (header: nucleotide bases; entries: frequency of usage 
% (5 digit floating point number))
% 
% Codon frequencies 
% 
% Replacing "Kingdom" column (dependent variable) values to adapt to the problem 
% classification.
% 
% The values will be remapped to correspond to the 3 classes of Kingdoms of 
% life:
% 
% 
% 
% Due to a controversial debate amongst viruses as to whether they can be included 
% in the tree of life then we will discard 'vrl' from the classification problem.
% 
% Another question posed by the biologists are related to phg classification 
% in which group they should be classified. Given that we will also discard 'phg' 
% from the problem.
% 
% For historical reasons, bacteriophage is widely used to refer to viruses of 
% bacteria (and sometimes even archaea). The problem with such nomenclature is 
% that it artificially divides the virosphere into two camps, with viruses of 
% bacteria and archaea on one hand and viruses of eukaryotes on the other. 
% 
% The term plasmid was first introduced by the American molecular biologist 
% Joshua Lederberg in 1952. Plasmids are considered replicons. They can be found 
% in all three major domains: *Archaea, Bacteria, and Eukarya*. Similar to viruses, 
% plasmids are not considered by some to be a form of life. Therefore 'plm' will 
% not be included as well.
% 
% From the original 11 classes of kingdoms we have 8 left in which 6 of them 
% (plant, invertebrate, vertebrate, mammal, rodent, primate) we decided to classify 
% as Eukaryotas and rename the values as 'euk' in order to reduce the complexity 
% and still maintain a fairly robust classification problem. Other than that, 
% there are another 2 groups ('arc' and 'bct' which are correspondent to the domains 
% of Bacteria and Archaea).
% 
% 'arc'(archaea), 'bct'(bacteria), 'phg'(bacteriophage), 
% 
% 'plm' (plasmid)
% 
% 'vrl'(virus)
% 
% Eukaryotas ('euk')
% 
% 'pln' (plant), 'inv' (invertebrate), 'vrt' (vertebrate), 'mam' (mammal), 'rod' 
% (rodent), 'pri' (primate), and

%codon.Kingdom(strcmpi(codon.Kingdom,'pln')) = {0};
codon.Kingdom = regexprep(codon.Kingdom, {'pln' 'inv' 'vrt' 'mam' 'rod' 'pri'}, 'euk')
% 1.2.3 *Remove 'vrl', 'phg' and 'plm' classes*
% Now we remove the Kingdom values (classes) which are not in the scope of the 
% model.

% Specify values
kingdom_out_scope = ['vrl';'phg';'plm'];
% Specify conditions
is_out_scope = ismember(codon.Kingdom,kingdom_out_scope) ~= 0;

% remove
codon(is_out_scope,:) = []


%new_table = my_Table(~(my_Table.data7 > 1000 | my_Table.data7 < 100),:); % filter and remove
%cleanedData_2.Pregnancy(isnan(cleanedData_2.Pregnancy))
%% 
% a


disp((codon.Properties.VariableNames)')
% 1.3 Missing values analysis
% Let's investigate to verify if missing values are found

% Find rows with missing values that have at least one missing value '' '.' 'NA' NaN -99

TF = ismissing(codon,{'' '.' 'NA' NaN -99});
rowsWithMissing = codon(any(TF,2),:);
disp(rowsWithMissing)
%% 
% Given that there is only one row with missing values

codon(any(TF,2),:) = []
%%
variables_codon = codonOriginal.Properties.VariableNames;
f=figure;
f.Position = [100 100 1000 400];
imagesc(ismissing(codonOriginal))
ax = gca;
ax.XTick = 1:69;
ax.XTickLabel = variables_codon;
ax.XTickLabelRotation = 90;
title('Missing values in the Codon dataset')
%% 
% 
%% 
% 

summary(codon)
% 1.4 Basic statistics 
% Let's calculate the number of samples per class and basic statistics about 
% the dependent variables.


% Unique values and count for dependent variable
ckingdom = codon.Kingdom;
[C,ia,ic] = unique(codon.Kingdom);
a_counts = accumarray(ic,1); 
a_proportion = accumarray(ic,1) / size(codon,1); 

value_counts = [string(C), a_counts, a_proportion]
%%
tabulate(ckingdom)
%% 
% The proportion of each class in the dataset respects the following relationship:
% 
% Eukaryota: 69.4%
% 
% Bacteria: 29.3%
% 
% Archaea: 1.3%
% 
% We observe a high imbalance in one of the classes (Archaea). Therefore we 

% Now we should split the dataset between categorical and numerical data as
% we will investigate basec statistics which are appropriate to numerical
% data (e.g. min, max, mean) but not to categorical data.

var_names = codon.Properties.VariableNames;

for i = [1:width(codon)]
    v_is_cell(i) = iscell(codon.(var_names{i}));
end 
if var_names{i}=="Kingdom"; then iscell(codon.(var_names{2})); end;
%use logical indexing to split between numerical and categorical columns
codon_numerical = codon(:,~v_is_cell);

%col_dependant_var = iscell(codon(:,find(string(codon.Properties.VariableNames) == "Kingdom"));

codon_categorical = codon(:,v_is_cell);
codon_categorical(:,codon_categorical.Properties.VariableNames=="Kingdom") = [];
%% 
% 


statsTable = varfun(@(x) [mean(x);std(x);kurtosis(x);skewness(x);min(x);max(x)],codon_numerical);
statsTable.Properties.RowNames = {'mean' 'std' 'kurtosis' 'skewness' 'min' 'max'};
statsTable.Properties.VariableNames = extractAfter(statsTable.Properties.VariableNames,'Fun_');
disp(statsTable);
%% 
% 
% 
% 
% 1.4 Outliers
% 
% 
% *Detect Outliers using Mean*
% 
% We can use isoutlier function to investigate the proportion of outliers. However, 
% we should be careful with outliers removal considering Random Forest and Logistic 
% Regression can be affected by outliers but depending on how they are implemented 
% it is possible to impart robustness to outliers.

outl = isoutlier(codon_numerical,'mean');
f = figure;
bar(round(100 * sum(outl) / size(codon_numerical,1),2))
%% 
% We observe the proportion of outliers is small considering each of the 67 
% columns
% 
% 





%% 
% *Detect Outliers for each codon using threshold* (Compute thresholds with 
% outliers)

f = figure;
f.Position = [10 10 2200 1600]; 

out_rows = width(codon_numerical) - 4;
p = zeros(out_rows ,2);
for i = [4:width(codon_numerical)]
    prc = prctile(codon_numerical{:,i},[5 95]);
    p(i,1) = prc(1);
    p(i,2) = prc(2);
    t = 1:numel(codon_numerical{:,1});
    % Logical Index Of Values Outside The Respective Percentiles
    TF = (codon_numerical{:,i}<=p(i,1)) | (codon_numerical{:,i}>=p(i,2));
    
    subplot(11,6,i-3)
    plot(t, codon_numerical{:,i})
    hold on
    plot(t(TF), codon_numerical{:,i}(TF),'x')
    yline(0.05)
    yline(0.95)
    hold off
    grid

end 


%%

%% 2. Descriptive statistics
% 
% 
% First let's analyse the dependent variables distributions individually  
% 
% Categorical variables

%for k = 1:size(codon_numerical,2)
%    var_numerical_names{k} = codon_numerical.Properties.VariableNames;
%end
%var_numerical_names = codon_numerical.Properties.VariableNames;
%var_numerical_names = cell2table(var_numerical_names);
var_numerical_names = string(codon_numerical.Properties.VariableNames);



%setappdata(gcf, 'SubplotDefaultAxesLocation', [0, 0, 1, 1]);

% subplot dimension
n1 = 3; % number of rows
n2 = 7; % number of columns

% These values would define the space between the graphs
% if equal to 1 there will be no space between graphs
nw = 0.9; % normalized width
nh = 0.9; % normalized height

f1=figure;
%size(codon_numerical,2) 
k = 0;
for k1 = 1:n1
    for k2 = 1:n2 
        k = k + 1;
        %Ax = subplot(3,7,k);
        subplot(n1,n2,(k1-1)*n2 + k2,...
                'position', [(1-nw)/n2/2 + (k2-1)/n2, (1-nh)/n1/2 + 1-k1/n1,...
                nw/n2 nh/n1]);
        hc1 = histogram(codon_numerical.(k));
        xlabel(var_numerical_names(k))
        ylabel('Freq.')
        title({'';'Histogram'})
        %PosVec = Ax.Position;
        %Ax.Position = PosVec+[0.005 0.035 0 0.005];
    end
end

%%
%f1.Position = f1.Position+[0 0 500 500];
var_numerical_names = string(codon_numerical.Properties.VariableNames);

fig = figure(); 
fig.Position = [0 0 1880 1400];
n = 67;
tlo = tiledlayout(fig, 'flow');

%arrayfun(@(col)histogram(nexttile(tlo),table2array(codon_numerical(:,col))),1:n); % *see below

for i = 1:n
    ax = nexttile(tlo);
    h=histogram(ax, table2array(codon_numerical(:,i))); 
    xlabel(var_numerical_names(i));
end

tlo.TileSpacing = 'compact';
tlo.Padding = 'compact';
title(tlo,'Global title')
ylabel(tlo, 'Frequency')
xlabel(tlo, 'Histogram of Dependent Variables')

%% 
% 
% 
% *Exploratory Plots*
% 
% We will generate boxplots to explore the relationships between the independent 
% variable and the other dependent variables.

% subplot dimension
n1 = 8; % number of rows
n2 = 7; % number of columns

% These values would define the space between the graphs
% if equal to 1 there will be no space between graphs
nw = 0.9; % normalized width
nh = 0.9; % normalized height

f1=figure();
f1.Position = [0 0 2100 2400];
%size(codon_numerical,2) 
k = 0;
j=0;
for k1 = 1:n1
    for k2 = 1:n2 
        %hc1 = histogram(codon_numerical.(k));
        k = k + 1;
        if any(ismember(var_numerical_names, codon.Properties.VariableNames{k})) 
            j = j + 1;
            subplot(n1,n2,j); 
            %(k1-1)*n2 + k2
            vs = violinplot(codon.(k), codon.Kingdom);
            xlabel(codon.Properties.VariableNames{k})
            ylabel('Freq.')
            %title({'';'Histogram'})
        end
            %PosVec = Ax.Position;
        %Ax.Position = PosVec+[0.005 0.035 0 0.005];
    end
end
 



 

%% 
% 
% 
% 

stats3 = groupsummary(codon,"Kingdom","sum")
%% 2.4 Correlation plot
% n this step correlation between variables is explored and visualised using 
% a heatmap

%codon_cleaned = removevars(cleanedData_2,["ICU","Intubation"]);
%%
fcorr = figure();
fcorr.Position = [0 0 2400 2800];
codon_covmat = table2array(codon_numerical);
covmat = corrcoef(codon_covmat);
imagesc(covmat)
ax = gca;
colormap(jet);
colorbar;
xlabel('Codon Usage parameters');
ylabel('Codon Usage parameters');
title('Covariance of Codon Usage parameters');
N=67;
labelNames = var_numerical_names;

set(gca,'XTick',1:N);
set(gca,'YTick',1:N);
set(gca,'XTickLabel',labelNames);
set(gca,'YTickLabel',labelNames);
set(gca,'XTickLabelRotation',90)
%set(gca,'YTickLabel',labelNames);
%% 2.5 Group statistics

%statarray = grpstats(codon,["Deceased"], "mean","DataVars",["Age"]) % Calculating group statistics by outcome variable (Deceased).
% Let's draw a probabilistic plot

%probplot('normal',dataF.Age)
%calculating basic statistics according to a grouping variable using groupsummary function
%stats3 = groupsummary(dataF,"Deceased","sum")
%% *2.6 Convert categorical variables to numerical*
% One hot encoding is the most widespread approach, and it works very well unless 
% your categorical variable takes on a large number of values (i.e. you generally 
% won't it for variables taking more than 15 different values. It'd be a poor 
% choice in some cases with fewer values, though that varies.)
% 
% 
% 
% First we will investigate how many values are in the SpeciesName column which 
% is the only categorical variable.

[C,ia,ic] = unique(codon_categorical);
size(C,1)
% Now we can calculate the proportion of unique values compared to the
% cardinality of the dataset
size(C,1)/size(codon_categorical,1)

%% 
% Since the only column left is SpeciesName with 9952 distinct values and 99.95% 
% of cardinality then we understand that this would not be a useful variable to 
% include as it has surprisingly high cardinality and it could be similar to a 
% unique identifier rather than a generalisable feature. Therefore, we will not 
% convert the SpeciesName column to numerical and we consider codon_numerical 
% as our cleaned dataset for the next steps of the process.


%% 
% 
% 
% 
% 
% 


% 2.6 Collinearity diagnostic
% 
% 
% The collinearity diagnostics *confirm that there are serious problems with 
% multicollinearity*. Several eigenvalues are close to 0, indicating that the 
% predictors are highly intercorrelated and that small changes in the data values 
% may lead to large changes in the estimates of the coefficients.
% 
% To assess collinearity, the software computes <https://in.mathworks.com/help/econ/collintest.html#btcd2tb 
% singular values> of the scaled variable matrix, _X_, and then converts them 
% to <https://in.mathworks.com/help/econ/collintest.html#btcdtr4 condition indices>. 
% The conditional indices identify the number and strength of any near dependencies 
% between variables in the variable matrix. The software decomposes the variance 
% of the ordinary least squares (OLS) estimates of the regression coefficients 
% in terms of the singular values to identify variables involved in each near 
% dependency, and the extent to which the dependencies degrade the regression.

% Display the Belsley collinearity diagnostics, using all default options.

coll = collintest(codon_numerical)
%% 
% Considering the method has a default tolerance of 30 we conclude there are 
% 11 rows with a condition index larger than the tolerance.
% 
% 
% 
% Now we should also investigate if any of the variables has 
% 
% And several 
% 
% last row in the display has a condition index larger than the default tolerance, 
% 30. In this row, the last three variables (in the last three columns) have variance-decomposition 
% proportions exceeding the default tolerance, 0.5. This suggests that the variables 
% |INT_S|, |INT_M|, and |INT_L| exhibit multicollinearity.
% 
% 
%% 
% 
% 
% 
%% *3. Dataset split*

%% Define a random seed for reproducibility purpose
% This is to prevent differences that can result in a new set of random numbers after
% executing again random functions.
rng(1,'twister')

%% Split up train and test set
X = table2array(codon_numerical);
y = categorical(codon.Kingdom);

% Partition data selecting 20% for test and the remaining (80%) for
% training.
part = cvpartition(codon.Kingdom,'Holdout',0.2,'Stratify',true);

% Create training/test set indexes
is_train = training(part); % Indexes for training
is_test = test(part);      % Indexes for test (quality assessment)

% Generate training set
X_train = X(is_train,:);
y_train = y(is_train,:);

% Generate test set to use after the best model selection
X_test = X(is_test,:);
y_test = y(is_test,:);


%% 
% Define array of classes that will be used to address class names ('arc', 'bct', 
% 'euk') to y arrays for class values (1, 2, 3) respectively.

codon_classes = ["arc" "bct" "euk"];
%% *4. Feature Selection*
% *Given the high dimensionality of the resulting dataset (67 variables) we 
% propose the implementation of several feature selection methods and then select 
% the one which is considered most suitable for our objective without loss of 
% generalisation.*
% 
% *Four methods will be used one as a Embedded Type Feature Selection type (Classification 
% ensemble of decision trees) and the other 3 methods are classified as Filter 
% Type Feature Selection (Sequentialfs, MNMR, and NCA).*
% 
% *4.1 Classification ensemble of decision trees*
% 
% *4.2 Sequentialfs*
% 
% *4.3 MNMR*
% 
% *4.4 NCA*
% 
% *We will use codon_numerical and codon.Kingdom as inputs that will be used 
% in the above methods*


%% 
% 
%% *4.1 Classification ensemble of decision trees*
% 
% 
% Estimates of predictor importance for classification ensemble of decision 
% trees.
% 
% |predictorImportance| estimates predictor importance for each tree learner 
% in the ensemble |ens| and returns the weighted average |imp| computed using 
% |ens.TrainedWeight|. The output |imp| has one element for each predictor.
% 
% |predictorImportance| computes importance measures of the predictors in a 
% tree by summing changes in the node risk due to splits on every predictor, and 
% then dividing the sum by the total number of branch nodes. The change in the 
% node risk is the difference between the risk for the parent node and the total 
% risk for the two children. For example, if a tree splits a parent node (for 
% example, node 1) into two child nodes (for example, nodes 2 and 3), then |predictorImportance| 
% increases the importance of the split predictor by 
% 
% (_R1_ – _R2_ – _R3_) / _N(_branch)
% 
% We will train a classification ensemble using AdaBoostM2. Specify tree stumps 
% as the weak learners.
% 
% We also identify surrogate splits because trees with surrogate splits are 
% supposed to give better predictions.
% 
% This means that if there is a missing variable used in a primary split to 
% be predicted then a "surrogate split*"* is used instead.


t = templateTree('MaxNumSplits',1,'Surrogate','on');
ens = fitcensemble(codon_numerical,codon.Kingdom,'Method','AdaBoostM2','Learners',t);
%% 
% And now we estimate the predictor importance for all predictor variables of 
% the ensemble.


[imp,ma] = predictorImportance(ens)
%% 
% And if we rank the imp array

[out,idx] = sort(imp,'descend')
%% 
% Finally we can also sort the predictor importance looking at the difference 
% between each predictor importance and the following to observe larger gaps of 
% difference.


[out' [0;diff(out')]]
%% 
% Even though the 10 first predictors give higher score with values over 0.01 
% when we compare the differences between them we do not observe a set of predictors 
% with higher node risks due to split. Thus we will not consider this method as 
% relevant for feature selection.
%% 
% 
% 
% 

disp('1')
%% *4.2 Sequential Feature selection (sequentialfs)*
% Knowing that sequentialfs has poor performance when a large dataset is used 
% we decided to run the algorithm with 20% of the samples as a baseline with a 
% sample of the training set and 5-fold cross validation.

rng(10,'twister')
part = cvpartition(codon.Kingdom,'Holdout',0.8,'Stratify',true);
issampletrain = training(part); % Data for fitting

X_sf = table2array(codon_numerical);
y_sf = categorical(codon.Kingdom);

X_sf_tr = X_sf(issampletrain,:);
y_sf_tr = y_sf(issampletrain,:);

cv = cvpartition(y_sf_tr,'k',5);

%% feature selection
opts = statset('display','iter');
costfun = @(XT,yT,Xt,yt)loss(fitcecoc(XT,yT),Xt,yt);
[fs, history] = sequentialfs(costfun, X_sf_tr, y_sf_tr, 'cv', cv, 'options', opts); 
%% 
% Based on the above result we conclude that only the column 1 was included. 
% This means from the initial 67 columns only 1 were selected. But we initially 
% assumed that only 20% would represent the entire distribution, hence the conclusion 
% of sequentialfs could result in poor performance. Therefore we will investigate 
% the next 2 methods to verify if any could be applicable for selecting the most 
% important features frmothe high-dimensional space.
%% 4.3 MSMR
% Rank features for classification using minimum redundancy maximum relevance 
% (MRMR) algorithm.
% 
% We are not using the same traning samples as the sequentialfs method because 
% the MSMR and NCA have better performance as we would be able to use more data 
% in order to produce a more robust result and also to have a baseline for comparison 
% between both approaches.

X_fs = table2array(codon_numerical);
y_fs = categorical(codon.Kingdom);

% Partition the data selecting 20% for test and the remaining (80%) for
% training.
% We call rng again as we want his experiment to be statistically
% independent from the previous one.
% And for long-term repeatability we specify the seed and the generator type together.
rng(10,'twister');
part = cvpartition(codon.Kingdom,'Holdout',0.2,'Stratify',true);

% Create training/val set indexes for training samples
idx_fs_train = training(part); % Indexes for training  
idx_fs_val = test(part);      % Indexes for validation  

X_fs_train = X_fs(idx_fs_train,:)
y_fs_train = y_fs(idx_fs_train,:)

[idx,scores] = fscmrmr(X_fs(issampletrain,:),y_fs(issampletrain,:));

figure
bar(scores(idx))
xlabel('Predictor rank')
ylabel('Predictor importance score')
%% 
% The drop in score between the first/second and third most important predictors 
% is large, while the drops after the 29th predictor are relatively small. A drop 
% in the importance score represents the confidence of feature selection. Therefore, 
% the large drop implies that the software is confident of selecting the most 
% important predictor. The small drops indicate that the difference in predictor 
% importance are not significant.

% Below we have the columns
idx(1:29)'
%%
% And the column names represented by the above indexes
msmridx = idx(1:29)';
fs_msmr = codon_numerical.Properties.VariableNames(msmridx(1:end,:));
%(selidx(1:end,:));

%%
{num2cell(idx(1:39))'}
%% |4.4 NCA|
% 

% Based on the initial data split (from item 3) we partition the data selecting 20% for validation and the remaining (80%) for
% training.
part = cvpartition(y_train,'Holdout',0.2,'Stratify',true);

% Create training/val set indexes for training samples
idx_fs_train = training(part); % Indexes for training of NCA
idx_fs_val = test(part);      % Indexes for validation of NCA

X_fs_train = X_train(idx_fs_train,:);
y_fs_train = y_train(idx_fs_train,:);

X_fs_val = X_train(idx_fs_val,:);
y_fs_val = y_train(idx_fs_val,:)

mdlnca = fscnca(X_fs_train,y_fs_train,'Solver','sgd','Verbose',1);
%%
figure()
plot(mdlnca.FeatureWeights,'ro')
grid on
xlabel('Feature index')
ylabel('Feature weight')
%%

%% 
% Compute generalization error without fitting.


nca = fscnca(X_fs_train,y_fs_train,'FitMethod','none');
L = loss(nca,X_fs_val,y_fs_val)
%% 
% First we fit NCA without regularization parameter (Lambda = 0)


nca = fscnca(X_fs_train,y_fs_train,'FitMethod','exact','Lambda',0,...
      'Solver','sgd','Standardize',true);
L = loss(nca,X_fs_val,y_fs_val)
%% 
% The improvement on the loss value suggests that feature selection is a good 
% idea. Tuning the _λ_ value usually improves the results.
% 
% Tuning _λ_ means finding the _λ_ value that produces the minimum classification 
% loss. To tune _λ_ using cross-validation:

%1. Partition the training data into ten folds and extract the number of validation (test) sets. 
% For each fold, cvpartition assigns nine-tenth of the data as a training set, and one-tenth of the data as a test set.
cvp = cvpartition(y_fs_train,'kfold',10);
numvalidsets = cvp.NumTestSets;

%Assign λ values and create an array to store the loss function values.
n = length(y_fs_train);
lambdavals = linspace(0,20,20)/n;
lossvals = zeros(length(lambdavals),numvalidsets);

for i = 1:length(lambdavals)
    for k = 1:numvalidsets
        X_fs_tr = X_fs_train(cvp.training(k),:);
        y_fs_tr = y_fs_train(cvp.training(k),:);
        Xvalid = X_fs_train(cvp.test(k),:);
        yvalid = y_fs_train(cvp.test(k),:);

        nca = fscnca(X_fs_tr,y_fs_tr,'FitMethod','exact', ...
             'Solver','sgd','Lambda',lambdavals(i), ...
             'IterationLimit',30,'GradientTolerance',1e-4, ...
             'Standardize',true);
                  
        lossvals(i,k) = loss(nca,Xvalid,yvalid,'LossFunction','classiferror');
    end
end
%% 
% Compute the average loss obtained from the folds for each _λ_ value.

meanloss = mean(lossvals,2);
%% 
% Plot the average loss values versus the _λ_ values.

figure()
plot(lambdavals,meanloss,'ro-')
xlabel('Lambda')
ylabel('Loss (MSE)')
grid on
%% 
% Find the best lambda value that corresponds to the minimum average loss.

[~,idx] = min(meanloss) % Find the index

bestlambda = lambdavals(idx) % Find the best lambda value
bestloss = meanloss(idx)

%% 
% 
%% 
% *Fitting the nca model on all data using best _λ_ and plot the feature weights*
% 
% We will now use the solver lbfgs and standardize the predictor values.

nca = fscnca(X_train,y_train,'FitMethod','exact','Solver','sgd',...
    'Lambda',bestlambda,'Standardize',true,'Verbose',1);
figure()
plot(nca.FeatureWeights,'ro')
xlabel('Feature index')
ylabel('Feature weight')
grid on
%%
%Set NCA threshold level

threshold_nca    = 0.02;
selidx = find(nca.FeatureWeights > threshold_nca*max(1,max(nca.FeatureWeights)))
%% 
% Indentify features to be dropped

fs_drop = find(nca.FeatureWeights <= threshold_nca*max(1,max(nca.FeatureWeights)))
%% 
% And the feature names related to the indexes.


codon_numerical.Properties.VariableNames(fs_drop)
%% 
% 
% 
% Drop the 24 features which are a result from the NCA feature selection

% Take a copy of X_train and X_test for backup purposes

if (~exist('X_train_raw','var') == 1 && ~exist('X_test_raw','var') == 1) ...
    || ...
    ((exist('X_train_raw','var') == 1 && exist('X_test_raw','var') == 1) ...
        && (size(X_train_raw,2) <= size(X_train,2) && ...
    size(X_test_raw,2) <= size(X_test,2) ))
    
    X_train_raw = X_train;
    X_test_raw = X_test;
    
    %Extract the features with feature weights greater than 0 from the training data.
    X_train = X_train_raw(:,selidx);
    X_test = X_test_raw(:,selidx);
end




%Evaluate the accuracy of the trained classifier on the test data which has not been used for selecting features.


%arra=num2cell(selidx);
%fs_nca = codon_numerical.Properties.VariableNames(selidx(1:end,:));
%%
features_to_keep = codon_numerical.Properties.VariableNames(selidx(1:end,:))

%%

codon_numerical(:, codon_numerical.Properties.VariableNames(fs_nca))
%% 
%% *5. Building, optimising and testing two models: Logistic Regression and Random Forest*
%% 5.1 Metrics of performance
% 
% 
% TP
% 
% FP
% 
% FN
% 
% FP
% 
% Precision
% 
% Recall
% 
% Sensititvity
% 
% Sensibility
% 
% Accuracy
% 
% Balanced Accuracy
% 
% 
% 
% 
% 
% 
% 
% *ROC AUC (ROC)*:
% 
% ROC curves are typically used in binary classification to study the output 
% of a classifier. In order to extend ROC curve and ROC area to multi-class or 
% multi-label classification, it is necessary to binarize the output. One ROC 
% curve can be drawn per label, but one can also draw a ROC curve by considering 
% each element of the label indicator matrix as a binary prediction (micro-averaging).
% 
% To get an estimate of the overall classification performance we can use the 
% area under the curve (AUC) for multi-class classification presented in the Hand 
% and Till 2001 paper (doi: 10.1023/A:1010920819831). 
% 
% <https://stats.stackexchange.com/questions/262616/roc-vs-precision-recall-curves-on-imbalanced-dataset 
% https://stats.stackexchange.com/questions/262616/roc-vs-precision-recall-curves-on-imbalanced-dataset>
% 
% *PR AUC (PRC)*:
% 
% Precision-recall curves are typically used in binary classification to study 
% the output of a classifier. In order to extend the precision-recall curve and 
% average precision to multi-class or multi-label classification, it is necessary 
% to binarize the output. One curve can be drawn per label, but one can also draw 
% a precision-recall curve by considering each element of the label indicator 
% matrix as a binary prediction (micro-averaging).
% 
% According to the studies from the <http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf 
% http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf> paper ROC curves 
% can sometimes be misleading in some very imbalanced applications. A ROC curve 
% can still look pretty good (ie better than random) while misclassifying most 
% or all of the minority class.  
% 
% Because of that we will also use PR AUC curves to assess the models performances.
% 
% 
% 
% 
% 
% <https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html 
% >
%% 4.2 Dataset split (training / testing)
% 
% 
% According to several references for smaller datasets a ratio of 70/30 for 
% train/test is used however in large datasets often 80/20 is used. We consider 
% our dataset for the task a large enough dataset with ~10k observations and approx 
% 40 variables.
% 
% To maintain a similar proportion we will utilize 5-fold validation to lower 
% the bias and select hyperparameters for the models.
% 
% 

%% Define a random seed for reproducibility purpose
% This is to prevent differences that can result in a new set of random numbers after
% executing again random functions.
rng('default')

%% Split up train and test set
X = table2array(codon_numerical);
y = categorical(codon.Kingdom);

% Partition data selecting 20% for test and the remaining (80%) for
% training.
part = cvpartition(codon.Kingdom,'Holdout',0.2,'Stratify',true);

% Create training/test set indexes
is_train = training(part); % Indexes for training
is_test = test(part);      % Indexes for test (quality assessment)

% Generate training set
X_train = X(is_train,:);
y_train = y(is_train,:);

% Generate test set to use after the best model selection
X_test = X(is_test,:);
y_test = y(is_test,:);

%% 
% At this point we can compare the class proportions between the original dataset 
% against the training set to validate if we have a stratified random sample to 
% use.


% Original dataset class proportion
tabulate(y)

% After splitting dataset class proportion
tabulate(y_train)
%% 
% 
% 
% 
% 
% As we observe above the classes have approximatelly the same proportion when 
% both datasets are compared.
%% 
% 
% 
% 

[m,n] = size(codon) ;
P = 0.80; % The size of the training dataset is set to 80% of total size of dataset

codon_fs = codon_numerical(:, codon_numerical.Properties.VariableNames(fs_nca))

rng('default'); % To prevent randperm function to draw random numbers after each run, "rng" is used. This is to ensure reproducibility 

% Create a series of index to randomly split the data into 80% training and 20% testing.
idx = randperm(m); % Generate a vector of random permutation of all data: m is the size of the datapoints
trainingData = codon(idx(1:round(P*m)),:); % Defining the training features of the datasets corresponding to the randomly shuffled vector
testingData = codon(idx(round(P*m)+1:end),:);  % Defining the testing features of the datasets corresponding to the randomly shuffled vector


%% 
% 
%% 
% <https://uk.mathworks.com/help/stats/bootstrp.html#mw_4cec271d-3ccd-4df8-959e-37cd686f4119 
% >

nboot=10;
[idx,bootsamp] = bootstrp(nboot,[],xTrain);
for i=1:nboot
    newX{i} = xTrain(bootsamp(:,i),:)
end
% 5.3 Multinomial Logistic regression
% <https://uk.mathworks.com/help/stats/multinomial-models-for-nominal-responses.html 
% *Multinomial Models for Nominal Responses*>
% 
% A nominal response variable has a restricted set of possible values with no 
% natural order between them. A nominal response model explains and predicts the 
% probability that an observation is in each category of a categorical response 
% variable.
% 
% A *multinomial logistic regression* model has the following form:
% 
% ln[pApC]=β0,1+β1,1⋅X(1)+β2,1⋅X(2)+...+βm,1⋅X(m)ln⁡[pApC]=β0,1+β1,1⋅X(1)+β2,1⋅X(2)+...+βm,1⋅X(m)
% 
% ln[pBpC]=β0,2+β1,2⋅X(1)+β2,2⋅X(2)+...+βm,2⋅X(m)ln⁡[pBpC]=β0,2+β1,2⋅X(1)+β2,2⋅X(2)+...+βm,2⋅X(m)
% 
% Please note the following comments regarding this model:
%% 
% # Since pA+pB+pC=1pA+pB+pC=1, if we know ln[pA/pC]ln⁡[pA/pC] and ln[pB/pC]ln⁡[pB/pC], 
% then we can calculate all three probabilities.
% # In general, if our reponse variable has kk classes, then our multinomial 
% logistic regression model will need to consist of k−1k−1 equations.
% # The expression pA/pCpA/pC is referred to as the *relative odds ratio* of 
% A with respect to C. We will denote this expression by Odds[A:C]Odds[A:C].

% Defining predictors 
xtrainNames = {'DNAtype', 'SpeciesID',	'Ncodons',	'UUU',	'UUC',	'UUA', 'UUG', 'CUU', 'CUC', 'CUA', ...
'CUG',	'AUU',	'AUC',	'AUA',	'AUG',	'GUU',	'GUC',	'GUA',	'GUG',	'GCU',	...
'GCC',	'GCA',	'GCG',	'CCU',	'CCC',	'CCA',	'CCG',	'UGG',	'GGU',	'GGC',	...
'GGA',	'GGG',	'UCU',	'UCC',	'UCA',	'UCG',	'AGU',	'AGC',	'ACU',	'ACC',	...
'ACA',	'ACG',	'UAU',	'UAC',	'CAA',	'CAG',	'AAU',	'AAC',	'UGU',	'UGC',	...
'CAU',	'CAC',	'AAA',	'AAG',	'CGU',	'CGC',	'CGA',	'CGG',	'AGA',	'AGG',	...
'GAU',	'GAC',	'GAA',	'GAG',	'UAA',	'UAG',	'UGA'};


xTrain = trainingData(:, xtrainNames); % Predictors
xTrain = table2array(xTrain);
% Define output response
yTrain = trainingData.Kingdom; % Output

thresholdmdl = 0.5; % Define a threshold for classification
numSamples = length(yTrain); % Number of samples
numBoots = 1; % Number of bootstrap samples
mdl_boot  = cell(numBoots,1); % Pre-allocate memory for the resampled fit values
predBoot_Mdl1 = zeros(numSamples,1);
[Precision,Recall,Specificity,BM,FPR,FNR,FOR,NPV,FDR,MCC,MK,F1,F2,Accuracy,AUC,Time] = deal(zeros(numBoots,1)); % Container for storing performance measure obtained  during the loop
Time = zeros(numBoots,1);

% Resample, iterate and model each instance of the resampled data
for i = 1:numBoots
    resampling_ix = ceil(numSamples*rand(1,numSamples));
    resampled_x = xTrain(resampling_ix,:);
    resampled_y = yTrain(resampling_ix);
    
    %Define the nominal response variable using a categorical array.

    resampled_y_cat = categorical(resampled_y);
    
    tic % Start recording time
    %mdl_boot{i}
    B = mnrfit(resampled_x,resampled_y_cat); % Fitting multinomial logistic regression
    
    %%
    prob = mnrval(B,resampled_x);
    %predict(B,resampled_x)
    %predBoot_Mdl1(:,i) = predict(mdl_boot{i},resampled_x) >= thresholdmdl; % Prediction using the the model built above   
    
    % Calculating measures of performance
    %TP(i) = sum((predBoot_Mdl1(:,i) == 0) & (resampled_y == 0)); % True positive
    %FP(i) = sum((predBoot_Mdl1(:,i) == 1) & (resampled_y == 0)); % False positive
    %FN(i) = sum((predBoot_Mdl1(:,i) == 0) & (resampled_y == 1)); % False negative
    %TN(i) = sum((predBoot_Mdl1(:,i) == 1) & (resampled_y == 1)); % True negative
    %Precision(i) = TP(i)/ (TP(i)+FP(i)); % ratio of correct predictions for the positive class out of total possible positives.
    %Recall(i) = TP(i)/ (TP(i)+FN(i)); % ratio of correct positive predictions.
    %Specificity(i) = TN(i)/ (FP(i)+TN(i)); % Specificity
    %BM(i) = Recall(i)+Specificity(i)-1; % Bookmaker informedness
    %FPR(i) = FP(i)/ (TN(i)+FP(i)); % False positive rate
    %FNR(i) = FN(i)/ (FN(i)+TP(i)); % False negative rate
    %FOR(i) = FN(i)/ (FN(i)+TN(i)); % False ommission rate
    %NPV(i) = TN(i)/ (TN(i)+FN(i)); % Negative predictor value
    %FDR(i) = FP(i)/ (FP(i)+TP(i)); % False discovery rate
    %MCC(i) = (TP(i)*TN(i)-FP(i)*FN(i))/sqrt((TP(i)+FP(i))*(TP(i)+FN(i))*(TN(i)+FP(i))*(TN(i)+FN(i))); % Matthews correlation coefficient
    %MK(i) = Precision(i)+NPV(i)-1; % Markedness 
    %F1(i) = (2*Precision(i)*Recall(i))/ (Precision(i)+Recall(i)); % average (weighted) Precision and Recall.
    %F2(i) = (5*Precision(i)*Recall(i)/ ((4*Precision(i)) + Recall(i))); % similar to F1 but less weight on Precision, more weight on Recall.
    %Accuracy(i) = (TP(i)+TN(i))./(TP(i)+FP(i)+TN(i)+FN(i))*100; % Accuracy
    %scores = mdl_boot{i}.Fitted.Probability;
    %[X,Y,T,AUC(i)] = perfcurve(resampled_y,scores,'1');
    %AUC(i); % Area under the curve
    Time(i) = toc; % End recording time
end


%%
X_train = table2array(X_train);
% Define output response
y_train = trainingData.Kingdom; % Output
%%
figure
plot(X_train(:,2),X_train(:,3),'o')
%% 
% First we will define a 5-fold cross validation using a constant value for 
% the LR alpha parameter and we will compare the metrics using SSMOTE to 



% Define 5 as number of folds
K=5;
rng(1, 'twister');

% Change classes to numerical data
y_train_num = renamecats(y_train,{'arc','bct','euk'},{'1','2','3'});
y_train_num = str2double(string(y_train_num));
%y_train_n = grp2idx(y_train);

indices=crossvalind('Kfold',y_train_num,K);

[TP] = deal(zeros(K,1)); % Container for storing each fold performance measure obtained  during the loop

% Initialize variables

m = size(X_train, 2); % number of columns
numLabels = size(unique(y_train),1); % number of labels
theta = zeros(numLabels,m+1,K);

%figure;
%res = [1024 768]; %set desired [horizontal vertical] resolution
%set(gcf,'PaperPosition',[0 0 res]*2.54); %set paper size (does not affect display)
%set(gcf,'units','normalized','outerposition',[0 0 1 1]);

% Variable to store each fold time and total/avg time metrics
%fTime = 

for i_fold=1:K
    % Evaluate time for each fold iteration
    
    % Assigning training and validation set indexes
    val = (indices == i_fold);
    train = ~val;
    % Training set
    Xf_train = X_train(train,:);
    yf_train = y_train_num(train);
    % Validation set
    Xf_val = X_train(val,:);
    yf_val = y_train_num(val);
   
    
    lambda = 10; % regularization parameter
    %numLabels = size(unique(y_train_num),1); % number of labels
    
    % Training
    
     
    %disp(b)
    %% Training Multinomial Logistic Regression classifier
    fprintf('Training Multinomial Logistic Regression');
    Xf_train_scaled = normalize(Xf_train);
    Xf_val_scaled = normalize(Xf_val);

    
    theta_temp = LRTraining(Xf_train_scaled, yf_train, numLabels, lambda);
    theta(:,:,i_fold) = theta_temp;
    %[W, b] = LRTrain(Xf_train_scaled, yf_train, lambda, numLabels);
    
    % Validation
    
    %% Prediction 
    %[preds] = LRPrediction(Xf_val_scaled, yf_val, W, b);

    predicted_y = LRPredict(theta_temp, Xf_val_scaled);
    proba = LRPredictProba(theta_temp, Xf_val_scaled);
    
    % Add ones to the X data matrix (x0)
    %Xf = [ones(size(Xf_val_scaled, 1), 1) Xf_val_scaled];

    %pihat = sigmoid(Xf * theta_temp');
    %subplot(3,2,i_fold);
    %cm = confusionchart(yf_val,predicted_y);
    
    lr_stats = confusionMatStats(confusionmat(yf_val, predicted_y));
    %(ifold)
    %m = size(Xf_val(:,3:end), 1);
    %Xf_val_scaled = [ones(m, 1) normalize(table2array(Xf_val(:,3:end)))];
    

    %diffscore=zeros;
    %for i=1:size(proba,1)
    %    temp=proba(i,:); % a row vector holding the scores for the classes [A, B, C, D] for the ith observation out of the total.
    %    % score of +ve class minus the maximum of the scores of all the negative classes (similar to the example available via the webpage link) 
    %    diffscore(i,:)=temp(2)-max([temp(1),temp(3)]); 
    %end
    
    %[X_perf,Y_perf,T,~,OPTROCPT,suby,subnames] = perfcurve(yf_val,diffscore,2); % predicted_y: True class labels

   
    clear plt_roc
    clear plt_prc
    figure;
    figure.position = [100 100 540 400];
    if (~exist('plt_roc', 'var') || ~exist('plt_prc', 'var'))
        plt_roc = plot([],[],'-');
        plt_prc = plot([],[],'-');
    end
    hold on;
    for i=1:size(proba,2)
        tgt=-ones(1,length(yf_val));
        positive_class=find(yf_val==i);
        tgt(positive_class)=1;
        %[xr, yr, ~, auc(i)] = perfcurve(yf_val,proba(:, i), i);
        %plot(xr, yr, 'linewidth', 1)
        
        legends_auc{i} = sprintf('AUC for %s class', codon_classes{i});
        %% Plot ROCs
        plt_roc = compute_prc_roc(tgt,proba(:, i)',"ROC",codon_classes{i},i,i_fold,legends_auc,plt_roc);
    end
    hold off;
    
    figure
    hold on;
    for i=1:size(proba,2)
        tgt=-ones(1,length(yf_val));
        positive_class=find(yf_val==i);
        tgt(positive_class)=1;
        legends_prc{i} = sprintf('PRC for %s class', codon_classes{i});
        %% Plot PRCs
        plt_prc = compute_prc_roc(tgt,proba(:, i)',"PRC",codon_classes{i},i,i_fold,legends_prc,plt_prc);
    end
    hold off;            

    %if i==1 %if is the first fold 
    %    mean_curve= (interp1(x_adj, Yroc, intervals))/k; 
    %else
    %    mean_curve= mean_curve+ (interp1(x_adj, Yroc, intervals))/k; 
    %end


    
    %y_hat = mnrval(b,test_x,stats,'interactions','off','type','cumulative','model','ordinal','link','logit');
    %ccdf_yfit=1-y_hat;
    %class1 = ccdf_yfit > 0.5;
    %%
    %prob = mnrval(B,resampled_x);
    %predict(B,resampled_x)
    %predBoot_Mdl1(:,   i) = predict(mdl_boot{i},resampled_x) >= thresholdmdl; % Prediction using the the model built above   
    
end

%%
    % Calculating measures of performance
 
%%
   %TP(i) = sum((pihat(:,i) == 0) & (yf_val_n == 0)); % True positive
    %FP(i) = sum((pihat(:,i) == 1) & (resampled_y == 0)); % False positive
    %FN(i) = sum((pihat(:,i) == 0) & (resampled_y == 1)); % False negative
    %TN(i) = sum((pihat(:,i) == 1) & (resampled_y == 1)); % True negative
    %Precision(i) = TP(i)/ (TP(i)+FP(i)); % ratio of correct predictions for the positive class out of total possible positives.
    %Recall(i) = TP(i)/ (TP(i)+FN(i)); % ratio of correct positive predictions.
    %Specificity(i) = TN(i)/ (FP(i)+TN(i)); % Specificity

%%

%% 5.3 Using SMOTE for minority class and undersampling of majority class
% 
% 
% In our training set if we consider that the proportion between the minority 
% class (arc) and the majority class (euk) has a ratio of approx. 1:50 one can 
% argue  that a oversampling technique alone might not be the best strategy and 
% could be harmful depending on the numer of new samples generated. Therefore 
% we would propose a two-step approach where we can update to first oversample 
% the minority class to have X percent the number of examples of the majority 
% class and then use random undersampling to reduce the number of examples in 
% the majority class to have Y percent more than the minority class, which is 
% considered a safer proportion.
% 
% Thus starting from 1:50 ratio we can increase the minority class 7 times to 
% be at 10 percent of the majority class (with an approx. of 700% increase) and 
% then undersample the majority class to half of the sample size as to reduce 
% the imbalance to appromately 1:3.  
% 
% In the literature SafeLevelSMOTE algorithm performed better than other algorithms 
% such as SMOTE and Borderline SMOTE for a class of problems. Based on that assumption 
% we decided to implement this method for our problem given that our variables 
% could have a degree of dependence between them and a safe margin of synthetic 
% data generation 
% 5.3.1 Validation of class proportions
% Checking again umber of data for each class before applying the algorithm

% Create table with X_train dataset appended with label data
X_train_label = addvars(array2table(X_train), string(y_train),...
    'NewVariableNames','label');


t = tabulate(X_train_label.label);
uniqueLabels = string(t(:,1));
labelCounts = cell2mat(t(:,2));
tbl = tabulate(X_train_label.label);
tabulate(X_train_label.label)
%% 
% Find ratio between minority and majority classes.

t_ratio_class = array2table(tbl,'VariableNames', ...
    {'Value','Count','Percent'});

% Divide minority class by the majority to find the ratio between them
cell2mat(table2array(t_ratio_class(1,2))) / cell2mat(table2array(t_ratio_class(3,2)))
%% 
% The result above represents the ratio between the classes is approx 1:50 (0.02).

(101+505)/(5530/3)
% 5.3.2 Applying SafeLevelSMOTE to class 1 (arc)
% Applying SafeLevelSMOTE

% Define the number of neighbours (k = 10) to use as one of the parameters in the comparison
% and proportion of increase (5 times)
k = 10;
prop_increase = 5;

% Define number of samples to add for minority class
smote_samples = cell2mat(table2array(t_ratio_class(1,2))) * prop_increase;

% We define samples for minority class and 0 for the other classes
num2Add = [smote_samples,0,0];


newdata = table;
visdataset = cell(length(uniqueLabels),1);

% Define for each class
    
for ii=1:length(uniqueLabels)
    [tmp,visdata] = SafeLevelSMOTE(X_train_label,uniqueLabels(ii),num2Add(ii),...
                "NumNeighbors",k, "Standardize", false);
    newdata = [newdata; tmp];
    visdataset{ii} = visdata;
end

% Finally we save the added samples to an array (removing the last column)
smote_class1 = table2array(newdata(:,1:end-1));

X_train_raw_2 = X_train;

% Finally we save the added samples to an array (removing the last column
X_train = [X_train ; smote_class1];
y_train = [y_train; categorical(table2array(newdata(:,end)))];
% 5.3.3 Random undersampling of majority class (Class 3 (euk))
% Now we address class-related data imbalance by undersampling the majority 
% (euk) class and reducing X_train size as well.

% 
% First we should calculate the number of samples that should be removed from 
% the majority class to find a 1:3 ratio between minority and majority classes.

X_train_label = addvars(array2table(X_train), string(y_train),...
    'NewVariableNames','label');

tbl = tabulate(X_train_label.label);

t_ratio_class = array2table(tbl,'VariableNames', ...
    {'Value','Count','Percent'});

% Divide minority class by the majority to find the ratio between them
ratio_min_max = cell2mat(table2array(t_ratio_class(1,2))) / cell2mat(table2array(t_ratio_class(3,2)))
%%
under_samples = round(cell2mat(table2array(t_ratio_class(1,2))) / 0.33,0)
%% 
% Given that k_samples is approx 1984 then we should remove (5530 - 1985) samples 
% =  3545 from the majority class.

samples_num = cell2mat(table2array(t_ratio_class(3,2))) - under_samples
%% 
% However instead of removing samples we will create a new dataset with 1985 
% samples randomly selected without replacement from the 5530 original samples 
% from the majority class.


% Input an imbalanced data and number of samples

% For reproducibility
rng(1,'twister');

% Create arrays for sampling purposes
x_rus = table2array(X_train_label);
y_rus = x_rus(:,end);

% Filter between majority class and the other 2 classes
X_maj = x_rus(find(y_rus == "euk"),:);
X_rest = x_rus(find(y_rus == "arc" | y_rus == "bct"),:);

% Generate random indexes for random undersampling
rp = randperm(size(X_maj,1));
random_sample = rp(1:under_samples);

X_rand_maj = X_maj(random_sample,:);

X_train_final = [str2double(X_rand_maj(:,1:end-1))  ; str2double(X_rest(:,1:end-1))];
y_train_final = [X_rand_maj(:,end) ; X_rest(:,end)];

%for i = 1 : 10
    % Select indexes randomly to be removed
%    out1 = randperm(size(r,1),p);
    
    % Include indexes randomly selected in the previous step
%    out1 = r(out1,:);
    
%    randSamp = [out1];
%    random_sample{i, :} = randSamp(randperm(size(randSamp, 1)), :); 
%end


% 5.3.4 Validate new dataset

X_train_label = addvars(array2table(X_train_final(:,1:end-1)), string(y_train_final),...
    'NewVariableNames','label');

%uniqueLabels = string(t(:,1));
%labelCounts = cell2mat(t(:,2));
%tbl = tabulate(X_train_label.label);
tabulate(X_train_label.label)
%% 
% 
% 3


X_train_label_t = addvars(array2table(X_train(:,1:end-1)), string(y_train),...
    'NewVariableNames','label');

%uniqueLabels = string(t(:,1));
%labelCounts = cell2mat(t(:,2));
%tbl = tabulate(X_train_label.label);
tabulate(X_train_label_t.label)
%%
% Appending performance measures to a table
LR_MaleMdlPerformance = table(Precision,Recall,Specificity, BM, FPR, FNR, FOR, NPV, FDR, MCC, MK, F1, F2, Accuracy,AUC,Time,...
    'RowNames',{'Model 1' 'Model 2' 'Model 3' 'Model 4' 'Model 5' 'Model 6' 'Model 7' 'Model 8' 'Model 9' 'Model 10' ...
                'Model 11' 'Model 12' 'Model 13' 'Model 14' 'Model 15' 'Model 16' 'Model 17' 'Model 18' 'Model 19' 'Model 20' ...
                'Model 21' 'Model 22' 'Model 23' 'Model 24' 'Model 25' 'Model 26' 'Model 27' 'Model 28' 'Model 29' 'Model 30'})
%% 
% prediction = predict(theta, X1Test(:,129:131));



% Define 5 as number of folds
K=5;
rng(1, 'twister');

% Change classes to numerical data
y_train_num = renamecats(categorical(y_train),{'arc','bct','euk'},{'1','2','3'});
y_train_num = str2double(string(y_train_num));
%y_train_n = grp2idx(y_train);

indices=crossvalind('Kfold',y_train_num,K);

[TP] = deal(zeros(K,1)); % Container for storing each fold performance measure obtained  during the loop

% Initialize variables
m = size(X_train, 2); % number of columns
numLabels = size(unique(y_train),1); % number of labels
theta = zeros(numLabels,m+1,K);


% Variable to store each fold time and total/avg time metrics
%fTime = 

for i_fold=1:K
    % Evaluate time for each fold iteration
    
    % Assigning training and validation set indexes
    val = (indices == i_fold);
    train = ~val;
    % Training set
    Xf_train = X_train(train,:);
    yf_train = y_train_num(train);
    % Validation set
    Xf_val = X_train(val,:);
    yf_val = y_train_num(val);
   
    
    lambda = 10; % regularization parameter
    %numLabels = size(unique(y_train_num),1); % number of labels
    
    % Training

    % No oversampling/undersampling 
    %Xf_train_balanced = Xf_train;
    %yf_train_balanced = y_train(train);
    
    % Apply SMOTE/Undersampling
    %[Xf_train_balanced, yf_train_balanced] = smote_and_undersampling(Xf_train, y_train(train), 3, 0.8,"smote_undersampling");
    
    % Apply SMOTE only (300 % more synthetic samples)
    [Xf_train_balanced, yf_train_balanced] = smote_and_undersampling(Xf_train, y_train(train), 3, 0,"smote");

    
    % Normalise dataset
    Xf_train_scaled = normalize(Xf_train_balanced);

    % Change classes to numerical data
    yf_train_num = renamecats(categorical(yf_train_balanced),{'arc','bct','euk'},{'1','2','3'});
    yf_train_num = str2double(string(yf_train_num));
    
    %% Training Multinomial Logistic Regression classifier
    fprintf('Training Multinomial Logistic Regression');    
    %theta_temp = LRTraining(Xf_train_scaled, yf_train_num, numLabels, lambda);
    %theta(:,:,i_fold) = theta_temp;
    
    %Mdl = fitcecoc(X,Y,'OptimizeHyperparameters','auto',...
    %'HyperparameterOptimizationOptions',struct('AcquisitionFunctionName',...
    %'expected-improvement-plus'))  
    t=templateLinear('Regularization','ridge', 'Lambda', 0.1,'Learner','logistic','Solver','lbfgs');
    LR_model=fitcecoc(Xf_train_scaled,yf_train_num,'Learners',t);
    
    %% Prediction 
    %[preds] = LRPrediction(Xf_val_scaled, yf_val, W, b);
    Xf_val_scaled = normalize(Xf_val);

    % Predict class values and calculate probability of each class
    %predicted_y = LRPredict(theta_temp, Xf_val_scaled);
    %proba = LRPredictProba(theta_temp, Xf_val_scaled);
    [predicted_y scores] = predict(LR_model,Xf_val_scaled);


    %cm = confusionchart(yf_val,predicted_y);
    
    weight_classes = [sum(yf_val==1)/length(yf_val);sum(yf_val==2)/length(yf_val);...
                  sum(yf_val==3)/length(yf_val)];
    
    lr_val_stats = confusionMatStats(yf_val, predicted_y, weight_classes);
    %(ifold)
    %m = size(Xf_val(:,3:end), 1);
    %Xf_val_scaled = [ones(m, 1) normalize(table2array(Xf_val(:,3:end)))];
    

    %diffscore=zeros;
    for i=1:size(proba,1)
        % a row vector holding the scores for the classes [A, B, C, D] for the ith observation out of the total.
        %temp=scores(i,:); 
    %    % score of +ve class minus the maximum of the scores of all the negative classes (similar to the example available via the webpage link) 
    %    diffscore(i,:)=temp(2)-max([temp(1),temp(3)]); 
        if i==1
            diffscore = scores(:,1) - max(scores(:,2),scores(:,3));
        elseif i==2
            diffscore = scores(:,2) - max(scores(:,1),scores(:,3));
        else
            diffscore = scores(:,3) - max(scores(:,1),scores(:,2));
        end
        
        if i == 1
            [X,Y,T,~,OPTROCPT,suby,subnames] = perfcurve(yf_val,diffscore,i);
            plot(X,Y)
            hold on
            plot(OPTROCPT(1),OPTROCPT(2),'ro')
            xlabel('False positive rate') 
            ylabel('True positive rate')
            title('ROC Curve for Classification by Classification Trees')
            hold off
        else
            %plot(suby(:,i),X)
        end
    end
    %hold off;
    
    %[X_perf,Y_perf,T,~,OPTROCPT,suby,subnames] = perfcurve(yf_val,diffscore,2); % predicted_y: True class labels

    
            

    %if i==1 %if is the first fold 
    %    mean_curve= (interp1(x_adj, Yroc, intervals))/k; 
    %else
    %    mean_curve= mean_curve+ (interp1(x_adj, Yroc, intervals))/k; 
    %end


    
    
    if i_fold == 1
        % Save results of performance to a table of measures
        LR_BaselinePerf = table(i_fold, {lr_val_stats.precision},{lr_val_stats.recall},{lr_val_stats.specificity}, ...
            {lr_val_stats.tp}, {lr_val_stats.tn}, {lr_val_stats.fp}, {lr_val_stats.fn}, ...
             lr_val_stats.Fscore_macro, lr_val_stats.Fscore_micro,lr_val_stats.accuracy, ...
             lr_val_stats.balanced_accuracy,lr_val_stats.weighted_balanced_accuracy);
        
        % Modify variable names
        LR_BaselinePerf.Properties.VariableNames = {'Fold_number' 'Precision' 'Recall' 'Specificity' ...
          'TP' 'TN' 'FP' 'FN' 'FScore_Macro' 'FScore_Micro' 'Accuracy' 'Balanced_Accuracy' ...
          'Weighted_Balanced_Accuracy'};
    else
        LR_BaselinePerf = [LR_BaselinePerf ; {i_fold, {lr_val_stats.precision},{lr_val_stats.recall},{lr_val_stats.specificity}, ...
        {lr_val_stats.tp}, {lr_val_stats.tn}, {lr_val_stats.fp}, {lr_val_stats.fn}, ...
         lr_val_stats.Fscore_macro, lr_val_stats.Fscore_micro,lr_val_stats.accuracy, ...
         lr_val_stats.balanced_accuracy,lr_val_stats.weighted_balanced_accuracy}];
    end
    
end
%%
%lr_precision={lr_val_stats.precision};
LR_BaselinePerf = table(i_fold, {lr_val_stats.precision},...
    {'Fold_number' 'Precision'});



%%



% Visualising in 4D the performance of above model using scatter3 and stacked plot
figure
scatter3(LR_MdlPerformance.Precision, LR_MdlPerformance.Recall, LR_MdlPerformance.Specificity, 100, LR_MdlPerformance.Accuracy, 'filled')
set(gca,'color',"#ecf0f1")
title('Performance measures of 30 logistic regression models', 'FontSize', 20)
xlabel('Precision', 'FontSize', 20)
ylabel('Recall', 'FontSize', 20)
zlabel('Specificity', 'FontSize', 20)
colormap(jet)
hcb = colorbar('Location', 'EastOutside', 'FontSize', 20);
hcb.Title.String = "Accuracy";

xplot = [0:1:29]; % stacked plot to visualise the remainder measures of performance to aid selecting the best performing model
stackedplot(LR_MdlPerformance,["BM","FPR","FNR","FOR","NPV","FDR","MCC","MK","F1","F2","AUC","Time"]);



%% |5.4 Regularization and best model selection|
% 
% 
% |%  In this part, you will get to try different values of lambda and|
% 
% |%  see how regularization affects the decision coundart|
% 
% 
% 
% |%  We will try the following values of lambda (0, 0.1, 1, 10, 100).|
% 
% |and investigate how does the decision boundary change when we vary lambda 
% and how does|
% 
% |the metrics vary. We will also test with differents values of solver ('quasi-newton' 
% and ' marquart'|

find(yf_val==3)
%%

 

% Define 5 as number of folds
K=5;
rng(1, 'twister');

% Change classes to numerical data
y_train_num = renamecats(categorical(y_train),{'arc','bct','euk'},{'1','2','3'});
y_train_num = str2double(string(y_train_num));
%y_train_n = grp2idx(y_train);

indices=crossvalind('Kfold',y_train_num,K);

[TP] = deal(zeros(K,1)); % Container for storing each fold performance measure obtained  during the loop

% Initialize variables
m = size(X_train, 2); % number of columns
numLabels = size(unique(y_train),1); % number of labels
theta = zeros(numLabels,m+1,K);



alpha_values = [0.1, 1, 10, 10];
solver_values = ['quasi-newton','']

for i_fold=1:K
    % Evaluate time for each fold iteration
    
    % Assigning training and validation set indexes
    val = (indices == i_fold);
    train = ~val;
    % Training set
    Xf_train = X_train(train,:);
    yf_train = y_train_num(train);
    % Validation set
    Xf_val = X_train(val,:);
    yf_val = y_train_num(val);
   
    
    lambda = 10; % regularization parameter
    %numLabels = size(unique(y_train_num),1); % number of labels
    
    % Trainin
    % No oversampling/undersampling 
    %Xf_train_balanced = Xf_train;
    %yf_train_balanced = y_train(train);
    
    % Apply SMOTE/Undersampling
    %[Xf_train_balanced, yf_train_balanced] = smote_and_undersampling(Xf_train, y_train(train), 3, 0.8,"smote_undersampling");
    
    % Apply SMOTE only (300 % more synthetic samples)
    [Xf_train_balanced, yf_train_balanced] = smote_and_undersampling(Xf_train, y_train(train), 3, 0,"smote");

    
    % Normalise dataset
    Xf_train_scaled = normalize(Xf_train_balanced);

    % Change classes to numerical data
    yf_train_num = renamecats(categorical(yf_train_balanced),{'arc','bct','euk'},{'1','2','3'});
    yf_train_num = str2double(string(yf_train_num));
    
    %% Training Multinomial Logistic Regression classifier
    fprintf('Training Multinomial Logistic Regression');    
    theta_temp = LRTraining(Xf_train_scaled, yf_train_num, numLabels, lambda);
    theta(:,:,i_fold) = theta_temp;
    %[W, b] = LRTrain(Xf_train_scaled, yf_train, lambda, numLabels);
    
    %% Prediction 
    %[preds] = LRPrediction(Xf_val_scaled, yf_val, W, b);
    Xf_val_scaled = normalize(Xf_val);

    % Using MLR
    predicted_y = LRPredict(theta_temp, Xf_val_scaled);
    proba = LRPredictProba(theta_temp, Xf_val_scaled);
    
    % Add ones to the X data matrix (x0)
    %Xf = [ones(size(Xf_val_scaled, 1), 1) Xf_val_scaled];

    %pihat = sigmoid(Xf * theta_temp');
    %cm = confusionchart(yf_val,predicted_y);
    
    lr_stats = confusionmatStats(confusionmat(yf_val, predicted_y),...
        [sum(yf_val==1) sum(yf_val==2) sum(yf_val==3)]);
    %(ifold)
    %m = size(Xf_val(:,3:end), 1);
    %Xf_val_scaled = [ones(m, 1) normalize(table2array(Xf_val(:,3:end)))];
    

    %diffscore=zeros;
    %for i=1:size(proba,1)
    %    temp=proba(i,:); % a row vector holding the scores for the classes [A, B, C, D] for the ith observation out of the total.
    %    % score of +ve class minus the maximum of the scores of all the negative classes (similar to the example available via the webpage link) 
    %    diffscore(i,:)=temp(2)-max([temp(1),temp(3)]); 
    %end
    
    %[X_perf,Y_perf,T,~,OPTROCPT,suby,subnames] = perfcurve(yf_val,diffscore,2); % predicted_y: True class labels

    
      

    %if i==1 %if is the first fold 
    %    mean_curve= (interp1(x_adj, Yroc, intervals))/k; 
    %else
    %    mean_curve= mean_curve+ (interp1(x_adj, Yroc, intervals))/k; 
    %end


end

%% 5.2.9 Generating SMOTE dataset for training with entire set

% Apply SMOTE (500 % more synthetic samples) and undersampling of majority
% class
[X_train_balanced, y_RF_train_balanced] = smote_and_undersampling(X_train, y_train, 5, 0.33,"smote_undersampling");



%% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
%% 
% 
%% 5.3 Random Forest
% 
% 
% *Model validation choice*
% 
% Random forests already have a unique, convenient property which is bootstrapping 
% that is used to fit the individual trees, which readily yields the out-of-bag 
% (OOB) error. This is an unbiased estimate of the error on future data, and can 
% therefore take the place of the validation or test set error. This leaves more 
% data available for training, and is computationally cheaper than nested cross 
% validation.
% 
% 
% 
% 
% 
% *Hyperparameter optimisation choice*
% 
% First we opted to implement grid search optimization to verify if there is 
% any region of best performance and then we will implement Bayesian Optimisation.
% 
% Tuning the number of trees is unnecessary; instead, simply set the number 
% of trees to a large, computationally feasible number, and let the asymptotic 
% behavior of LLN do the rest.
% 
% In the case that you have some kind of constraint (a cap on the total number 
% of terminal nodes, a cap on the model estimation time, a limit to the size of 
% the model on disk), this amounts to choosing the largest TT that satisfies your 
% constraint.
% 
% We need to define a few hyperparameters that will be important to be analysed 
% by the random forest:
% 
% *MinLeafSize*
% 
% For boosting ensemble methods, specify the maximum number of splits or branch 
% points to control the depth of your tree learners. Many branches tend to overfit, 
% and simpler trees can be more robust and easy to interpret. Experiment to choose 
% the best tree depth for the trees in the ensemble.
% 
% NumTrees
% 
% NumPredictorstoSample
% 
% NumSplits
% 
% Grid search and random forest implementation


leaf = [5 10 20 30 40];
NumTrees = [5 10 20 30 40];
NumSplits = [5 10 15 20 25];
numPredictors = [1 3 5 7 9];
gsErrors = [];
Accuracy = [];
Time = [];
for i=1:length(leaf)
    for j=1:length(NumTrees)
        for s=1:length(numSplits)
            for p=1:length(numPredictors)
                t_old = clock;
                b = TreeBagger(numTree(j),X_train,y_train, "SampleWithReplacement", "on",'Method','Classification','OOBPrediction','On',...
            			'OOBPredictorImportance','On','MinLeafSize',leaf(i),'MaxNumSplits',numSplits(s),'NumPredictorsToSample',numPredictors(p));
                [predicted_labels, scores] = cell2mat(oobPredict(b)); %str2num(cell2mat(oobPredict(b)));
                cm_rf = confusionmat(y_train, predicted_labels);
                Accuracy_model = 100*sum(diag(cm_rf))./sum(cm_rf(:));
                Accuracy = [Accuracy; Accuracy_model];
                gsErrors = [gsErrors; leaf(i) numTree(j) numSplits(s) numPredictors(p) sum(1-(y_train == predicted_labels)) / length(y_train)];
                Time = [Time; etime(clock, t_old)];
                Final_Male = [gsErrors Accuracy Time];
            end
        end
    end
end



% 5.3.1 Using Bayesian Optimisation
% 
% 
% We know that matlab function TreeBagger doesn't have built-in hyperparameter 
% optimization therefore we need to use 'bayesopt' function. 
% 
% Efficiently find the best target solution.
% 
% It is a iterative process and it starts with a selection of a sampling set.
% 
% Given the sampling set then we train a gaussian process, after that we calculate 
% an acquisition function and finally identify the input vector minimizing the 
% acquisition function value.
% 
% 



X_RF_train = array2table(X_train,...
    'VariableNames',features_to_keep);

y_RF_train = array2table(y_train,...
    'VariableNames',{'Kingdom'});

X_RF_train_label = [X_RF_train y_RF_train];

% Merge tables
%T2 = outerjoin(T,tempTable,'MergeKeys', 1)

%% 
% 
% 
% NumSplits = [5 10 15 20 25];
% 
% We decided to leave off a few set parameters out of the algorithm (e.g. prune).
% 
% *Pruning* decision trees is not recommended for ensembles.


rng('default'); % For reproducibility


maxminLeafSize = 30;
minNumSplits = 5; 
maxNumSplits = 40; 
%maxNumTrees = 500;
% Define variables that should be optimised with Bayes Optimisation (BO)
Hyperparameters = [optimizableVariable('minLeafSize',[1,maxminLeafSize], 'Type','integer');
                   optimizableVariable('numPredictorstoSample', [1,size(X_RF_train_label,2)-1], 'Type','integer');
                   optimizableVariable('maxNumSplits', [minNumSplits,maxNumSplits], 'Type','integer')];
                   %optimizableVariable('NumTrees', [1,maxNumTrees], 'Type','integer')];

% Define the objective function to be the out-of-bag Quantile Error. 
fun = @(hparams)oobErrorRF(hparams,X_RF_train_label);          % It must be a function of only the hyperparameters.


% Call bayesopt to optimize Quantile Error
results = bayesopt(fun, Hyperparameters,'AcquisitionFunctionName','expected-improvement-plus','Verbose',1);


% Look at the best hyperparameters found
%bestHyperparameters = bestPoint(results)
bestOOBErr = results.MinObjective
bestHyperparameters = results.XAtMinObjective

% Fit final Random Forest  model to the full dataset using the best hyperparameters
%FinalModel = TreeBagger(300,X,'MPG','Method','regression',...
%                        'MinLeafSize', bestHyperparameters.MinLeafSize,...
%                        'NumPredictorstoSample', bestHyperparameters.NumPredictorstoSample)

%% 
% 
% 
% Reference:https://uk.mathworks.com/help/stats/tune-random-forest-using-quantile-error-and-bayesian-optimization.html


%% 5.3.2 Performing training using best hyperparameters choice
% 

bestminLeafSize = bestHyperparameters.minLeafSize;

bestnumPredictorstoSample = bestHyperparameters.numPredictorstoSample;

bestmaxNumSplits = bestHyperparameters.maxNumSplits;


oobRF = TreeBagger(400,X_RF_train_label,'Kingdom',"SampleWithReplacement", "on",'Method','Classification',...
                          'OOBPrediction','On', 'OOBPredictorImportance','On',...
                          'MinLeafSize',bestminLeafSize,...
                          'NumPredictorstoSample',bestnumPredictorstoSample,...
                          'MaxNumSplits',bestmaxNumSplits);

oobErr = oobError(oobRF, 'Mode','ensemble');


%% 
% Prediction of Out-of-Bag samples with training set (without oversampling / 
% undersampling)

%pred = str2num(cell2mat(predict(oobRF,X_RF_train)));


[predicted_labels, scores] = oobPredict(oobRF);
%cm_RF = confusionmat(cellstr(table2array(y_RF_train)), cell2mat(predicted_labels));
%Accuracy_model = 100*sum(diag(ConfMat))./sum(ConfMat(:));
%Accuracy = [Accuracy; Accuracy_model];
%gsErrors = [gsErrors; leaf(i) numTree(j) numSplits(s) numPredictors(p) sum(1-(yTrain_Male == predicted_labels)) / length(yTrain_Male)];
%Time = [Time; etime(clock, t_old)];

weight_classes = [sum(y_train=='arc')/length(y_train);sum(y_train=='bct')/length(y_train);...
                  sum(y_train=='euk')/length(y_train)];
rf_train_scores = confusionMatStats(cellstr(y_train),predicted_labels,weight_classes);


% Plotting performance
tiledlayout('flow');
nexttile
Confmat_RFTrain = confusionchart(cellstr(table2array(y_RF_train)), predicted_labels,'RowSummary','row-normalized','FontSize',12,'FontName','Arial');
sortClasses(Confmat_RFTrain,["arc","bct","euk"]);
Confmat_RFTrain.Normalization = 'absolute'; 
title("Confusion chart");
%%
bar(oobRF.OOBPermutedVarDeltaError)
xlabel('Feature Index')
ylabel('Out-of-Bag Feature Importance')
%% 5.5.4 with oversampling
% 
% 
% In this step we generate a new set of samples for the minority class 1 and 
% Generate syn
% 
% 


%% 
%% 
%% 5.5.4 with oversampling
% 

rng('default'); % For reproducibility


maxminLeafSize = 30;
minNumSplits = 2;  
maxNumSplits = 50; 
maxNumTrees = 500;

splitCriterion = 'gdi';
% Define variables that should be optimised with Bayes Optimisation (BO)
Hyperparameters = [optimizableVariable('minLeafSize',[1,maxminLeafSize], 'Type','integer');
                   optimizableVariable('numPredictorstoSample', [1,size(X_RF_SMOTE_train_label,2)-1], 'Type','integer');
                   optimizableVariable('maxNumSplits', [minNumSplits,maxNumSplits], 'Type','integer'),...
                   optimizableVariable('maxNumTrees', [1,maxNumTrees], 'Type','integer')];

% Define the objective function to be the out-of-bag Quantile Error. 
fun = @(hparams)oobErrorRF(hparams,X_RF_SMOTE_train_label,splitCriterion);          % It must be a function of only the hyperparameters.


% Call bayesopt to optimize Quantile Error
results = bayesopt(fun, Hyperparameters,'AcquisitionFunctionName','expected-improvement-plus','Verbose',1);
%% 
% 

bestminLeafSize = 16; %bestHyperparameters.minLeafSize;

bestnumPredictorstoSample = 15; %bestHyperparameters.numPredictorstoSample;

bestmaxNumSplits = 5; %bestHyperparameters.maxNumSplits;

bestmaxNumTrees = 128; %bestHyperparameters.maxNumTrees;


rng(1,'twister'); % For reproducibility
%oobRF = TreeBagger(128,X_RF_SMOTE_train_label,'Kingdom',"SampleWithReplacement", "on",'Method','Classification',...
%                          'OOBPrediction','On', 'OOBPredictorImportance','On',...
%                          'MinLeafSize',bestminLeafSize,...
%                          'NumPredictorstoSample',bestnumPredictorstoSample,...
%                          'MaxNumSplits',bestmaxNumSplits);
%

oobRF = TreeBagger(bestmaxNumTrees,X_RF_SMOTE_train_label,'Kingdom',"SampleWithReplacement", "on",'Method','Classification',...
                          'OOBPrediction','On', 'OOBPredictorImportance','On',...
                          'MinLeafSize',bestminLeafSize,...
                          'NumPredictorstoSample',bestnumPredictorstoSample,...
                          'MaxNumSplits',bestmaxNumSplits, ...
                          'AlgorithmForCategorical','PCA','Prior','Empirical', ...
                          'SplitCriterion',splitCriterion);

oobErr = oobError(oobRF, 'Mode','ensemble');


%% 
% Prediction of Out-of-Bag samples with training set (without oversampling / 
% undersampling)

%pred = str2num(cell2mat(predict(oobRF,X_RF_train)));


[predicted_labels, scores] = oobPredict(oobRF);
%cm_RF = confusionmat(cellstr(table2array(y_RF_train)), cell2mat(predicted_labels));
%Accuracy_model = 100*sum(diag(ConfMat))./sum(ConfMat(:));
%Accuracy = [Accuracy; Accuracy_model];
%gsErrors = [gsErrors; leaf(i) numTree(j) numSplits(s) numPredictors(p) sum(1-(yTrain_Male == predicted_labels)) / length(yTrain_Male)];
%Time = [Time; etime(clock, t_old)];
%%
%% plot PRCs

y_train_num = renamecats(categorical(table2array(y_RF_SMOTE_train)),{'arc','bct','euk'},{'1','2','3'});
y_train_num = str2double(string(y_train_num));


i=1;
tgt=-ones(1,length(y_RF_SMOTE_train));
positive_class=find(y_RF_SMOTE_train==i);
tgt(positive_class)=1;
legends_prc{i} = sprintf('PRC for %s class', codon_classes{i});
fprintf(PR1);
%% Plot PRCs
plt_prc = compute_prc_roc(tgt,proba(:, i)',"PRC",codon_classes{i},i,i_fold,legends_prc,plt_prc);

drawnow();
for i=2:length(codon_classes)
    tgt=-ones(1,length(y_RF_SMOTE_train));
    positive_class=find(y_RF_SMOTE_train==i);
    tgt(positive_class)=1;
    legends_prc{i} = sprintf('PRC for %s class', codon_classes{i});
    fprintf(PR1);
    %% Plot PRCs
    plt_prc = compute_prc_roc(tgt,proba(:, i)',"PRC",codon_classes{i},i,i_fold,legends_prc,plt_prc);
    drawnow();
end
  
%%
figure;
[x,y,t,auc,optrocpt,suby,subynames] = perfcurve(y_train_num,scores(:, i),...
1,'negClass',[2 3],...
'ycrit','fpr','xcrit','tpr');
plot(suby(:,1),x)
hold
plot(suby(:,2),x,'r')
hold off
title('Two ROC curves')
%%

% Plotting Confusion Matrix

weight_classes = [sum(table2array(y_RF_SMOTE_train)=='arc')/length(table2array(y_RF_SMOTE_train));...
                  sum(table2array(y_RF_SMOTE_train)=='bct')/length(table2array(y_RF_SMOTE_train));...
                  sum(table2array(y_RF_SMOTE_train)=='euk')/length(table2array(y_RF_SMOTE_train))];
rf_train_scores = confusionMatStats(cellstr(table2array(y_RF_SMOTE_train)),predicted_labels,weight_classes);


tiledlayout('flow');
nexttile
Confmat_RFTrain = confusionchart(cellstr(table2array(y_RF_SMOTE_train)), predicted_labels,'RowSummary','row-normalized','FontSize',12,'FontName','Arial');
sortClasses(Confmat_RFTrain,["arc","bct","euk"]);
Confmat_RFTrain.Normalization = 'absolute'; 
title("Confusion chart");

%rf_smote_train_scores = confusionMatStats(cellstr(y_RF_SMOTE_train),predicted_labels,weight_classes);


% Saving metrics to a table
%RF_SMOTETraining = table(Precision,Recall,Specificity, BM, FPR, FNR, FOR, NPV, FDR, MCC, MK, F1, F2, Accuracy,AUC,Time,...
%    'RowNames',{'Optimised RF model with SMOTE'}) % Creating a table of performance for the best performing model

%% Using cross-validation to improve performance of Bayesian Optimisation function


rng('default'); % For reproducibility


maxminLeafSize = 30;
minNumSplits = 2;  
maxNumSplits = 50; 
%maxNumTrees = 500;
numkfold = 5;

% Gini Index
splitCriterion = 'gdi';

% Define variables that should be optimised with Bayes Optimisation (BO)
Hyperparameters = [optimizableVariable('minLeafSize',[1,maxminLeafSize], 'Type','integer');
                   optimizableVariable('numPredictorstoSample', [1,size(X_RF_SMOTE_train_label,2)-1], 'Type','integer');
                   optimizableVariable('maxNumSplits', [minNumSplits,maxNumSplits], 'Type','integer')];
                   %,optimizableVariable('maxNumTrees', [1,maxNumTrees], 'Type','integer')];

% Define the objective function to be the out-of-bag classification Error. 
%ObjFcn = @(hparams)makeObjFcn(hparams,numkfold,X_RF_train_label,splitCriterion);          % It must be a function of only the hyperparameters.
ObjFcn = makeObjFcn(numkfold,X_RF_train_label,splitCriterion); % It must be a function of only the hyperparameters.

% Call bayesopt to optimize Classification Error
results_bo_smote = bayesopt(ObjFcn, Hyperparameters,'AcquisitionFunctionName','expected-improvement-plus','Verbose',1);
%% 
% 
%% 5.9 Generate best model from the training set (using all data)
% We will use the same training dataset with 300% of synthetic samples generated 
% from Logistic regression


% Convert X and y arrays to table
X_RF_SMOTE_train = array2table(X_RF_train_balanced,...
    'VariableNames',features_to_keep);

y_RF_SMOTE_train = array2table(y_RF_train_balanced,...
    'VariableNames',{'Kingdom'});

X_RF_SMOTE_train_label = [X_RF_SMOTE_train y_RF_SMOTE_train];

tabulate(y_RF_train_balanced)
%% 
% 
%% 
% 
%% 5.10 Validating the optimised RF model on the test set

tic; % Start recording execution time
predicted_test = cellstr(predict(oobRF,X_test)); % Prediction of RF model for testing set
 

% Build metric scores based on pred_test
weight_classes = [sum(y_test=='arc')/length(y_test);sum(y_test=='bct')/length(y_test);...
                  sum(y_test=='euk')/length(y_test)];
rf_test_scores = confusionMatStats(cellstr(y_test),predicted_test,weight_classes);

% Visualising performance of RF prediction for test set
figure;
t = tiledlayout('flow');
t.Title.String = 'Performance of optimised random forest model on test set';
nexttile
Confmat_RFTest = confusionchart(cellstr(y_test),predicted_test,'RowSummary','row-normalized','FontSize',12,'FontName','Arial');
sortClasses(Confmat_RFTest,["arc","bct","euk"]);
Confmat_RFTest.Normalization = 'absolute'; 
title("Confusion chart");
%% 
% Prediction on 
% 
% Plot performance of the best model
% 
% 

pred = str2num(cell2mat(predict(oobRF,xTest_Male))); % Prediction of RF model for male testing dataset

% Plotting performance
tiledlayout('flow');
nexttile
Confmat_RFTrain = confusionchart(yTrain_Male,pred,'RowSummary','row-normalized','FontSize',12,'FontName','Arial');
sortClasses(Confmat_RFTrain,["1","0"]);
Confmat_RFTrain.Normalization = 'absolute'; 
title("Confusion chart");
%% 
% *6. Comparison of LR & RF models for predicting Kingdom classes*
% 
% *Based on the best models we will compare metrics related to the minority 
% class such as the weighted balance accuracy and Precision-Recall curves*

figure
scatter3(combined_performance.Precision, combined_performance.Recall, combined_performance.Specificity, 100, combined_performance.Accuracy, 'filled')
set(gca,'color',"#ecf0f1")
title('Performance measures of LR and RF models', 'FontSize', 20)
xlabel('Precision', 'FontSize', 20)
ylabel('Recall', 'FontSize', 20)
zlabel('Specificity', 'FontSize', 20)
colormap(jet)
hcb = colorbar('Location', 'EastOutside', 'FontSize', 20);
hcb.Title.String = "Accuracy";

%% 
% 
% 
% *7. Auxiliary functions* 
% 
% *Functions list:*
% 
% *Violinplot*
% 
% *LRTraining*
% 
% *LRPredict*
% 
% *SafeLevelSMOTE (apply SafeLevelSMOTE oversampling algorithm based on a class 
% and return a new sample)*
% 
% *generateGap (*
% 
% *sigmoid (compute sigmoid of a variable z)*
% 
% *fmincg (Minimize a continuous differentialble multivariate function)*
% 
% *costFunctionReg (Compute cost and gradient for logistic regression with regularization)*
% 
% *confusionMatStats (calculate metrics to assess the algorithms comparison)*
% 
% *oobErrRF (Bayesian Optimisation hyperparameter function)*
% 
% *boxplot_statistics (calculate data description statistics)*
% 
% *compute_prc_roc (receiver operating characteristic curve)*
% 
% 

function violins = violinplot(data, cats, varargin)
%Violinplots plots violin plots of some data and categories
%   VIOLINPLOT(DATA) plots a violin of a double vector DATA
%
%   VIOLINPLOT(DATAMATRIX) plots violins for each column in
%   DATAMATRIX.
%
%   VIOLINPLOT(TABLE), VIOLINPLOT(STRUCT), VIOLINPLOT(DATASET)
%   plots violins for each column in TABLE, each field in STRUCT, and
%   each variable in DATASET. The violins are labeled according to
%   the table/dataset variable name or the struct field name.
%
%   VIOLINPLOT(DATAMATRIX, CATEGORYNAMES) plots violins for each
%   column in DATAMATRIX and labels them according to the names in the
%   cell-of-strings CATEGORYNAMES.
%
%   VIOLINPLOT(DATA, CATEGORIES) where double vector DATA and vector
%   CATEGORIES are of equal length; plots violins for each category in
%   DATA.
%
%   violins = VIOLINPLOT(...) returns an object array of
%   <a href="matlab:help('Violin')">Violin</a> objects.
%
%   VIOLINPLOT(..., 'PARAM1', val1, 'PARAM2', val2, ...)
%   specifies optional name/value pairs for all violins:
%     'Width'        Width of the violin in axis space.
%                    Defaults to 0.3
%     'Bandwidth'    Bandwidth of the kernel density estimate.
%                    Should be between 10% and 40% of the data range.
%     'ViolinColor'  Fill color of the violin area and data points.
%                    Defaults to the next default color cycle.
%     'ViolinAlpha'  Transparency of the violin area and data points.
%                    Defaults to 0.3.
%     'EdgeColor'    Color of the violin area outline.
%                    Defaults to [0.5 0.5 0.5]
%     'BoxColor'     Color of the box, whiskers, and the outlines of
%                    the median point and the notch indicators.
%                    Defaults to [0.5 0.5 0.5]
%     'MedianColor'  Fill color of the median and notch indicators.
%                    Defaults to [1 1 1]
%     'ShowData'     Whether to show data points.
%                    Defaults to true
%     'ShowNotches'  Whether to show notch indicators.
%                    Defaults to false
%     'ShowMean'     Whether to show mean indicator
%                    Defaults to false
%     'GroupOrder'   Cell of category names in order to be plotted.
%                    Defaults to alphabetical ordering

% Copyright (c) 2016, Bastian Bechtold
% This code is released under the terms of the BSD 3-clause license

    hascategories = exist('cats','var') && not(isempty(cats));
    
    %parse the optional grouporder argument 
    %if it exists parse the categories order 
    % but also delete it from the arguments passed to Violin
    grouporder = {};
    idx=find(strcmp(varargin, 'GroupOrder'));
    if ~isempty(idx) && numel(varargin)>idx
        if iscell(varargin{idx+1})
            grouporder = varargin{idx+1};
            varargin(idx:idx+1)=[];
        else
            error('Second argument of ''GroupOrder'' optional arg must be a cell of category names')
        end
    end

    % tabular data
    if isa(data, 'dataset') || isstruct(data) || istable(data)
        if isa(data, 'dataset')
            colnames = data.Properties.VarNames;
        elseif istable(data)
            colnames = data.Properties.VariableNames;
        elseif isstruct(data)
            colnames = fieldnames(data);
        end
        catnames = {};
        for n=1:length(colnames)
            if isnumeric(data.(colnames{n}))
                catnames = [catnames colnames{n}];
            end
        end
        for n=1:length(catnames)
            thisData = data.(catnames{n});
            violins(n) = Violin(thisData, n, varargin{:});
        end
        set(gca, 'XTick', 1:length(catnames), 'XTickLabels', catnames);

    % 1D data, one category for each data point
    elseif hascategories && numel(data) == numel(cats)

        if isempty(grouporder)
            cats = categorical(cats);
        else
            cats = categorical(cats, grouporder);
        end

        catnames = (unique(cats)); % this ignores categories without any data
        catnames_labels = {};
        for n = 1:length(catnames)
            thisCat = catnames(n);
            catnames_labels{n} = char(thisCat);
            thisData = data(cats == thisCat);
            violins(n) = Violin(thisData, n, varargin{:});
        end
        set(gca, 'XTick', 1:length(catnames), 'XTickLabels', catnames_labels);

    % 1D data, no categories
    elseif not(hascategories) && isvector(data)
        violins = Violin(data, 1, varargin{:});
        set(gca, 'XTick', 1);

    % 2D data with or without categories
    elseif ismatrix(data)
        for n=1:size(data, 2)
            thisData = data(:, n);
            violins(n) = Violin(thisData, n, varargin{:});
        end
        set(gca, 'XTick', 1:size(data, 2));
        if hascategories && length(cats) == size(data, 2)
            set(gca, 'XTickLabels', cats);
        end

    end

end


function [newdata,visdata] = SafeLevelSMOTE(data, minorityLabel, num2Add, options)
% Input
% data: table data with features and labels
% 1. The right-most variable is treated as labels
% 2. Features are expected to be numeric values
%
% minorityLabel (scalar string): Label to oversample
% num2Add (scalar numeric): Number of data to generate
% options.NumNeighbors (scalar integer): number of neighbors to consider
% options.Standardize (scalar logical):
% Standard-euclidean (true) or Euclidean distance (false) distance to search the neighbors
%
% Output
% newdata: generated dataset
% visdata: optional output for debugging
%REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH-
% Copyright (c) 2019 Michio Inoue

arguments
    data {mustBeTableWithClassname}
    minorityLabel (1,1) string
    num2Add (1,1) double {mustBeNonnegative, mustBeInteger} = 0
    options.NumNeighbors (1,1) double {mustBePositive, mustBeInteger} = 5
    options.Standardize (1,1) logical = false;
end

numNeighbors = options.NumNeighbors;
if options.Standardize
    distance = 'seuclidean';
else
    distance = 'euclidean';
end

% If N is smaller than zero, do not oversample data
if  num2Add <= 0
    newdata = table;
    visdata = cell(1);
    return;
end

visdata = cell(num2Add,4);
% Optional output for visualization purpose only
% 1: y, 2: nnarray, 3: y2, 4: synthetic

% labels of whote dataset
labelsAll = string(data{:,end});

% all feature dataset
featuresAll = data{:,1:end-1};

% feature dataset of the minority label
featuresMinority = data{labelsAll == minorityLabel,1:end-1};

% Number of minority data
NofMinorityData = size(featuresMinority,1);

% safe-level of each minority class data
safeLevels = zeros(NofMinorityData,1);

% Save list of neighboring points for each minority data
nnarrays = cell(NofMinorityData,1);
for ii=1:NofMinorityData
    y = featuresMinority(ii,:); % a minority data
    [nnarray, ~] = knnsearch(featuresAll,y,'k',numNeighbors+1,...
        'Distance',distance, ...
        'SortIndices',true); % search for neighboring points
    % NOTE: this include self y, needs to omit y from nnarray
    nnarray = nnarray(2:end);
    
    idx = labelsAll(nnarray) == minorityLabel;
    NofNonMinority = sum(~idx); % number of non-minority data
    nnarrays{ii} = nnarray(idx); % keeps minority dataset only
    safeLevels(ii) = numNeighbors-NofNonMinority;
    % safe level of y, safeLevelP
    % safe level of nnarray, saveLevelN
end

% If the number of minority data is smaller than the requested number of new
% data set (num2Add), we randomly pick num2Add of minority data to be used to generate
% data.
if NofMinorityData >= num2Add
    idx = randperm(NofMinorityData,num2Add);
    featuresMinoritySubset = featuresMinority(idx,:);
    T1 = num2Add; % Number of data from minority dataset to be used
    T2 = 1; % Number of newdata from each minority dataset
else
    % Otherwise we use all minority data
    idx = randperm(NofMinorityData); % just to randamize
    featuresMinoritySubset = featuresMinority(idx,:);
    T1 = NofMinorityData; % Number of data from minority dataset to be used
    T2 = ceil(num2Add/NofMinorityData); % Number of newdata from each minority dataset
    % Note: doe to CEIL the total number of newdata may exceeds the
    % requested #, num2Add. Currently, the below has the routine to stop the process at num2Add.
end

% Array to save the synthesized features
newFeatures = zeros(num2Add,size(featuresMinority,2));
index = 1;

while index < num2Add 
% Make sure if num2Add is satisfied since it skips when gan = nan;
    for ii=1:T1 % Number of data from minority dataset to be used
        y = featuresMinoritySubset(ii,:); % a minority data
        safeLevelP = safeLevels(ii);
        
        [nnarray, ~] = knnsearch(featuresMinoritySubset,y,'k',numNeighbors+1,...
            'Distance',distance, ...
            'SortIndices',true); % search for neighboring points
        % NOTE: this include self y, needs to omit y from nnarray
        nnarray = nnarray(2:end);
        
        for kk=1:T2 % Number of newdata from each minority dataset
            nn = datasample(nnarray, 1); % pick one (randomly)
            safeLevelN = safeLevels(nn);
            diff = featuresMinoritySubset(nn,:) - y;
            gap = generateGap(safeLevelP, safeLevelN);
            if isnan(gap)
                continue; % for case 1
            end
            synthetic = y + gap.*diff; % “à‘}
            newFeatures(index,:) = synthetic;
            
            visdata{index,1} = y;
            visdata{index,2} = featuresMinoritySubset(nnarray,:);
            visdata{index,3} = featuresMinoritySubset(nn,:);
            visdata{index,4} = synthetic;
            
            index = index + 1;
            
            if index > num2Add
                break;
            end
        end
    end
end

% make newFeature to table data with the same variable names
tmp = array2table(newFeatures,'VariableNames',data.Properties.VariableNames(1:end-1));
% add label variable
newdata = addvars(tmp,repmat(minorityLabel,height(tmp),1),...
    'NewVariableNames',data.Properties.VariableNames(end));
end


function gap = generateGap(safeLevelP, safeLevelN)

if safeLevelN ~= 0
    safeLevelRatio = safeLevelP/safeLevelN;
else
    safeLevelRatio = inf;
end


if (isinf(safeLevelRatio) && safeLevelP == 0) % 1st case
    % When neighbors are all non-minority class (y and its neighbors)
    gap = nan;
    % does not generate positive synthetic instance
elseif (isinf(safeLevelRatio) && safeLevelP ~= 0) % 2nd case
    % When neighbors' neighbors are all non-minority, but there are
    % minority class around y
    gap = 0;
elseif (safeLevelRatio == 1) % 3rd case
    gap = rand();
elseif (safeLevelRatio > 1) % 4th case
    % When there are more minority class around y
    gap = rand()/safeLevelRatio;
elseif (safeLevelRatio < 1)
    % When there are more minority class around y's neighbor
    gap = rand()*safeLevelRatio + (1-safeLevelRatio);
else
    % warning('generateGap() in SafeLevelSmote.m: something is wrong in getting gap');
    gap = rand();
end

end


function g = sigmoid(z)
% Computes sigmoid of z
g = 1.0 ./ (1.0 + exp(-z));
end

function [X, fX, i] = fmincg(f, X, options, P1, P2, P3, P4, P5)
% Minimize a continuous differentialble multivariate function. Starting point
% is given by "X" (D by 1), and the function named in the string "f", must
% return a function value and a vector of partial derivatives. The Polack-
% Ribiere flavour of conjugate gradients is used to compute search directions,
% and a line search using quadratic and cubic polynomial approximations and the
% Wolfe-Powell stopping criteria is used together with the slope ratio method
% for guessing initial step sizes. Additionally a bunch of checks are made to
% make sure that exploration is taking place and that extrapolation will not
% be unboundedly large. The "length" gives the length of the run: if it is
% positive, it gives the maximum number of line searches, if negative its
% absolute gives the maximum allowed number of function evaluations. You can
% (optionally) give "length" a second component, which will indicate the
% reduction in function value to be expected in the first line-search (defaults
% to 1.0). The function returns when either its length is up, or if no further
% progress can be made (ie, we are at a minimum, or so close that due to
% numerical problems, we cannot get any closer). If the function terminates
% within a few iterations, it could be an indication that the function value
% and derivatives are not consistent (ie, there may be a bug in the
% implementation of your "f" function). The function returns the found
% solution "X", a vector of function values "fX" indicating the progress made
% and "i" the number of iterations (line searches or function evaluations,
% depending on the sign of "length") used.
%
% Usage: [X, fX, i] = fmincg(f, X, options, P1, P2, P3, P4, P5)
%
% See also: checkgrad 
%
% Copyright (C) 2001 and 2002 by Carl Edward Rasmussen. Date 2002-02-13
%
%
% (C) Copyright 1999, 2000 & 2001, Carl Edward Rasmussen
% 
% Permission is granted for anyone to copy, use, or modify these
% programs and accompanying documents for purposes of research or
% education, provided this copyright notice is retained, and note is
% made of any changes that have been made.
% 
% These programs and documents are distributed without any warranty,
% express or implied.  As the programs were written for research
% purposes only, they have not been tested to the degree that would be
% advisable in any important application.  All use of these programs is
% entirely at the user's own risk.
%
% [ml-class] Changes Made:
% 1) Function name and argument specifications
% 2) Output display
%

% Read options
if exist('options', 'var') && ~isempty(options) && isfield(options, 'MaxIter')
    length = options.MaxIter;
else
    length = 100;
end


RHO = 0.01;                            % a bunch of constants for line searches
SIG = 0.5;       % RHO and SIG are the constants in the Wolfe-Powell conditions
INT = 0.1;    % don't reevaluate within 0.1 of the limit of the current bracket
EXT = 3.0;                    % extrapolate maximum 3 times the current bracket
MAX = 20;                         % max 20 function evaluations per line search
RATIO = 100;                                      % maximum allowed slope ratio

argstr = ['feval(f, X'];                      % compose string used to call function
for i = 1:(nargin - 3)
  argstr = [argstr, ',P', int2str(i)];
end
argstr = [argstr, ')'];

if max(size(length)) == 2, red=length(2); length=length(1); else red=1; end
S=['Iteration '];

i = 0;                                            % zero the run length counter
ls_failed = 0;                             % no previous line search has failed
fX = [];
[f1 df1] = eval(argstr);                      % get function value and gradient
i = i + (length<0);                                            % count epochs?!
s = -df1;                                        % search direction is steepest
d1 = -s'*s;                                                 % this is the slope
z1 = red/(1-d1);                                  % initial step is red/(|s|+1)

while i < abs(length)                                      % while not finished
  i = i + (length>0);                                      % count iterations?!

  X0 = X; f0 = f1; df0 = df1;                   % make a copy of current values
  X = X + z1*s;                                             % begin line search
  [f2 df2] = eval(argstr);
  i = i + (length<0);                                          % count epochs?!
  d2 = df2'*s;
  f3 = f1; d3 = d1; z3 = -z1;             % initialize point 3 equal to point 1
  if length>0, M = MAX; else M = min(MAX, -length-i); end
  success = 0; limit = -1;                     % initialize quanteties
  while 1
    while ((f2 > f1+z1*RHO*d1) | (d2 > -SIG*d1)) & (M > 0) 
      limit = z1;                                         % tighten the bracket
      if f2 > f1
        z2 = z3 - (0.5*d3*z3*z3)/(d3*z3+f2-f3);                 % quadratic fit
      else
        A = 6*(f2-f3)/z3+3*(d2+d3);                                 % cubic fit
        B = 3*(f3-f2)-z3*(d3+2*d2);
        z2 = (sqrt(B*B-A*d2*z3*z3)-B)/A;       % numerical error possible - ok!
      end
      if isnan(z2) | isinf(z2)
        z2 = z3/2;                  % if we had a numerical problem then bisect
      end
      z2 = max(min(z2, INT*z3),(1-INT)*z3);  % don't accept too close to limits
      z1 = z1 + z2;                                           % update the step
      X = X + z2*s;
      [f2 df2] = eval(argstr);
      M = M - 1; i = i + (length<0);                           % count epochs?!
      d2 = df2'*s;
      z3 = z3-z2;                    % z3 is now relative to the location of z2
    end
    if f2 > f1+z1*RHO*d1 | d2 > -SIG*d1
      break;                                                % this is a failure
    elseif d2 > SIG*d1
      success = 1; break;                                             % success
    elseif M == 0
      break;                                                          % failure
    end
    A = 6*(f2-f3)/z3+3*(d2+d3);                      % make cubic extrapolation
    B = 3*(f3-f2)-z3*(d3+2*d2);
    z2 = -d2*z3*z3/(B+sqrt(B*B-A*d2*z3*z3));        % num. error possible - ok!
    if ~isreal(z2) | isnan(z2) | isinf(z2) | z2 < 0   % num prob or wrong sign?
      if limit < -0.5                               % if we have no upper limit
        z2 = z1 * (EXT-1);                 % the extrapolate the maximum amount
      else
        z2 = (limit-z1)/2;                                   % otherwise bisect
      end
    elseif (limit > -0.5) & (z2+z1 > limit)          % extraplation beyond max?
      z2 = (limit-z1)/2;                                               % bisect
    elseif (limit < -0.5) & (z2+z1 > z1*EXT)       % extrapolation beyond limit
      z2 = z1*(EXT-1.0);                           % set to extrapolation limit
    elseif z2 < -z3*INT
      z2 = -z3*INT;
    elseif (limit > -0.5) & (z2 < (limit-z1)*(1.0-INT))   % too close to limit?
      z2 = (limit-z1)*(1.0-INT);
    end
    f3 = f2; d3 = d2; z3 = -z2;                  % set point 3 equal to point 2
    z1 = z1 + z2; X = X + z2*s;                      % update current estimates
    [f2 df2] = eval(argstr);
    M = M - 1; i = i + (length<0);                             % count epochs?!
    d2 = df2'*s;
  end                                                      % end of line search

  if success                                         % if line search succeeded
    f1 = f2; fX = [fX' f1]';
    fprintf('%s %4i | Cost: %4.6e\r', S, i, f1);
    s = (df2'*df2-df1'*df2)/(df1'*df1)*s - df2;      % Polack-Ribiere direction
    tmp = df1; df1 = df2; df2 = tmp;                         % swap derivatives
    d2 = df1'*s;
    if d2 > 0                                      % new slope must be negative
      s = -df1;                              % otherwise use steepest direction
      d2 = -s'*s;    
    end
    z1 = z1 * min(RATIO, d1/(d2-realmin));          % slope ratio but max RATIO
    d1 = d2;
    ls_failed = 0;                              % this line search did not fail
  else
    X = X0; f1 = f0; df1 = df0;  % restore point from before failed line search
    if ls_failed | i > abs(length)          % line search failed twice in a row
      break;                             % or we ran out of time, so we give up
    end
    tmp = df1; df1 = df2; df2 = tmp;                         % swap derivatives
    s = -df1;                                                    % try steepest
    d1 = -s'*s;
    z1 = 1/(1-d1);                     
    ls_failed = 1;                                    % this line search failed
  end
  if exist('OCTAVE_VERSION')
    fflush(stdout);
  end
end
fprintf('\n');
end

function [J, grad] = cost(theta, X, y, lambda)
% Computes the cost of using theta as the parameter for regularized 
% logistic regression and the gradient of the cost w.r.t. to the parameters. 
% Initialize some useful values
m = length(y); % number of training examples
J = 0;
grad = zeros(size(theta));
% Compute cost function
templog(:,1) = log(sigmoid(X*theta));
templog(:,2) = log(1-(sigmoid(X*theta)));
tempy(:,1) = y;
tempy(:,2) = 1-y;
temp = templog.*tempy;
% Formula for cost function. Note theta0 not involved in regularization
J = (1/m)*(-sum(temp(:,1))-sum(temp(:,2))) + ...
    (lambda/(2*m))*sum(theta(2:end,1).^2);
% Compute gradient 
% theta0 not calclated with regularization
grad(1,1) = (1/m)*sum((sigmoid(X*theta)-y).*X(:,1)); 
grad(2:end,1)=((1/m)*((sigmoid(X*theta)-y)'*X(:,2:end)))'+(lambda/m)*theta(2:end);


grad = grad(:);
end

function [J, grad] = costFunctionReg(theta, X, y, lambda)
%   costFunctionReg Compute cost and gradient for logistic regression with regularization
%   J = costFunctionReg(theta, X, y, lambda) computes the cost of using
%   theta as the parameter for regularized logistic regression and the
%   gradient of the cost w.r.t. to the parameters.

% Initialize some useful values
m = length(y); % number of training examples

% You need to return the following variables correctly
J = 0;
grad = zeros(size(theta));

% ====================== YOUR CODE HERE ======================
% Instructions: Compute the cost of a particular choice of theta.
%               You should set J to the cost.
%               Compute the partial derivatives and set grad to the partial
%               derivatives of the cost w.r.t. each parameter in theta

% calculate cost function
h = sigmoid(X*theta);
% calculate penalty
% excluded the first theta value
theta1 = [0 ; theta(2:size(theta), :)];
p = lambda*(theta1'*theta1)/(2*m);
J = ((-y)'*log(h) - (1-y)'*log(1-h))/m + p;

% calculate grads
grad = (X'*(h - y)+lambda*theta1)/m;

% =============================================================

end

function theta = LRTraining(X, y, numLabels, lambda, hessUpdate)
% LRTraining returns the values of theta. Each row of theta corresponds
% to a single classifier for the number being considered.
% Some useful variables

m = size(X, 1); % number of examples
n = size(X, 2); % how many parameters (features)
theta = zeros(numLabels, n+1); % (n+1) to account for the x0 term
initialTheta = zeros(n+1,1);
%options = optimset('GradObj','on','MaxIter',150); % used in fmincg
%options = optimoptions(@fminunc,'Display','iter','Algorithm','quasi-newton');
options = optimoptions('fminunc','Algorithm','quasi-newton','SpecifyObjectiveGradient',true,...
    'HessUpdate',hessUpdate);

% Add ones to the X data matrix to account for x0
X = [ones(m, 1) X];
% fmincg works similarly to fminunc, but is more efficient when 
% dealing with large number of parameters.

for i=1:numLabels
    yTemp = (y==i); % select all examples of particular number for training
    %disp(yTemp)
    %[tempTheta(:,i)] = fmincg(@(t)(cost(t,X,yTemp,lambda)),...
    %                           initialTheta,options);
    % Optimize
    [tempTheta(:,i), J, exit_flag] = ...
        fminunc(@(t)(costFunctionReg(t, X, yTemp, lambda)), initialTheta, options);
    % fmincg was taken from Andrew Ng machine learning course
    theta(i,:) = tempTheta(:,i)';
    
end
end

function prediction = LRPredict(theta, X)
% This function returns the predicted label for the given X based on the
% highest probablity compared among each of the classifiers.
m = size(X, 1);
prediction = zeros(size(X, 1), 1);
% Add ones to the X data matrix to account for x0
X = [ones(m, 1) X];
tempProb = X * theta';
[~,prediction] = max(tempProb ,[],2);
end

function proba = LRPredictProba(theta, X)
% This function returns the predicted label for the given X based on the
% highest probablity compared among each of the classifiers.
m = size(X, 1);

% Add ones to the X data matrix to account for x0
X = [ones(m, 1) X];
proba = sigmoid(X * theta');
end

function [h, display_array] = displayData(X, example_width)
%DISPLAYDATA Display 2D data in a nice grid
%   [h, display_array] = DISPLAYDATA(X, example_width) displays 2D data
%   stored in X in a nice grid. It returns the figure handle h and the 
%   displayed array if requested.
% Set example_width automatically if not passed in
if ~exist('example_width', 'var') || isempty(example_width) 
	example_width = round(sqrt(size(X, 2)));
end
% Gray Image
colormap(gray);
% Compute rows, cols
[m n] = size(X);
example_height = (n / example_width);
% Compute number of items to display
display_rows = floor(sqrt(m));
display_cols = ceil(m / display_rows);
% Between images padding
pad = 1;
% Setup blank display
display_array = - ones(pad + display_rows * (example_height + pad), ...
                       pad + display_cols * (example_width + pad));
% Copy each example into a patch on the display array
curr_ex = 1;
for j = 1:display_rows
	for i = 1:display_cols
		if curr_ex > m, 
			break; 
		end
		% Copy the patch
		
		% Get the max value of the patch
		max_val = max(abs(X(curr_ex, :)));
		display_array(pad + (j - 1) * (example_height + pad) + (1:example_height), ...
		              pad + (i - 1) * (example_width + pad) + (1:example_width)) = ...
						reshape(X(curr_ex, :), example_height, example_width) / max_val;
		curr_ex = curr_ex + 1;
	end
	if curr_ex > m, 
		break; 
	end
end
% Display Image
h = imagesc(display_array, [-1 1]);
% Do not show axis
axis image off
drawnow;
end


function p = predictOneVsAll(all_theta, X)
%PREDICT Predict the label for a trained one-vs-all classifier. The labels 
%are in the range 1..K, where K = size(all_theta, 1). 
%  p = PREDICTONEVSALL(all_theta, X) will return a vector of predictions
%  for each example in the matrix X. Note that X contains the examples in
%  rows. all_theta is a matrix where the i-th row is a trained logistic
%  regression theta vector for the i-th class. You should set p to a vector
%  of values from 1..K (e.g., p = [1; 3; 1; 2] predicts classes 1, 3, 1, 2
%  for 4 examples) 

m = size(X, 1);
num_labels = size(all_theta, 1);

% You need to return the following variables correctly 
p = zeros(size(X, 1), 1);

% Add ones to the X data matrix
X = [ones(m, 1) X];

% ====================== YOUR CODE HERE ======================
% Instructions: Complete the following code to make predictions using
%               your learned logistic regression parameters (one-vs-all).
%               You should set p to a vector of predictions (from 1 to
%               num_labels).
%
% Hint: This code can be done all vectorized using the max function.
%       In particular, the max function can also return the index of the 
%       max element, for more information see 'help max'. If your examples 
%       are in rows, then, you can use max(A, [], 2) to obtain the max 
%       for each row.    

[dummy, p] = max(sigmoid(X * all_theta'), [],2);
    
end


function stats = confusionMatStats(group,grouphat,weight)
% http://www.mathworks.com/matlabcentral/fileexchange/46035-confusion-matrixREPLACE_WITH_DASH_DASHaccuracyREPLACE_WITH_DASH_DASHprecisionREPLACE_WITH_DASH_DASHspecificityREPLACE_WITH_DASH_DASHsensitivityREPLACE_WITH_DASH_DASHrecallREPLACE_WITH_DASH_DASHf-score
%
% INPUT
% group = true class labels
% grouphat = predicted class labels
%
% OR INPUT
% stats = confusionmatStats(group);
% group = confusion matrix from matlab function (confusionmat)
%
% OUTPUT
% stats is a structure array
% stats.confusionMat
%               Predicted Classes
%                    p'    n'
%              ___|_____|_____| 
%       Actual  p |     |     |
%      Classes  n |     |     |
%

% Accuracy returns an overall measure of how much the model is correctly predicting on the entire set of data. The basic
% element of the metric are the single individuals in the dataset: each unit has the same weight and they contribute equally
% to the Accuracy value.
% When we think about classes instead of individuals, there will be classes with a high number of units and others with
% just few ones. In this situation, highly populated classes will have higher weight compared to the smallest ones.
% Therefore, Accuracy is most suited when we just care about single individuals instead of multiple classes. The key
% question is "Am I interested in a predicting the highest number of individuals in the right class, without caring about
% class distribution and other indicators?". If the answer is positive, then the Accuracy is the right indicator.


% stats.accuracy = (TP + TN)/(TP + FP + FN + TN) ; the average accuracy is returned
% stats.precision = TP / (TP + FP)                  % for each class label
% stats.sensitivity = TP / (TP + FN)                % for each class label
% stats.specificity = TN / (FP + TN)                % for each class label
% stats.recall = sensitivity                        % for each class label
% stats.Fscore = 2*TP /(2*TP + FP + FN)            % for each class label
%
% TP: true positive, TN: true negative, 
% FP: false positive, FN: false negative
% 

field1 = 'confusionMat';
if nargin < 3
    value1 = group;
else
    value1 = confusionmat(group,grouphat);
end
disp('test')
numOfClasses = size(value1,1);
totalSamples = sum(sum(value1));
rowMat = 0;

[TP,TN,FP,FN,sensitivity,specificity,precision,f_score_macro,f_score_micro,weighted_balanced_accuracy]...
    = deal(zeros(numOfClasses,1));
for class = 1:numOfClasses
   TP(class) = value1(class,class);
   tempMat = value1;
   tempMat(:,class) = []; % remove column
   tempMat(class,:) = []; % remove row
   TN(class) = sum(sum(tempMat));
   FP(class) = sum(value1(:,class))-TP(class);
   FN(class) = sum(value1(class,:))-TP(class);
   rowMat = rowMat + (value1(class,class) / sum(value1(class,:)));
   weight(class) = 1/weight(class); % calculate inverse of frequency
end

%field2 = 'accuracy';  value2 = (trace(value1)) / (totalSamples);

nweight = normalize(weight,'range'); %normalize weights

for class = 1:numOfClasses
    sensitivity(class) = TP(class) / (TP(class) + FN(class));
    specificity(class) = TN(class) / (FP(class) + TN(class));
    precision(class) = TP(class) / (TP(class) + FP(class));
    f_score_macro(class) = TP(class)/(TP(class) + FP(class));
    %f_score_micro(class) = 2*TP(class)/(2*TP(class) + FP(class) + FN(class));
    weighted_balanced_accuracy(class) = sensitivity(class) * nweight(class);
end

field2 = 'accuracy';  value2 = sum(TP)/sum(TP+FP);
field3 = 'balanced_accuracy';  value3 = sum(sensitivity) / (numOfClasses); %(rowMat)/(numOfClasses);
field4 = 'weighted_balanced_accuracy'; value4 = sum(weighted_balanced_accuracy);
field5 = 'weights'; value5 = weight;
field6 = 'tp';  value6 = TP;
field7 = 'tn';  value7 = TN;
field8 = 'fp';  value8 = FP;
field9 = 'fn';  value9 = FN;
field10 = 'sensitivity';  value10 = sensitivity;
field11 = 'specificity';  value11 = specificity;
field12 = 'precision';  value12 = precision;
field13 = 'recall';  value13 = sensitivity;
field14 = 'Fscore_macro';  value14 = sum(f_score_macro)/numOfClasses;
field15 = 'Fscore_micro';  value15 = sum(TP)/sum(TP+FP);

stats = struct(field1,value1,field2,value2,field3,value3,field4,value4,field5,value5,field6,value6,...
               field7,value7,field8,value8,field9,value9,field10,value10,field11,value11,field12,value12,...
               field13,value13,field14,value14,field15,value15);
end


function [W, b] = LRTrain(X_train, y_train, lambda, n)
%Logistic Regression that operates a multinomial Logistic Regression on input

%% INITIALIZATIONS
%lambda = 0.01;  %regularization coef
epochs = 50; %Change to 300 for final training
[n,D] = size(X_train);
W = rand(D, n);
b = zeros(1, n);
l2 = 0.0;
epochs_costs = [];

% converting labels to one-hot represatiation
y_hot = full(ind2vec(y_train',n))';

%% TRAIN
% Gradient Descent
for e=1:epochs
    
    diff = softmax((X_train * W + b)')' - y_hot; % calculating gradient
    grad = X_train' * diff;
    W = W - (lambda * grad + (lambda * l2 * W)); % Updating W & b
    b = b - (lambda * sum(diff));    
end

end

function [preds] = LRPrediction(X_test, y_test, W ,b)

%% TEST

sm = softmax((X_test * W + b)')';
[~ , preds] = max(sm, [], 2);
end

% Custom validation function
% https://jp.mathworks.com/help/matlab/matlab_prog/function-argument-validation-1.html
%REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH-
% Copyright (c) 2019 Michio Inoue
function mustBeTableWithClassname(arg)
    features = arg{:,1:end-1};
    class = arg{:,end};
    if ~isnumeric(features)
        error(['not numeric features'])
    end
    if ~isstring(class)
        display(class)
        error(['not a string classname'])
    end
end

function oobErr = oobErrorRF(params,X,split_criterion)
%oobErrRF Trains random forest and estimates out-of-bag quantile error
%   oobErr trains a random forest of classification trees using the
%   predictor data in X and the parameter specification in params, and then
%   returns the out-of-bag quantile error based on the median. X is a table
%   and params is an array of OptimizableVariable objects corresponding to
%   the minimum leaf size and number of predictors to sample at each node.
randomForest = TreeBagger(params.maxNumTrees,X,'Kingdom',"SampleWithReplacement", "on",'Method','Classification',...
                          'OOBPrediction','On', 'OOBPredictorImportance','On',...
                          'MinLeafSize',params.minLeafSize,...
                          'NumPredictorstoSample',params.numPredictorstoSample,...
                          'MaxNumSplits',params.maxNumSplits, ...
                          'Prior','Empirical', ...
                          'SplitCriterion',split_criterion);

oobErr = oobError(randomForest, 'Mode','ensemble');
end


function [q1,q2,q3,w0,w1,outliers] = boxplot_statistics(data, whisker)
    if ~exist('whisker', 'var')
        % whisker is 1.5 by default
        whisker = 1.5;
    end

    % quantile(data,3) will return the 25th, 50th, and 75th percentile
    % for each column
    quants = quantile(data, 3);
    q1 = quants(1,:);
    q2 = quants(2,:);
    q3 = quants(3,:);

    % Compute the upper and lower thresholds for outlier classification
    upper_thresh = q3 + whisker .* (q3-q1);
    lower_thresh = q1 - whisker .* (q3-q1);

    % Outliers are points above the upper_thresh or below lower_thresh
    outliers = (data > upper_thresh) | (data < lower_thresh);

    % To compute the whiskers, take max and min (per column). Setting
    % outlier values to NaN causes them to be ignored.
    data(outliers) = NaN;
    w0 = min(data,[],1);
    w1 = max(data,[],1);
end



% Computes several quantities based on the model-based confusion matrix of
% a classifier. The model specification could be the ground truth or an
% estimate of it.
% 
% Usage:
%     [TPR, FPR, PPV, AUC, AP] = prc_compute_stats(alpha, muN, sigmaN, muP, sigmaP)
%
% Arguments:
%     alpha: fraction of examples from positive class (0 < alpha < 1)
%     muN: mean of decision values from negative class
%     sigmaN: std.dev. of decision values from negative class (must be > 0)
%     muP: mean of decision values from positive class
%     sigmaP: std.dev. of decision values from positive class  (must be > 0)
%     nPoints (optional): number of thresholds to consider (default: 1000)
% 
% Return values:
%     TPR: true positive rate (recall)
%     FPR: false positive rate
%     PPV: positive predictive value (precision)
%     AUC: area under the ROC curve
%     AP: area under the PR curve (average precision)
% 
% Literature:
%     K.H. Brodersen, C.S. Ong, K.E. Stephan, J.M. Buhmann (2010). The
%     binormal assumption on precision-recall curves. In: Proceedings of
%     the 20th International Conference on Pattern Recognition (ICPR).

% Kay H. Brodersen & Cheng Soon Ong, ETH Zurich, Switzerland
% $Id: prc_stats.m 6393 2010-06-14 15:24:46Z bkay $
% REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH-
function [TPR, FPR, PPV, AUC, AP] = prc_stats(alpha, muN, sigmaN, muP, sigmaP, nPoints)
    
    % Set interpolation accuracy: the higher the more accurate
    try; nPoints; catch; nPoints = 1000; end
    
    % Check input
    assert(isscalar(alpha) && isscalar(muN) && isscalar(sigmaN) && isscalar(muP) && isscalar(sigmaP) && isscalar(nPoints));
    assert(0<alpha && alpha<1, 'class balance ''alpha'' must be strictly between 0 and 1');
    assert(sigmaN>0 && sigmaP>0, 'variances must be positive');
    assert(nPoints>1, 'must use at least 2 interpolation points (nPoints)');
    if nPoints<10, warning('nPoints is very small and may result in highly inaccurate estimates'); end
    
    % Set thresholds between data points
    thr = linspace(muN-5*sigmaN, muP+5*sigmaP, nPoints);
    assert(length(thr)>1);
    
    % Compute parametric confusion matrix
    TP = alpha.*(1-normcdf(thr,muP,sigmaP));
    FP = (1-alpha).*(1-normcdf(thr,muN,sigmaN));
    FN = alpha.*normcdf(thr,muP,sigmaP);
    TN = (1-alpha).*normcdf(thr,muN,sigmaN);
    
    % Compute rates
    TPR = TP./(TP+FN);
    FPR = FP./(FP+TN);
    PPV = TP./(TP+FP);
    
    % Area under the ROC curve
    A = (muP-muN)/sigmaP; B = sigmaN/sigmaP;
    AUC = normcdf(A/sqrt(1+B^2));
    
    % Area under the PR curve
    AP = abs(trapz(TPR,PPV));
end

% Computes smooth estimates of statistics based on classification output,
% based on either the binormal or the alpha-binormal model.
% 
% Usage:
%     [TPR, FPR, PPV, AUC, AP] = prc_stats_binormal(targs, dvs, alpha_binormal)
% 
% Arguments:
%     targs: a vector of true class labels (targets). The vector must only
%         contain the values -1 (for negative examples) and +1 (for
%         positive examples).
%     dvs: a vector of decision values. The vector must have the same size
%         as 'targs'
%     alpha_binormal: whether to use the alpha-binormal model, in
%         which the class imbalance is estimated from the data (default =
%         false, i.e., classes are assumed to be perfectly balanced).
%         This setting is highly recommended for smooth estimates of the
%         precision-recall curve.
% 
% Return values:
%     TPR: true positive rate (recall)
%     FPR: false positive rate
%     PPV: positive predictive value (precision)
%     AUC: area under the ROC curve
%     AP: area under the PR curve (average precision)
% 
% Literature:
%     K.H. Brodersen, C.S. Ong, K.E. Stephan, J.M. Buhmann (2010). The
%     binormal assumption on precision-recall curves. In: Proceedings of
%     the 20th International Conference on Pattern Recognition (ICPR).

% Kay H. Brodersen & Cheng Soon Ong, ETH Zurich, Switzerland
% $Id: prc_stats_binormal.m 6393 2010-06-14 15:24:46Z bkay $
% REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH-
function [TPR, FPR, PPV, AUC, AP] = prc_stats_binormal(targs, dvs, alpha_binormal)
    
    % Set default values
    try, estimateClassImbalance; catch; estimateClassImbalance = false; end
    
    % Check input
    targs = targs(:)';
    assert(all(targs==-1 | targs==1), 'targs must only contain -1 and 1');
    dvs = dvs(:)';
    assert(length(targs)==length(dvs), 'targs and dvs must have the same number of elements');
    assert(isscalar(alpha_binormal) && ~isstr(alpha_binormal), 'alpha_binormal must be true or false');
    
    % Get class-conditional decision values
    pos = dvs(targs == 1);
    neg = dvs(targs == -1);
    assert(length(pos)>=2 && length(neg)>=2, 'targs must contain at least two examples of either class');
    
    % Estimate mean and std.dev. from the data
    muP = mean(pos);
    muN = mean(neg);
    sigmaP = std(pos);
    sigmaN = std(neg);
    assert(sigmaP>0 & sigmaN>0, 'dvs must allow for estimation of positive class-conditional standard deviations');
    
    % Estimate class balance as well?
    if alpha_binormal
        alpha = length(pos)/length(targs);
        assert(alpha>=0 && alpha<=1);
    else
        alpha = 0.5;
    end
    
    % Compute stats
    [TPR, FPR, PPV, AUC, AP] = prc_stats(alpha, muN, sigmaN, muP, sigmaP);
    
end



function plt = compute_prc_roc(targs, dvs,PRC_or_ROC,codon_class,class_number,kfold,legends,plt)
% Modified by Bernardo Azevedo for multi-classification 
%
% Application of methods for estimating a
% precision-recall curve (PRC) and receiver operator curve (ROC) .
%
% Generates decision values from a binormal distribution and plots true vs.
% empirical vs. model-based quantities derived from the confusion matrix of
% the simulated classifier.
%
% Usage:
%     prc_demo
%
% Literature:
%     K.H. Brodersen, C.S. Ong, K.E. Stephan, J.M. Buhmann (2010). The
%     binormal assumption on precision-recall curves. In: Proceedings of
%     the 20th International Conference on Pattern Recognition (ICPR).
% Kay H. Brodersen & Cheng Soon Ong, ETH Zurich, Switzerland
% $Id: prc_demo.m 5529 2010-04-22 21:10:32Z bkay $


% REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH-
% Compute empirical curves
%[TPR_emp, FPR_emp, PPV_emp] = prc_stats_empirical(targs, dvs);

% Compute smooth curves (binormal model)
[TPR_bin, FPR_bin, PPV_bin] = prc_stats_binormal(targs, dvs, false);

% Compute smooth curves (alpha-binormal model)
%[TPR_abin, FPR_abin, PPV_abin] = prc_stats_binormal(targs, dvs, true);

CM = jet(3);
% REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH-
cols = [200 45 43; 37 64 180; 0 176 80; 0 0 0]/255;
if PRC_or_ROC=="PRC"
    % Plot PR curves
    %figure; hold on;
    pl = plot(TPR_bin, PPV_bin, '-', 'color', [CM(class_number,:) 0.6], 'linewidth', 2);
    plt(class_number) = pl; 
    axis([0 1 0 1]);
    %xlabel('TPR (recall)'); ylabel('PPV (precision)'); title('PR curves');
    xlabel('Recall'); ylabel('Precision'); title(['PR AUC curves for Fold: ', num2str(kfold)]);
    if class_number == 3
        legend(plt,legends,'location','southeast');
    end
    set(gca, 'box', 'on');
elseif PRC_or_ROC=="ROC"
    % Plot ROC curves
    %figure; hold on;
    pl = plot(FPR_bin, TPR_bin, '-', 'color', [CM(class_number,:) 0.6], 'linewidth', 1);
    plt(class_number) = pl;   
    plot([0 1], [0 1], '-', 'color', [0.7 0.7 0.7], 'linewidth', 2);
    axis([0 1 0 1]);
    xlabel('FPR'); ylabel('TPR'); title(['ROC curves for Fold: ', num2str(kfold)]);
    if class_number == 3
        legend(plt,legends,'location','southeast');
    end
    set(gca, 'box', 'on');
end
end


function [X_train_balanced, y_train_balanced] = smote_and_undersampling(X_train,y_train,smote_proportion,...
    undersampling_proportion,smote_undersampling_choice)

% 1 - SMOTE

% Define the number of neighbours (k = 10) to use as one of the parameters in the comparison
% and proportion of increase (5 times)
k = 10;
%smote_proportion = 5;

X_train_label = addvars(array2table(X_train), string(y_train),...
    'NewVariableNames','label');

tbl = tabulate(X_train_label.label);

t_ratio_class = array2table(tbl,'VariableNames', ...
    {'Value','Count','Percent'});

uniqueLabels = string(tbl(:,1));

% Define number of samples to add for minority class
smote_samples = round(cell2mat(table2array(t_ratio_class(1,2))) * smote_proportion,0);

% We define samples for minority class and 0 for the other classes
num2Add = [smote_samples,0,0];


newdata = table;
visdataset = cell(length(uniqueLabels),1);

% Define for each class
    
for ii=1:length(uniqueLabels)
    [tmp,visdata] = SafeLevelSMOTE(X_train_label,uniqueLabels(ii),num2Add(ii),...
                "NumNeighbors",k, "Standardize", false);
    newdata = [newdata; tmp];
    visdataset{ii} = visdata;
end

% Finally we save the added samples to an array (removing the last column)
smote_class1 = table2array(newdata(:,1:end-1));

% Finally we save the added samples to an array (removing the last column)
X_train = [X_train ; smote_class1];

% For y_train we save only the last column (label) 
% which is composed of the original training set with added samples
y_train = [y_train; categorical(table2array(newdata(:,end)))];

if smote_undersampling_choice == "smote_undersampling"
    % 2 - Undersampling
    
    % For reproducibility
    rng(1,'twister');
    
    % Concatenate X_Train columns after SMOTE with label columns
    X_train_label = addvars(array2table(X_train), string(y_train),...
    'NewVariableNames','label');
    tbl = tabulate(X_train_label.label);
    t_ratio_class = array2table(tbl,'VariableNames', ...
        {'Value','Count','Percent'});
    
    % Calculate number of samples for undersampling step
    under_samples = round(cell2mat(table2array(t_ratio_class(1,2))) / undersampling_proportion,0);
    disp(under_samples)
    
    % Create arrays for sampling purposes
    x_rus = table2array(X_train_label);
    y_rus = x_rus(:,end);
    
    % Filter between majority class and the other 2 classes
    X_maj = x_rus(find(y_rus == "euk"),:);
    X_rest = x_rus(find(y_rus == "arc" | y_rus == "bct"),:);
    
    % Generate random indexes for random undersampling
    rp = randperm(size(X_maj,1));
    random_sample = rp(1:under_samples);
    
    X_rand_maj = X_maj(random_sample,:);
    
    X_train_balanced = [str2double(X_rand_maj(:,1:end-1))  ; str2double(X_rest(:,1:end-1))];
    y_train_balanced = [X_rand_maj(:,end) ; X_rest(:,end)];
else
   X_train_balanced = X_train;
   y_train_balanced = y_train;
end    
end


function ObjFcn = makeObjFcn(k_fold, X, splitCriterion)
     
ObjFcn = @valErrorFun;
function objective = valErrorFun(optVars,~)

% Set KFold
K = k_fold;

rng(1, 'twister');

X_train = table2array(X(:,1:end-1));
y_train = table2array(X(:,end));

% Change classes to numerical data
y_train_num = renamecats(categorical(y_train),{'arc','bct','euk'},{'1','2','3'});
y_train_num = str2double(string(y_train_num));

indices=crossvalind('Kfold',y_train_num,K);

%leaf = 5;
numSplits = 50; % 20 25];
numPredictors = 15;

errorMat = zeros(1,K);

for i_fold=1:K

    % Assigning training and validation set indexes
    val = (indices == i_fold);
    train = ~val;
    % Training set
    Xf_train = X_train(train,:);
    yf_train = y_train(train);
    % Validation set
    Xf_val = X_train(val,:);
    yf_val = y_train(val);
    
    % Apply SMOTE only (300 % more synthetic samples)
    [Xf_train_balanced, yf_train_balanced] = smote_and_undersampling(Xf_train, yf_train, 3, 0,"smote");

    
    rfGS = TreeBagger(128,Xf_train_balanced,yf_train_balanced, "SampleWithReplacement", "on",...
            'Method','Classification','OOBPrediction','On','OOBPredictorImportance','On',...
            'MinLeafSize',optVars.minLeafSize,'MaxNumSplits',optVars.maxNumSplits,...
            'NumPredictorsToSample',optVars.numPredictorstoSample,...
            'SplitCriterion',splitCriterion);

    predicted_val = cellstr(predict(rfGS,Xf_val)); % Prediction of RF model for testing set

    % Check the success of the classifier
    %cp = classperf(cellstr(yf_val), predicted_val);
    %testval = testval + cp.ErrorRate;  
    index = cellfun(@strcmp,predicted_val,cellstr(yf_val));
    errorMat(i_fold) = sum(index)/length(yf_val);
end

% Calculate misclassification error (1 - mean(errors))
objective = 1-mean(errorMat); 

    end
end


%% 
%
##### SOURCE END #####
--></body></html>